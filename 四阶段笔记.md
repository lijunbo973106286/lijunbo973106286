# day01



### 微服务概述（低 30）

单体应用到分布式，微服务的演变,微服务架构的定义及优缺点



#### 大型网络架构变迁

##### 单体架构

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210802094516.png" alt="image-20210802094515955" style="zoom:50%;" />

集群解决单服务器负载问题

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210801172038.png" alt="image-20210801172038458" style="zoom:50%;" />

##### SOA

面向服务的架构（SOA）是一个组件模型，它将应用程序的不同功能单元（称为服务）进行拆分，并通过这些服务之间定义良好的接口和协议联系起来。一个服务可能负责几个功能

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210801174815.png" alt="image-20210801174815174" style="zoom: 50%;" />

SOA 设计原则 
    在 SOA 架构中，继承了来自对象和构件设计的各种原则，例如，封装和自我包含等。那些保证服务的灵活性、松散耦合和复用能力的设计原则，对 SOA 架构来说同样是非常重要的。关于服务，一些常见的设计原则如下：

- 明确定义的接口。服务请求者依赖于服务规约来调用服务，因此，服务定义必须长时间稳定，一旦公布，不能随意更改；服务的定义应尽可能明确，减少请求者的不适当使用；不要让请求者看到服务内部的私有数据。

- 自包含和模块化。服务封装了那些在业务上稳定、重复出现的活动和构件，实现服务的功能实体是完全独立自主的，独立进行部署、版本控制、自我管理和恢复。

- 粗粒度。服务数量不应该太多，依靠消息交互而不是远程过程调用，通常消息量比较大，但是服务之间的交互频度较低。

- 松耦合。服务请求者可见的是服务的接口，其位置、实现技术、当前状态和私有数据等，对服务请求者而言是不可见的。

- 互操作性、兼容和策略声明。为了确保服务规约的全面和明确，策略成为一个越来越重要的方面。这可以是技术相关的内容，例如，一个服务对安全性方面的要求；也可以是与业务有关的语义方面的内容，例如，需要满足的费用或者服务级别方面的要求，这些策略对于服务在交互时是非常重要的。

但是这种集成方式开发代价大、通信效率低，且有单点故障的风险， 实际上在企业中并没有得到大规模应用。



##### 微服务

微服务顾名思义，就是很小的服务，所以它属于面向服务架构的一种。通俗一点来说，微服务类似于古代著名的发明，活字印刷术，每个服务都是一个组件，通过编排组合的方式来使用，从而真正做到了独立、解耦、组件化、易维护、可复用、可替换、高可用、最终达到提高交付质量、缩短交付周期的效果。

从专业的角度来看，微服务架构是一种架构模式，它提倡将单一应用程序划分成一组小的服务，服务之间互相协调、互相配合，为用户提供最终价值。每个服务运行在其独立的进程中，服务与服务间采用轻量级的通信机制互相沟通（通常是基于 HTTP  协议的 RESTful API）。每个服务都围绕着具体业务进行构建，并且能够被独立的部署到生产环境、类生产环境等。另外，应当尽量避免统一的、集中式的服务管理机制，对具体的一个服务而言，应根据业务上下文，选择合适的语言、工具对其进行构建。

所以总结起来，微服务的核心特点为：小, 且专注于做⼀件事情、轻量级的通信机制、松耦合、独立部署。



与SOA的主要区别

| 微服务                       | SOA                                       |
| ---------------------------- | ----------------------------------------- |
| 能拆分的就拆分               | 是整体的，服务能放一起的都放一起          |
| 业务逻辑存在于每一个服务中   | 业务逻辑横跨多个业务领域                  |
| 使用轻量级的通讯方式，如HTTP | 企业服务产总线(ESB)充当服务之间通讯的角色 |
| 细粒度                       | 粗粒度                                    |



微服务由SOA的发展而来。



#### 什么是分布式系统？

要理解分布式系统，主要需要明白一下2个方面：

1.分布式系统一定是由多个节点组成的系统。

其中，节点指的是计算机服务器，而且这些节点一般不是孤立的，而是互通的。

 

2.这些连通的节点上部署了我们的节点，并且相互的操作会有协同。

分布式系统对于用户而言，他们面对的就是一个服务器，提供用户需要的服务而已，而实际上这些服务是通过背后的众多服务器组成的一个分布式系统，因此分布式系统看起来像是一个超级计算机一样。

 

例如淘宝，平时大家都会使用，它本身就是一个分布式系统，我们通过浏览器访问淘宝网站时，这个请求的背后就是一个庞大的分布式系统在为我们提供服务，整个系统中有的负责请求处理，有的负责存储，有的负责计算，最终他们相互协调把最后的结果返回并呈现给用户。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210708093744.png" alt="image-20210708093744032" style="zoom: 50%;" />

#### 分布式服务框架的发展

##### 第一代服务框架

　　代表：Dubbo(Java)、Orleans(.Net)等

　　特点：和语言绑定非常紧密

##### 第二代服务框架

　　代表：Spring Cloud

　　特点：适合混合式开发，非常成熟，市场占有率高

##### 第三代服务框架

　　代表：Service Mesh（服务网格），例如Service Fabric、lstio、Linkerd、Conduit等

　　特点：快速发展，更新迭代比较快不够成熟

 

Spring Cloud作为第二代微服务的代表性框架，已经在国内众多大中小型的公司有实际应用案例。许多公司的业务线全部拥抱Spring Cloud，部分公司选择部分拥抱Spring Cloud。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210708093823.png" alt="image-20210708093823557" style="zoom:50%;" />

#### 微服务介绍

##### 什么是微服务

在介绍微服务时，首先得先理解什么是微服务，顾名思义，微服务得从两个方面去理解，什么是"微"、什么是"服务"，

 

微，狭义来讲就是体积小、著名的"2 pizza 团队"很好的诠释了这一解释（2 pizza 团队最早是亚马逊 CEO Bezos提出来的，意思是说单个服务的设计，所有参与人从设计、开发、测试、运维所有人加起来 只需要2个披萨就够了 ）。 而所谓服务，一定要区别于系统，服务一个或者一组相对较小且独立的功能单元，是用户可以感知最小功能集。

 

##### 微服务由来

微服务最早由Martin Fowler与James Lewis于2014年共同提出，微服务架构风格是一种使用一套小服务来开发单个应用的方式途径，每个服务运行在自己的进程中，并使用轻量级机制通信，通常是HTTP API，这些服务基于业务能力构建，并能够通过自动化部署机制来独立部署，这些服务使用不同的编程语言实现，以及不同数据存储技术，并保持最低限度的集中式管理。

 

##### 为什么需要微服务？

在传统的IT行业软件大多都是各种独立系统的堆砌，这些系统的问题总结来说就是扩展性差，可靠性不高，维护成本高。到后面引入了SOA服务化，但是，由于 SOA 早期均使用了总线模式，这种总线模式是与某种技术栈强绑定的，比如：J2EE。这导致很多企业的遗留系统很难对接，切换时间太长，成本太高，新系统稳定性的收敛也需要一些时间。最终 SOA 看起来很美，但却成为了企业级奢侈品，中小公司都望而生畏。



#### 早期的单体架构带来的问题

单体架构在规模比较小的情况下工作情况良好，但是随着系统规模的扩大，它暴露出来的问题也越来越多，主要有以下几点：

##### 复杂性逐渐变高

比如有的项目有几十万行代码，各个模块之间区别比较模糊，逻辑比较混乱，代码越多复杂性越高，越难解决遇到的问题。

 

##### 技术债务逐渐上升

公司的人员流动是再正常不过的事情，有的员工在离职之前，疏于代码质量的自我管束，导致留下来很多坑，由于单体项目代码量庞大的惊人，留下的坑很难被发觉，这就给新来的员工带来很大的烦恼，人员流动越大所留下的坑越多，也就是所谓的技术债务越来越多。

 

##### 部署速度逐渐变慢

这个就很好理解了，单体架构模块非常多，代码量非常庞大，导致部署项目所花费的时间越来越多，曾经有的项目启动就要一二十分钟，这是多么恐怖的事情啊，启动几次项目一天的时间就过去了，留给开发者开发的时间就非常少了。

 

##### 阻碍技术创新

比如以前的某个项目使用struts2写的，由于各个模块之间有着千丝万缕的联系，代码量大，逻辑不够清楚，如果现在想用spring mvc来重构这个项目将是非常困难的，付出的成本将非常大，所以更多的时候公司不得不硬着头皮继续使用老的struts架构，这就阻碍了技术的创新。

 

##### 无法按需伸缩

比如说电影模块是CPU密集型的模块，而订单模块是IO密集型的模块，假如我们要提升订单模块的性能，比如加大内存、增加硬盘，但是由于所有的模块都在一个架构下，因此我们在扩展订单模块的性能时不得不考虑其它模块的因素，因为我们不能因为扩展某个模块的性能而损害其它模块的性能，从而无法按需进行伸缩。

 

#### 微服务与单体架构区别

单体架构所有的模块全都耦合在一块，代码量大，维护困难，微服务每个模块就相当于一个单独的项目，代码量明显减少，遇到问题也相对来说比较好解决。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210708093948.png" alt="image-20210708093948274" style="zoom:50%;" />

单体架构所有的模块都共用一个数据库，存储方式比较单一，微服务每个模块都可以使用不同的存储方式（比如有的用redis，有的用mysql等），数据库也是单个模块对应自己的数据库。

 

单体架构所有的模块开发所使用的技术一样，微服务每个模块都可以使用不同的开发技术，开发模式更灵活。

 

#### 微服务的本质

微服务，关键其实不仅仅是微服务本身，而是系统要提供一套基础的架构，这种架构使得微服务可以独立的部署、运行、升级，不仅如此，这个系统架构还让微服务与微服务之间在结构上“松耦合”，而在功能上则表现为一个统一的整体。这种所谓的“统一的整体”表现出来的是统一风格的界面，统一的权限管理，统一的安全策略，统一的上线过程，统一的日志和审计方法，统一的调度方式，统一的访问入口等等。

微服务的目的是有效的拆分应用，实现敏捷开发和部署 。

微服务提倡的理念团队间应该是 inter-operate, not integrate 。inter-operate是定义好系统的边界和接口，在一个团队内全栈，让团队自治，原因就是因为如果团队按照这样的方式组建，将沟通的成本维持在系统内部，每个子系统就会更加内聚，彼此的依赖耦合能变弱，跨系统的沟通成本也就能降低。

 

#### 什么样的项目适合微服务

微服务可以按照业务功能本身的独立性来划分，如果系统提供的业务是非常底层的，如：操作系统内核、存储系统、网络系统、数据库系统等等，这类系统都偏底层，功能和功能之间有着紧密的配合关系，如果强制拆分为较小的服务单元，会让集成工作量急剧上升，并且这种人为的切割无法带来业务上的真正的隔离，所以无法做到独立部署和运行，也就不适合做成微服务了。

 

能不能做成微服务，取决于四个要素：

小：微服务体积小，2 pizza 团队。

独：能够独立的部署和运行。

轻：使用轻量级的通信机制和架构。

松：为服务之间是松耦合的。

 

#### 微服务折分与设计

从单体式结构转向微服务架构中会持续碰到服务边界划分的问题：比如，我们有user 服务来提供用户的基础信息，那么用户的头像和图片等是应该单独划分为一个新的service更好还是应该合并到user服务里呢？如果服务的粒度划分的过粗，那就回到了单体式的老路；如果过细，那服务间调用的开销就变得不可忽视了，管理难度也会指数级增加。目前为止还没有一个可以称之为服务边界划分的标准，只能根据不同的业务系统加以调节。

 

拆分的大原则是当一块业务不依赖或极少依赖其它服务，有独立的业务语义，为超过2个的其他服务或客户端提供数据，那么它就应该被拆分成一个独立的服务模块。

 

#### 微服务设计原则

##### 单一职责原则

意思是每个微服务只需要实现自己的业务逻辑就可以了，比如订单管理模块，它只需要处理订单的业务逻辑就可以了，其它的不必考虑。

 

##### 服务自治原则

意思是每个微服务从开发、测试、运维等都是独立的，包括存储的数据库也都是独立的，自己就有一套完整的流程，我们完全可以把它当成一个项目来对待。不必依赖于其它模块。

 

##### 轻量级通信原则

首先是通信的语言非常的轻量，第二，该通信方式需要是跨语言、跨平台的，之所以要跨平台、跨语言就是为了让每个微服务都有足够的独立性，可以不受技术的钳制。

 

##### 接口明确原则

由于微服务之间可能存在着调用关系，为了尽量避免以后由于某个微服务的接口变化而导致其它微服务都做调整，在设计之初就要考虑到所有情况，让接口尽量做的更通用，更灵活，从而尽量避免其它模块也做调整。

 

#### 微服务优势与缺点

##### 特性

- 每个微服务可独立运行在自己的进程里；

- 一系列独立运行的微服务共同构建起了整个系统；

- 每个服务为独立的业务开发，一个微服务一般完成某个特定的功能，比如：订单管理，用户管理等；

- 微服务之间通过一些轻量级的通信机制进行通信，例如通过REST API或者RPC的方式进行调用。

 

##### 特点

- 易于开发和维护

由于微服务单个模块就相当于一个项目，开发这个模块我们就只需关心这个模块的逻辑即可，代码量和逻辑复杂度都会降低，从而易于开发和维护。

 

- 启动较快

这是相对单个微服务来讲的，相比于启动单体架构的整个项目，启动某个模块的服务速度明显是要快很多的。

 

- 局部修改容易部署

在开发中发现了一个问题，如果是单体架构的话，我们就需要重新发布并启动整个项目，非常耗时间，但是微服务则不同，哪个模块出现了bug我们只需要解决那个模块的bug就可以了，解决完bug之后，我们只需要重启这个模块的服务即可，部署相对简单，不必重启整个项目从而大大节约时间。

 

- 技术栈不受限

比如订单微服务和电影微服务原来都是用java写的，现在我们想把电影微服务改成nodeJs技术，这是完全可以的，而且由于所关注的只是电影的逻辑而已，因此技术更换的成本也就会少很多。

 

- 按需伸缩

上面说了单体架构在想扩展某个模块的性能时不得不考虑到其它模块的性能会不会受影响，对于我们微服务来讲，完全不是问题，电影模块通过什么方式来提升性能不必考虑其它模块的情况。

 

##### 缺点

- 运维要求较高

对于单体架构来讲，我们只需要维护好这一个项目就可以了，但是对于微服务架构来讲，由于项目是由多个微服务构成的，每个模块出现问题都会造成整个项目运行出现异常，想要知道是哪个模块造成的问题往往是不容易的，因为我们无法一步一步通过debug的方式来跟踪，这就对运维人员提出了很高的要求。

 

- 分布式的复杂性

对于单体架构来讲，我们可以不使用分布式，但是对于微服务架构来说，分布式几乎是必会用的技术，由于分布式本身的复杂性，导致微服务架构也变得复杂起来。

 

- 接口调整成本高

比如，用户微服务是要被订单微服务和电影微服务所调用的，一旦用户微服务的接口发生大的变动，那么所有依赖它的微服务都要做相应的调整，由于微服务可能非常多，那么调整接口所造成的成本将会明显提高。

 

- 重复劳动

对于单体架构来讲，如果某段业务被多个模块所共同使用，我们便可以抽象成一个工具类，被所有模块直接调用，但是微服务却无法这样做，因为这个微服务的工具类是不能被其它微服务所直接调用的，从而我们便不得不在每个微服

 

#### 分布式和微服务的区别

<font color='red'>简单的说，微服务是架构设计方式，分布式是系统部署方式，两者概念不同</font>



### SpringCloud介绍（中 20）

#### SpringCloud整体架构概览

子项目简介

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210708094138.png" alt="image-20210708094138045" style="zoom:50%;" />

Spring Cloud为开发人员提供了快速构建分布式系统中一些常见模式的工具（例如配置管理，服务发现，断路器，智能路由，微代理，控制总线，一次性令牌，全局锁，领导选举，分布式会话，集群状态）。分布式系统的协调导致了样板模式, 使用Spring Cloud开发人员可以快速地支持实现这些模式的服务和应用程序。他们将在任何分布式环境中运行良好，包括开发人员自己的笔记本电脑，裸机数据中心，以及Cloud Foundry等托管平台。

 

##### 注意：

首先，尽管Spring Cloud带有“Cloud”这个单词，但它并不是云计算解决方案，而是在Spring Boot基础之上构建的，用于快速构建分布式系统的通用模式的工具集。

 

其次，使用Spring Cloud开发的应用程序非常适合在Docker和PaaS（比如Pivotal Cloud Foundry）上部署，所以又叫做云原生应用（Cloud Native Application）。云原生可以简单地理解为面向云环境的软件架构。

 

##### 特征

- Spring Cloud专注于提供良好的开箱即用经验的典型用例和可扩展性机制覆盖。

- 分布式/版本化配置

- 服务注册和发现(eureka)

- 路由

- service - to - service调用(服务之间的调用)

- 负载均衡

- 断路器

- 全局锁

- Leadership选举与集群状态

- 分布式消息传递

 

#### Spring Cloud与Spring Boot的关系

Spring Boot用来开发项目

Spring Cloud用来管理项目，Spring Cloud管理的项目需要基于Spring Boot来开发

 

#### 版本对应关系

| Spring Cloud             | Spring Boot                                    |
| ------------------------ | ---------------------------------------------- |
| Angel版本                | 兼容Spring Boot 1.2.x                          |
| Brixton版本              | 兼容Spring Boot 1.3.x，也兼容Spring Boot 1.4.x |
| Camden版本               | 兼容Spring Boot 1.4.x，也兼容Spring Boot 1.5.x |
| Dalston版本、Edgware版本 | 兼容Spring Boot 1.5.x，不兼容Spring Boot 2.0.x |
| Finchley版本             | 兼容Spring Boot 2.0.x，不兼容Spring Boot 1.5.x |
| Greenwich版本            | 兼容Spring Boot 2.1.x                          |
| Hoxton版                 | 兼容Spring Boot 2.2.x                          |

在实际开发过程中，我们需要更详细的版本对应：

| Spring Boot   | Spring Cloud            |
| ------------- | ----------------------- |
| 1.5.2.RELEASE | Dalston.RC1             |
| 1.5.9.RELEASE | Edgware.RELEASE         |
| 2.0.2.RELEASE | Finchley.BUILD-SNAPSHOT |
| 2.0.3.RELEASE | Finchley.RELEASE        |
| 2.1.0.RELEASE | Greenwich.SR1           |
| 2.2.0.M4      | Hoxton.SR9              |
| 2.3.7         | Hoxton.BUILD-SNAPSHOT   |
| 2.4.0.M1      | 2020.0.0-M3             |



### 注册中心Eureka（高 45）

#### Eureka简介

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210708094318.png" alt="image-20210708094318867" style="zoom:50%;" />

Spring Cloud Eureka 是对Netflix公司的Eureka的二次封装，它实现了服务治理的功能，Spring Cloud Eureka提供服务端与客户端，服务端即是Eureka服务注册中心，客户端完成微服务向Eureka服务的**注册与发现**。服务端和客户端均采用Java语言编写。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210708094333.png" alt="image-20210708094332946" style="zoom:50%;" />

一个消费者和一个生产者

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210708094343.png" alt="image-20210708094343420" style="zoom:50%;" />

多个消费者与多个生产者

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210708094354.png" alt="image-20210708094354721" style="zoom:50%;" />

下图显示了Eureka Server与Eureka Client的关系

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210708094404.png" alt="image-20210708094404737" style="zoom:50%;" />

- Eureka Server是服务端，负责管理各个微服务结点的信息和状态。

- 在微服务上部署Eureka Client程序，远程访问Eureka Server将自己注册在Eureka Server。

- 微服务需要调用另一个微服务时从Eureka Server中获取服务调用地址，进行远程调用。

 

#### 原理：

- 服务提供方启动后将注册到注册中心，提供IP, 名字，什么服务等信息，

- 服务调用方作为客户端注册到注册中心后，拉取注册中心的服务列表，在通过负载均衡调用对应的服务提供方。

- 注册中心可以建立集群，生成多台eureka，注册中心为了监测各个服务的心跳，将在每30S 向所注册的服务发起请求判断

- 服务是否挂掉，如果挂掉90S后将会将服务从注册中心剔除。

- 一个服务可以监测多台服务实例，从而可实现均衡负载。



#### 创建父项目

##### 创建Maven项目

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210708094436.png" alt="image-20210708094436160" style="zoom: 50%;" />

指定项目名、gid、版本

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210708094458.png" alt="image-20210708094458481" style="zoom: 50%;" />

删除父项目的src目录

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210708094747.png" alt="image-20210708094747249" style="zoom: 33%;" />

在父项目的pom.xml中指定打包方式为**<font color='red'>pom</font>**方式

```xml
<groupId>com.woniuxy</groupId>
<artifactId>springcloud-teach</artifactId>
<version>1.0</version>

<packaging>pom</packaging>
```


#### 创建子项目

在父项目名上右键->new->module，创建子项目

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210708094943.png" alt="image-20210708094943046" style="zoom: 33%;" />

选择springboot项目

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210708095037.png" alt="image-20210708095037115" style="zoom: 33%;" />

指定gid、aid、version

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210708095151.png" alt="image-20210708095151395" style="zoom:33%;" />

导入eureka server依赖，选择对应springboot版本

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210802114600.png" alt="image-20210802114600646" style="zoom:33%;" />



在子项目eureka-server的pom.xml中指定父项目

```xml
<parent>
   <artifactId>springcloud-teach</artifactId>
   <groupId>com.woniuxy</groupId>
   <version>1.0</version>
</parent>
    
<modelVersion>4.0.0</modelVersion>
```



在父项目的pom.xml中指定子模块

```xml
<packaging>pom</packaging>

<modules>
    <module>eureka-server</module>
</modules>
```



将eureka-server的主配置文件改为yml格式，并配置以下内容  **<font color='red'>eureka默认端口号为8761</font>**

```yaml
server:
  port: 9001
eureka:
  instance:
    hostname: localhost
  client:
    register-with-eureka: false   #false表示不向注册中心注册自己
    fetch-registry: false   #false表示自己就是注册中心，不需要从注册中心获取注册列表信息
    service-url:
      defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/
```

##### 配置说明：

​	register-with-eureka: false	<font color='red'>false表示不向注册中心注册自己</font>

​	fetch-registry: false			 <font color='red'>false表示自己就是注册中心，不需要从注册中心获取注册列表信息</font>

​	service-url					<font color='red'>设置eureka server交互的地址查询服务和注册服务都需要用到这个地址（单机用）</font>



在eureka-server的主启动类上开启eureka服务**<font color='red'>@EnableEurekaServer</font>**

```java
@SpringBootApplication
@EnableEurekaServer
public class EurekaServerApplication {
    public static void main(String[] args) {
        SpringApplication.run(EurekaServerApplication.class, args);
    }
}
```



启动eureka-server子项目，在浏览器上访问localhost:9001

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210708101053.png" style="zoom: 25%;" />



### 搭建Eureka Client（高 20）


在父项目上再创建一个provider子模块，导入**<font color='red'>Eureka Discovery Client、Spring Web</font>**依赖

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210708103648.png" style="zoom:33%;" />

在provider的pom中配置父项目

```xml
<parent>
   <artifactId>springcloud-teach</artifactId>
   <groupId>com.woniuxy</groupId>
   <version>1.0</version>
</parent>
    
<modelVersion>4.0.0</modelVersion>
```



在父项目的pom.xml中配置子模块

```xml
<modules>
   <module>eureka-server</module>
   <module>provider</module>
</modules>
```



在provider子项目的主配置文件中配置以下信息

```yaml
server:
  port: 8080
eureka:
  client: #客户端注册到eureka列表中
    service-url:
      defaultZone: http://127.0.0.1:9001/eureka
  instance:
    instance-id: provider-8080  #注册中心显示出来的微服务名称
    prefer-ip-address: true #显示访问url
spring:
  application:
    name: provider

```

**<font color='red'>注意：service-url使用IP地址，最好不要使用localhost</font>**



在provider的主启动类上开启eureka-client功能**<font color='red'>@EnableEurekaClient</font>**

```java
@SpringBootApplication
@EnableEurekaClient
public class ProviderApplication {
    public static void main(String[] args) {
        SpringApplication.run(ProviderApplication.class, args);
    }
}
```



启动provider模块，然后到eureka控制台查看注册情况

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210708104232.png" alt="image-20210708104232021" style="zoom: 25%;" />

#### 常见概念

##### Register	服务注册

当Eureka客户端向Eureka Server注册时，它提供自身的元数据，比如IP地址、端口，运行状况指示符URL，主页等。

 

##### Renew	服务续约（心跳机制）

Eureka客户会每隔30秒发送一次心跳来续约。通过续约来告知Eureka Server该Eureka客户仍然存在，没有出现问题。正常情况下，如果Eureka Server在90秒没有收到Eureka客户的续约，它会将实例从其注册表中删除。建议不要更改续约间隔。

- 心跳机制是每隔30秒发送一个自定义的结构体(心跳包)，让对方知道自己还活着，以确保连接的有效性的机制。

- 心跳机制是每隔30秒发送一个固定信息给服务端，服务端收到后回复一个固定的信息。如果服务端90秒内没有收到客户端消息则视客户端断开。

- 发送方可以是客户端或服务端，根据实际情况，一般是客户端；因为一个服务端可能有很多客户端，服务端作为发送方的比较耗费性能。

 

在provider微服务的application.yml配置心跳时间和下线时间

```yaml
server:
  port: 8080
eureka:
  client: #客户端注册到eureka列表中
    service-url:
      defaultZone: http://127.0.0.1:9001/eureka
  instance:
    instance-id: provider-8080  #注册中心显示出来的微服务名称
    prefer-ip-address: true #显示访问url
    lease-renewal-interval-in-seconds: 20   #心跳时间
    lease-expiration-duration-in-seconds: 60 #下线时间
```



心跳信息可以从eureka微服务的控制台看到

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210715151123.png" alt="image-20210715151122927" style="zoom: 33%;" />

要看到信息，可以在eureka微服务的application.yml中设置日志级别为debug

```yaml
logging:
  level:
    root: debug
```

也可以在provider的application.yml设置日志级别，观察provider发送服务续约请求信息

```yaml
logging:
  level:
    root: debug
```



##### Fetch Registries	获取注册列表信息

Eureka客户端从服务器获取注册表信息，并将其缓存在本地。客户端会使用该信息查找其他服务，从而进行远程调用。该注册列表信息定期（每30秒钟）更新一次。每次返回注册列表信息可能与Eureka客户端的缓存信息不同， Eureka客户端自动处理。如果由于某种原因导致注册列表信息不能及时匹配，Eureka客户端则会重新获取整个注册表信息。 Eureka服务器缓存注册列表信息，整个注册表以及每个应用程序的信息进行了压缩，压缩内容和没有压缩的内容完全相同。Eureka客户端和Eureka 服务器可以使用JSON / XML格式进行通讯。在默认的情况下Eureka客户端使用压缩JSON格式来获取注册列表的信息。

 

##### Cancel		服务下线

Eureka客户端在程序关闭时向Eureka服务器发送取消请求，发送请求后，该客户端实例信息将从服务器的实例注册表中删除，该下线请求不会自动完成，它需要调用以下内容：

DiscoveryManager.getInstance().shutdownComponent()；

 

##### Eviction  服务剔除

在默认的情况下，当Eureka客户端连续90秒没有向Eureka服务器发送服务续约（心跳），Eureka服务器会将该服务实例从服务注册列表删除，即服务剔除。



### RestTemplate使用（中 30）

RestTmeplate使用GET、POST、PUT、DELETE请求方法

#### 实体类

 在provider子模块中添加Goods实体类及GoodsController接口

```java
@Data
@AllArgsConstructor
@NoArgsConstructor
@Accessors(chain = true)
public class Goods {
    private int id;
    private String name;
}
```

#### controller

```java
@RestController
public class GoodsController {
    @RequestMapping("/all")
    public List<Goods> all(){
        return Arrays.asList(
                new Goods(1001,"手机"),
                new Goods(1002,"电脑")
        );
    }
}
```

#### 实体类

在consumer子模块中添加goods实体类、RestTemplate配置类及controller

```java
@Data
@AllArgsConstructor
@NoArgsConstructor
@Accessors(chain = true)
public class Goods {
    private int id;
    private String name;
}
```

##### 配置类

```java
@Configuration
public class WebConfiguration {
    @Bean
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }
}
```

##### controller

```java
@RestController
public class ConsumerController {
    @Resource
    private RestTemplate restTemplate;

    @RequestMapping("/all")
    public List<Goods> all(){
        String url = "http://127.0.0.1:8080/all";
        //
        List<Goods> goods = restTemplate.getForObject(url,List.class);
        //
        return goods;
    }
}
```

先后启动provider、consumer两个子模块，一般情况下先启动被调用方


##### 测试

在浏览器中访问consumer中的接口

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210714172935.png" alt="image-20210714172934889" style="zoom: 25%;" />

得到数据说明OK



#### GET请求（restful）

##### 不带参数

```java
@GetMapping("/all")
public List<Goods> all(){
    String url = "http://127.0.0.1:8080/all";
    //
    List<Goods> goods = restTemplate.getForObject(url,List.class);
    //
    return goods;
}
```

##### 带参数（<font color='red'>restful风格</font>）

在provider模块controller添加以下接口

```java
@GetMapping("find/{id}")
public Goods findById(@PathVariable("id") int id){
    System.out.println(id);
    return new Goods(1003,"平板");
}
```

在consumer 的controller中添加接口

```java
@RequestMapping("/find")
public Goods find(){
    String url = "http://127.0.0.1:8080/find/1003";
    Goods goods = restTemplate.getForObject(url,Goods.class);
    return goods;
}
```



#### POST请求（restful）

##### 在provider的controller中添加接口，注意接收参数时需要加**<font color="red">@RequestBody</font>**注解

```java
@PostMapping("/add")
    public ResponseResult<Boolean> add(@RequestBody Goods goods){
        System.out.println(goods);
        //
        return new ResponseResult<>(200,"success",true);
    }
```

##### 在consumer的controller中添加接口

```java
@RequestMapping("/add")
    public ResponseResult<Boolean> add(){
        String url = "http://127.0.0.1:8080/add";
        //
        Goods goods = new Goods(1004,"耳机");
        //
        ResponseResult<Boolean> result = 
            restTemplate.postForObject(url,goods,ResponseResult.class);
        //
        return result;
    }
```



#### PUT请求（restful）

**<font color='red'>注意PUT请求没有返回值</font>**

##### 在provider的controller中添加接口

```java
@PutMapping("/update")
public void update(@RequestBody Goods goods){
    System.out.println(goods);
}
```

##### 在consumer的controller中添加接口

```java
@RequestMapping("/update")
public void update(){
    String url = "http://127.0.0.1:8080/update";
    //
    Goods goods = new Goods(1005,"手表");

    //PUT请求没有返回值
    restTemplate.put(url,goods);
}
```



#### DELETE请求（restful）

**<font color='red'>注意DELETE请求也没有返回值</font>**

##### 在provider的controller中添加接口

```java
@DeleteMapping("/del/{id}")
public void del(@PathVariable("id") int id){
    System.out.println(id);
}
```

##### 在consumer的controller中添加接口

```java
@RequestMapping("/del")
public void del(){
    String url = "http://PROVIDER/del/1006";
    restTemplate.delete(url);
}
```



#### provider集群

再开启一个provider服务器

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210714172353.png" alt="image-20210714172353486" style="zoom: 50%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210714172449.png" alt="image-20210714172449021" style="zoom:50%;" />



<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210714174822.png" alt="image-20210714174822010" style="zoom:33%;" />

-Dserver.port=8081 -Deureka.instance.instance-id=provider-8081



#### 负载均衡器

在consumer的WebConfiguration配置类中，在创建RestTemplate对象的方法上添加 **<font color='red'>@LoadBalanced</font>**注解，开启负载均衡器

```java
@Configuration
public class WebConfiguration {
    @Bean
    @LoadBalanced
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }
}
```

将consumer接口方法中url的ip地址改为provider子模块的名字

```java
String url = "http://PROVIDER/all";
String url = "http://PROVIDER/find/1003";
String url = "http://PROVIDER/add";
String url = "http://PROVIDER/update";
```


##### controller

在provider的controller上添加以下代码获取到当前项目端口号，并在all方法中打印

**<font color='red'>@Value("${server.port}")</font>**

```java
@RestController
public class GoodsController {
    @Value("${server.port}")
    private String port;
    @GetMapping("/all")
    public List<Goods> all(){
        System.out.println(port);
        return Arrays.asList(
                new Goods(1001,"手机"),
                new Goods(1002,"电脑")
        );
    }
}
```

### Ribbon负载均衡（中 30）

#### 负载均衡策略

 常见负载均衡策略

| 策略                                               | 解释                                                         |
| -------------------------------------------------- | ------------------------------------------------------------ |
| com.netflix.loadbalancer.RandomRule                | 随机，在服务实例中随机选择请求                               |
| com.netflix.loadbalancer.RoundRobinRule            | 轮询，根据服务列表轮流请求                                   |
| com.netflix.loadbalancer.RetryRule                 | 在RoundRobinRule的基础上添加重试机制，即在指定的重试时间内，反复使用线性轮询策略来选择可用实例 |
| com.netflix.loadbalancer.WeightedResponseTimeRule  | 对RoundRobinRule的扩展，响应速度越快的实例选择权重越大，越容易被选择 |
| com.netflix.loadbalancer.BestAvailableRule         | 选择并发较小的实例                                           |
| com.netflix.loadbalancer.AvailabilityFilteringRule | 先过滤掉故障实例，再选择并发较小的实例                       |
| com.netflix.loadbalancer.ZoneAwareLoadBalancer     | 采用双重过滤，同时过滤不是同一区域的实例和故障实例，选择并发较小的实例 |

#### 全局设置

在WebConfiguration配置类中通过代码方式指定

```java
//全局设置负载均衡策略
@Bean
public IRule rule(){
    return new RandomRule();
}

```

#### 



# day02

### Ribbon配置（中 30）

Ribbon的常用配置、全局配置、指定服务进行配置

 <img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210708121320.jpg" alt="img" style="zoom:33%;" />

Ribbon是一个基于HTTP和TCP客户端的负载均衡器，默认使用轮询的方式

SpringCloud Ribbon是基于Netfix Ribbon实现的一套客户端负载均衡工具



**导入了eureka就导入了ribbon，不需要单独再导入**

#### 开启ribbon

在application.yml文件中开启ribbon

```yaml
ribbon:
  eureka:
    enabled: true #开启ribbon，并从eureka中获取其它微服务信息
```


#### 全局配置

修改consumer的配置类WebConfiguration，全局配置ribbon

```java
@Configuration
public class WebConfiguration {
    @Bean
    @LoadBalanced
    public RestTemplate restTemplate(){
        //全局设置超时时间
        SimpleClientHttpRequestFactory factory = new SimpleClientHttpRequestFactory();
        factory.setReadTimeout(1000);       //读取超时时间  默认1秒
        factory.setConnectTimeout(2000);    //连接超时时间  默认1秒
        //
        return new RestTemplate(factory);
    }
}
```

参考：org.springframework.cloud.netflix.ribbon.RibbonClientConfiguration.ribbonClientConfig()方法


#### 局部配置

也可以在调用方的application.yml中对某个微服务进行局部设置

```yaml
#局部配置有效
provider:   #微服务名字
  ribbon:
    ReadTimeout: 1000 
    ConnectTimeout: 1000 
```



#### ribbon重试机制

##### 导入依赖

```xml
<dependency>
    <groupId>org.springframework.retry</groupId>
    <artifactId>spring-retry</artifactId>
</dependency>
```

##### 开启重试

在主启动类上添加**<font color='red'>@EnableRetry</font>**注解开启重试机制

```java
@SpringBootApplication
@EnableEurekaClient
@EnableRetry
public class ConsumerApplication {

    public static void main(String[] args) {
        SpringApplication.run(ConsumerApplication.class, args);
    }

}
```

##### 指定策略

在application.yml中指定全局重试策略

```yaml
ribbon:
  eureka:
    enabled: true #开启ribbon，并从eureka中获取其它微服务信息
  MaxAutoRetries: 1 # 切换实例后重试最大次数 默认0
  OkToRetryOnAllOperations: true #对所有超时的请求启用重试机制  默认false
  MaxAutoRetriesNextServer: 1 #切换重试实例的最大个数  默认1
```

也可以在单个微服务下单独设置

```yaml
#局部配置有效
provider:   #微服务名字
  ribbon:
    ReadTimeout: 1000
    ConnectTimeout: 1000
    MaxAutoRetries: 1 # 切换实例后重试最大次数 默认0
    OkToRetryOnAllOperations: true #对所有超时的请求启用重试机制  默认false
    MaxAutoRetriesNextServer: 1 #切换重试实例的最大个数  默认1
```



**具体配置参考类：com.netflix.client.config.DefaultClientConfigImpl**



### Ribbon负载均衡（中 30）

#### 负载均衡策略

 常见负载均衡策略

| 策略                                               | 解释                                                         |
| -------------------------------------------------- | ------------------------------------------------------------ |
| com.netflix.loadbalancer.RandomRule                | 随机，在服务实例中随机选择请求                               |
| com.netflix.loadbalancer.RoundRobinRule            | 轮询，根据服务列表轮流请求                                   |
| com.netflix.loadbalancer.RetryRule                 | 在RoundRobinRule的基础上添加重试机制，即在指定的重试时间内，反复使用线性轮询策略来选择可用实例 |
| com.netflix.loadbalancer.WeightedResponseTimeRule  | 对RoundRobinRule的扩展，响应速度越快的实例选择权重越大，越容易被选择 |
| com.netflix.loadbalancer.BestAvailableRule         | 选择并发较小的实例                                           |
| com.netflix.loadbalancer.AvailabilityFilteringRule | 先过滤掉故障实例，再选择并发较小的实例                       |
| com.netflix.loadbalancer.ZoneAwareLoadBalancer     | 采用双重过滤，同时过滤不是同一区域的实例和故障实例，选择并发较小的实例 |

#### 全局设置

在WebConfiguration配置类中通过代码方式指定

```java
//全局设置负载均衡策略
@Bean
public IRule rule(){
    return new RandomRule();
}
```

#### 局部设置

**<font color='red'>注意：全局与局部同时存在，ribbon优先使用全局设置，因此需要先注释掉全局设置才有用</font>**

```yaml
#局部配置有效
provider:   #微服务名字
  ribbon:
#    ReadTimeout: 1000
#    ConnectTimeout: 1000
#    MaxAutoRetries: 1 # 切换实例后重试最大次数 默认0
#    OkToRetryOnAllOperations: true #对所有超时的请求启用重试机制  默认false
#    MaxAutoRetriesNextServer: 1 #切换重试实例的最大个数  默认1
    NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RoundRobinRule

```



### 公共模块

公共模块中定义各个子模块中共同的类，方便维护

#### 在父项目名上右键新建maven项目

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210715152700.png" alt="image-20210715152700234" style="zoom: 33%;" />

##### 指定项目名字

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210715152735.png" alt="image-20210715152734971" style="zoom: 33%;" />

##### 在公共模块的pom.xml中导入lombok依赖，**并指定打包方式为jar包**

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <parent>
        <artifactId>springcloud-teach</artifactId>
        <groupId>com.woniuxy</groupId>
        <version>1.0</version>
    </parent>
    <modelVersion>4.0.0</modelVersion>
    <packaging>jar</packaging>

    <artifactId>commons</artifactId>
    <dependencies>
        <dependency>
            <groupId>org.projectlombok</groupId>
            <artifactId>lombok</artifactId>
            <version>1.18.20</version>
        </dependency>
    </dependencies>
</project>

```

##### 创建Goods实体类

```java
@Data
@AllArgsConstructor
@NoArgsConstructor
@Accessors(chain = true)
public class Goods {
    private int id;
    private String name;
}

```

目录结构如下

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210715155016.png" alt="image-20210715155016857" style="zoom:50%;" />

##### 将commons打包

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210715155132.png" alt="image-20210715155132415" style="zoom: 50%;" />

##### 在provider、consumer模块的pom.xml中分别引入commons模块

```xml
<!--导入公共模块-->
<dependency>
     <groupId>com.woniuxy</groupId>
     <artifactId>commons</artifactId>
     <version>1.0</version>
</dependency>

```

##### 将provider、consumer的controller中使用的Goods更换成commons模块中的Goods



##### 测试

**ResponseResult按照同样的方式提取到commons模块中**



**<font color='red'>注意：只要在commons中做了修改，请立即将commons进行打包，如果不打包其它模块无法得到最新的更改</font>**



### OpenFeign声明式通信（中 15）

#### 声明式通信

 <img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210715152316.png" alt="image-20210715152316596" style="zoom:50%;" />

之前我们通过RestTemplate调用其它服务的API时，所需要的参数须在请求的URL中进行拼接，如果参数少的话或许我们还可以忍受，一旦有多个参数的话，这时拼接请求字符串就会效率低下。

 

那么有没有更好的解决方案呢？答案是确定的有，Netflix已经为我们提供了一个框架：Feign。

 

Feign是一个声明式的Web Service客户端，它的目的就是让Web Service调用更加简单。Feign提供了HTTP请求的模板，通过编写简单的接口和插入注解，就可以定义好HTTP请求的参数、格式、地址等信息。

 

而Feign则会完全代理HTTP请求，我们只需要像调用方法一样调用它就可以完成服务请求及相关处理。Feign整合了Ribbon和Hystrix(关于Hystrix我们后面再讲)，可以让我们不再需要显式地使用这两个组件。

 

总起来说，Feign具有如下特性：

- 可插拔的注解支持，包括Feign注解和JAX-RS注解;

- 支持可插拔的HTTP编码器和解码器;

- 支持Hystrix和它的Fallback;

- 支持Ribbon的负载均衡;

- 支持HTTP请求和响应的压缩。



#### 创建consumer-feign子模块



<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210715155655.png" alt="image-20210715155655429" style="zoom: 33%;" />

##### 导入web、eureka依赖

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210715155813.png" alt="image-20210715155813007" style="zoom:33%;" />

##### 在consumer-feign的pom.xml中指定父项目

```xml
<parent>
    <artifactId>springcloud-teach</artifactId>
    <groupId>com.woniuxy</groupId>
    <version>1.0</version>
</parent>

```

##### 在父项目中引入子模块

```xml
<modules>
    <module>eureka-server</module>
    <module>provider</module>
    <module>consumer</module>
    <module>commons</module>
    <module>consumer-feign</module>
</modules>

```

##### 在父项目中导入openfeign依赖

```xml
<dependencyManagement>
    <dependencies>
        <dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-openfeign-core</artifactId>
            <version>2.1.3.RELEASE</version>
        </dependency>
    </dependencies>
</dependencyManagement>

```

##### 在consumer-feign的pom.xml中导入feign依赖和公共模块

```xml
<!--openfeign-->
<dependency>
     <groupId>org.springframework.cloud</groupId>
     <artifactId>spring-cloud-openfeign-core</artifactId>
</dependency>
<!--公共模块-->
<dependency>
     <groupId>com.woniuxy</groupId>
     <artifactId>commons</artifactId>
     <version>1.0</version>
</dependency>

```



##### 编辑application.yml配置feign

```yaml
spring:
  application:
    name: consumer-feign
server:
  port: 80
ribbon:
  eureka:
    enabled: true
eureka:
  client:
    service-url:
      defaultZone: http://127.0.0.1:9001/eureka
  instance:
    instance-id: consumer-feign  #注册中心显示出来的微服务名称

```



##### 在commons模块中导入openfeign依赖、并创建service接口

**<font color='red'>spring-cloud-starter-openfeign</font>**

```xml
<!--openfeign-->
<dependency>
     <groupId>org.springframework.cloud</groupId>
     <artifactId>spring-cloud-starter-openfeign</artifactId>
</dependency>

```



##### 添加openfeign接口

```java
package com.commons.service;

import com.commons.entity.Goods;
import com.commons.result.ResponseResult;
import org.springframework.cloud.openfeign.FeignClient;
import org.springframework.web.bind.annotation.*;

import java.util.List;

//指定调用微服务的名字
@FeignClient(name = "PROVIDER")
public interface ProviderService {
    //接口与被调用的controller一致
    @GetMapping("/all")
    public List<Goods> all();
}

```

**<font color='red'>将commons模块重新打包</font>**



##### 在consumer-feign中创建controller，并注入service

```java
@RestController
public class FeignController {
    @Resource
    private ProviderService providerService;

    //接口与被调用的controller一致
    @GetMapping("/all")
    public List<Goods> all(){
        return providerService.all();
    }
}

```



##### 在consumer-feign的主启动类上开启eureka和openfeign

```java
@SpringBootApplication
@EnableEurekaClient
@EnableFeignClients(basePackages = "com.commons.service")
public class ConsumerFeignApplication {

    public static void main(String[] args) {
        SpringApplication.run(ConsumerFeignApplication.class, args);
    }

}

```

basePackages扫描openfeign service所在的包



**分别按顺序启动eureka、provider、consumer-feign**

如果在运行过程中报loadbalancer xxx错误，是由于eureka开启了负载均衡器ribbon造成的，可以在调用方添加以下设置关闭ribbon

```yaml
spring:
  cloud:
    loadbalancer:
      ribbon:
        enabled: false  #关闭负载均衡器

```



### OpenFeign请求传递对象（高 30）

#### 在commons模块的ProviderService接口中添加以下方法

```java
@FeignClient(name = "PROVIDER")
public interface ProviderService {
    //接口与被调用的controller一致
    @GetMapping("/all")
    public List<Goods> all();

    @GetMapping("find/{id}")
    public Goods findById(@PathVariable("id") int id);

    @PostMapping("/add")
    public ResponseResult<Boolean> add(@RequestBody Goods goods);

    @PutMapping("/update")
    public void update(@RequestBody Goods goods);

    @DeleteMapping("/del/{id}")
    public void del(@PathVariable("id") int id);
}

```

##### <font color="red">将commons模块重新打包</font>

#### 在consumer-feign的controller类上添加对应的方法

```java
@RestController
public class FeignController {
    @Resource
    private ProviderService providerService;

    //接口与被调用的controller一致
    @GetMapping("/all")
    public List<Goods> all(){
        return providerService.all();
    }

    @GetMapping("find/{id}")
    public Goods findById(@PathVariable("id") int id){
        return providerService.findById(id);
    }

    @PostMapping("/add")
    public ResponseResult<Boolean> add(@RequestBody Goods goods){
        return providerService.add(goods);
    }

    @PutMapping("/update")
    public void update(@RequestBody Goods goods){
        providerService.update(goods);
    }

    @DeleteMapping("/del/{id}")
    public void del(@PathVariable("id") int id){
        providerService.del(id);
    }
}

```



##### 运行程序通过postman进行测试

postman发送json

1、选择请求方式、设置请求头

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210715205729.png" alt="image-20210715205729068" style="zoom: 33%;" />

2、设置body的编码方式为raw，application/json,  raw是发送纯文本，不包含任何空格的编码方式

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210715205833.png" alt="image-20210715205833518" style="zoom: 33%;" />



### OpenFeign配置（高 20）

#### 负载均衡

openfeign 默认采用ribbon为负载均衡器，可以在配置类中指定负载均衡策略

```java
@Configuration
public class RibbonConfiguration {

    @Bean
    public IRule rule(){
        return new RandomRule();
    }
}

```



#### feign通信日志

Feign 提供了日志打印功能，可以通过配置来调整日志级别，从而了解 Feign 中 Http 请求的细节。

说白了就是对接口的调用情况进行监控和输出。

 

##### 日志级别

| 级别    | 解释                                                        |
| ------- | ----------------------------------------------------------- |
| NONE    | 默认的，不显示任何日志                                      |
| BASIC   | 仅记录请求方法、URL、响应状态码及执行时间                   |
| HEADERS | 除了 BASIC 中定义的信息之外，还有请求和响应的头信息         |
| FULL    | 除了 HEADERS 中定义的信息之外，还有请求和响应的正文及元数据 |

 

在consumer-feign中添加feign日志配置类，指定日志输出级别以显示指定的内容

注意Level的包为：**feign.Logger**

```java
import feign.Logger;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class LogConfiguration {
    @Bean
    public Logger.Level level(){
        return Logger.Level.FULL;
    }
}

```

因为feign日志的输出级别都是debug级别，因此如果想要看到日志信息，还需要设置service包的日志级别

```yaml
logging:
  level:
    com.commons.service: debug

```

运行consumer-feign，在其控制台会显示以下信息

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210715202905.png" alt="image-20210715202905651" style="zoom:33%;" />



### Hystrix概述（中 15）

Hystrix简介、雪崩效应与熔断机制

#### 雪崩效应

在微服务架构中通常会有多个服务层调用，基础服务的故障可能会导致级联故障，进而造成整个系统不可用的情况，这种现象被称为服务雪崩效应。服务雪崩效应是一种因“服务提供者"的不可用导致“服务消费者”的不可用，并将不可用逐渐放大的过程。

如果下图所示: A作为服务提供者，B为A的服务消费者，C和D是B的服务消费者。A不可用引起了B的不可用，并将不可用像滚雪球一样放大到C和D时，雪崩效应就形成了。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210715210009.png" alt="image-20210715210009270" style="zoom: 67%;" />

服务雪崩的过程可以分为三个阶段：

a）服务提供者不可用

b）重试加大请求流量

c）服务调用者不可用

 

应对策略：

a）应用扩容，包括增加机器数量、升级硬件规格等

b）流量控制，限流、关闭重试

c）缓存，缓存预加载

d）服务降级，服务接口拒绝服务、页面拒绝服务、延迟持久化、随机拒绝服务

e）服务熔断



#### 熔断器（Hystrix）

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210715210124.png" alt="image-20210715210124778" style="zoom: 67%;float: left;" />

在分布式系统中，单个应用通常会有多个不同类型的外部依赖服务，内部通常依赖于各种RPC服务，外部则依赖于各种HTTP服务。这些依赖服务不可避免的会出现调用失败，比如超时、异常等情况，如何在外部依赖出问题的情况，仍然保证自身应用的稳定，就是Hystrix这类服务保障框架的工作了。

 

Hystrix是一个用于分布式系统的延迟和容错的开源库。在分布式系统里，许多依赖不可避免的调用失败，比如超时、异常等，Hystrix能够保证在一个依赖出问题的情况下，不会导致整个服务失败，避免级联故障，以提高分布式系统的弹性。

 

生活中举个例子，如电力过载保护器，当电流过大的时候，出问题，过载器会自动断开，从而保护电器不受烧坏。因此Hystrix请求熔断的机制跟电力过载保护器的原理很类似。

 

举个例子来说，某个应用中依赖了30个外部服务，实际应用中通常比这还要多，假设每个服务的可用性为99.99%，4个9的可用性，算是不错了，但99.99%的30次幂≈ 99.7%，也就是有0.3%的请求不可用，假设总共有1亿次请求，那么就意味着有300万次请求会失败，如果一切正常每个月就有2个小时服务是不可用的。

 

现实通常是更糟糕

当一切正常时，请求看起来是这样的

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210715210437.png" alt="image-20210715210436869" style="zoom:67%;" />

当其中有一个系统有延迟时，它可能阻塞整个用户请求：

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210715210455.png" alt="image-20210715210455534" style="zoom:67%;" />

在高流量的情况下，一个后端依赖项的延迟可能导致所有服务器上的所有资源在数秒内饱和（PS：意味着后续再有请求将无法立即提供服务）

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210715210511.png" alt="image-20210715210511685" style="zoom:67%;" />

#### Hystrix设计原则是什么

·防止任何单个依赖项耗尽所有容器（如Tomcat）用户线程。

·甩掉包袱，快速失败而不是排队。

·在任何可行的地方提供回退，以保护用户不受失败的影响。

·使用隔离技术（如隔离板、泳道和断路器模式）来限制任何一个依赖项的影响。

·通过近实时的度量、监视和警报来优化发现时间。

·通过配置的低延迟传播来优化恢复时间。

·支持对Hystrix的大多数方面的动态属性更改，允许使用低延迟反馈循环进行实时操作修改。

·避免在整个依赖客户端执行中出现故障，而不仅仅是在网络流量中。



#### Fallback

Fallback相当于是降级操作。对于查询操作,我们可以实现一个fallback方法，当请求后端服务出现异常的时候,可以使用fallback方法返回的值。fallback方法的返回值一般是设置的默认值或者来自缓存。

 

·资源隔离

在Hystrix中,主要通过线程池来实现资源隔离。通常在使用的时候我们会根据调用的远程服务划分出多个线程池。例如调用产品服务的Command放入A线程池，调用账户服务的Command放入B线程池。这样做的主要优点是运行环境被隔离开了。这样就算调用服务的代码存在bug或者由于其他原因导致自己所在线程池被耗尽时，不会对系统的其他服务造成影响。但是带来的代价就是维护多个线程池会对系统带来额外的性能开销。如果是对性能有严格要求而且确信自己调用服务的客户端代码不会出问题的话，可以使用Hystrix的信号模式(Semaphores)来隔离资源。



### RestTemplate与Hystrix整合（低 20）

#### 在**<font color='red'>consumer</font>**模块中导入hystrix依赖

注：hystrix导入的依赖如下

```xml
<!--hystrix-->
<dependency>
     <groupId>org.springframework.cloud</groupId>
     <artifactId>spring-cloud-starter-netflix-hystrix</artifactId>
</dependency>

```

#### 再导入公共模块

```xml
<!--公共模块-->
<dependency>
    <groupId>com.woniuxy</groupId>
    <artifactId>commons</artifactId>
    <version>1.0</version>
</dependency>

```



#### 在主启动类上添加**<font color="red">@EnableCircuitBreaker</font>**注解开启熔断器

```java
@SpringBootApplication
@EnableEurekaClient
@EnableRetry
@EnableCircuitBreaker  //开启降级
public class ConsumerApplication {

    public static void main(String[] args) {
        SpringApplication.run(ConsumerApplication.class, args);
    }

}

```



#### 在controller需要保护的方法上添加**<font color="red">@HystrixCommand</font>**注解，并指定fallback方法

```java
@RestController
public class ConsumerController {
    @Resource
    private RestTemplate restTemplate;

    @RequestMapping("/all")
    @HystrixCommand(fallbackMethod = "fallback")
    public List<Goods> all(){
        String url = "http://PROVIDER/all";
        //
        List<Goods> goods = restTemplate.getForObject(url,List.class);
        //
        return goods;
    }
    //返回值、参数必须与对应的方法保持一致
    public List<Goods> fallback(){

        List<Goods> goods = Arrays.asList(
                new Goods(4001,"fallbackA"),
                new Goods(4002,"fallbackB")
        );
        //
        return goods;
    }
}

```

#### 启动eureka、consumer模块，然后访问all方法，得到以下结果表示成功

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210715214749.png" alt="image-20210715214749221" style="zoom:50%;" />



### OpenFeign与Hystrix整合（高 20）

#### 服务降级

<font color='red'>巨坑：一定要确保Comsumer的依赖中不要自己再导入ribbon了，如果有则删除，因为feign其实已经集成了ribbon，而我们导入的ribbon将feign中的ribbon给覆盖了，而我们又没有给新的ribbon指定http请求、超时时间等配置原因导致的，所以在使用feign调用微服务时就不要再自己引入ribbon，反而破坏了feign与ribbon的整合关系。</font>

 

什么是服务降级？当服务器压力剧增的情况下，根据实际业务情况及流量，对一些服务和页面有策略的不处理或换种简单的方式处理，从而释放服务器资源以保证核心交易正常运作或高效运作。

 

如果还是不理解，那么可以举个例子：假如目前有很多人想要给我付钱，但我的服务器除了正在运行支付的服务之外，还有一些其它的服务在运行，比如搜索、定时任务和详情等等。然而这些不重要的服务就占用了JVM的不少内存与CPU资源，为了能把钱都收下来（钱才是目标），我设计了一个动态开关，把这些不重要的服务直接在最外层拒掉，这样处理后的后端处理收钱的服务就有更多的资源来收钱了（收钱速度更快了），这就是一个简单的服务降级的使用场景。

 

所谓降级，就是一般是从整体层面考虑，就是当某个服务熔断之后，服务器将不再被调用，此刻客户端可以自己准备一个本地的fallback回调，返回一个缺省值，这样做，虽然服务水平下降，但好歹可用，比直接挂掉要强。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210715215026.png" alt="image-20210715215026501" style="zoom:67%;" />



#### 使用场景

服务降级主要用于什么场景呢？当整个微服务架构整体的负载超出了预设的上限阈值或即将到来的流量预计将会超过预设的阈值时，为了保证重要或基本的服务能正常运行，我们可以将一些 不重要 或 不紧急 的服务或任务进行服务的 延迟使用 或 暂停使用。

 

实现方式：<font color='red'>在客户端实现服务降级，在客户端指定本地fallback</font>



##### 在**<font color='red'>commons</font>**模块创建fallback工厂类   <font color='red'>不需要导包</font>

注意：需要通过**<font color='red'>@Component</font>**将factory加入到IOC容器

```java
@Component
public class ProviderServiceFactory implements FallbackFactory<ProviderService> {

    @Override
    public ProviderService create(Throwable throwable) {
        return new ProviderService() {
            @Override
            public List<Goods> all() {

                return Arrays.asList(
                        new Goods(5001,"service-backA"),
                        new Goods(5002,"service-backB")
                );
            }

            @Override
            public Goods findById(int id) {
                return new Goods(5003,"service-backC");
            }

            @Override
            public ResponseResult<Boolean> add(Goods goods) {
                return new ResponseResult<>();
            }

            @Override
            public void update(Goods goods) {
                System.out.println("update服务降级");
            }

            @Override
            public void del(int id) {
                System.out.println("del服务降级");
            }
        };
    }
}

```



注意目录结构

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210715220232.png" alt="image-20210715220231879" style="zoom:50%;float: left;" />

##### 将commons模块重新打包



##### 在consumer-feign的application.yml中开启服务降级

```yaml
feign:
  hystrix:
    enabled: true  #开启服务降级

```



##### 在consumer-feign的主启动类上通过@SpringBootApplication改变默认扫描起始位置，以便扫描到factory所在的包

```java
@SpringBootApplication(scanBasePackages = "com")
@EnableEurekaClient
@EnableFeignClients(basePackages = "com.commons.service")

```



**<font color='red'>分别启动eureka、provider、consumer-feign模块，先正常请求，然后关闭provider再次请求查看服务是否降级</font>**，出现以下结果说明成功

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210715221936.png" alt="image-20210715221936403" style="zoom:50%;" />



### Hystrix超时设置（高 15）

#### 在provider的controller对应方法上添加sleep

```java
@GetMapping("find/{id}")
public Goods findById(@PathVariable("id") int id){
    try {
        Thread.sleep(5000);
    }catch (Exception e){
    }
    System.out.println(id);
    return new Goods(1003,"平板");
}

```



#### 运行eureka、provider、consumer-feign，访问consumer-feign的find方法，一秒钟之后自动熔断，得到factory中的结果

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210716103448.png" alt="image-20210716103448712" style="zoom:50%;" />



#### 在consumer-feign的application.yml中开启hystrix超时配置、设置超时时间

```yaml
hystrix:
  command:
    default:
      execution:
        timeout:
          enabled: true #开启超时管理
        isolation:
          thread:
            timeoutInMilliseconds: 10000  #设置超时时间

```



#### 重启consumer-feign，再次请求find，结果发现还是得不到数据，原因是openfeign默认采用了ribbon作为负载均衡器，而ribbon也是有超时时间的，因此此处由于超过了ribbon的超时时间导致的熔断，所以还需要修改ribbon的默认超时时间

```yaml
ribbon:
  eureka:
    enabled: true
  http:
    client:
      enabled: true   #开启超时管理
  ReadTimeout: 10000  #请求超时
  ConnectTimeout: 10000 #连接超时

```



#### 重启consumer-feign，请求find接口测试，5秒钟之后返回结果，说明超时设置成功



### Hystrix Dashboard（低 20）

#### 介绍

我们在公司开发过程中,微服务越来越多,为了保证系统的健壮性和安全性,我们加入了熔断机制。那现在我们想要知道每个微服务的运行状态,针对微服务进行优化。应该怎么办呢?

 

Hystrix-dashboard是一款针对Hystrix 进行实时监控的工具,通过Hystrix Dashboard我们可以在直观地看到各Hystrix Command的请求响应时间，请求成功率等数据。


#### 代码操作

##### 创建dashboard模块，该模块专门用来监控其他模块，而且它**<font color='red'>不用注册到注册中心</font>**

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210716110359.png" alt="image-20210716110359142" style="zoom:50%;" />

##### pom.xml中配置父项目

```xml
<parent>
    <artifactId>springcloud-teach</artifactId>
    <groupId>com.woniuxy</groupId>
    <version>1.0</version>
</parent>

```



##### 在父项目中引入子模块

```xml
<modules>
   <module>eureka-server</module>
   <module>provider</module>
   <module>consumer</module>
   <module>commons</module>
   <module>consumer-feign</module>
   <module>dashboard</module>
</modules>

```



##### 配置application.yml

```yaml
# 应用名称
spring:
  application:
    name: dashboard
server:
  port: 9999
hystrix:
  dashboard:
  	#添加服务监控白名单，可以监控哪些IP的服务，如：localhost
    proxyStreamAllowList: '127.0.0.1,localhost,192.168.41.161'  

```



##### 在主启动类上开启dashboard**<font color='red'>@EnableHystrixDashboard</font>**

```java
@SpringBootApplication
@EnableHystrixDashboard  //开启仪表盘
public class DashboardApplication {

    public static void main(String[] args) {
        SpringApplication.run(DashboardApplication.class, args);
    }

}

```



##### 启动项目在浏览器上访问：http://localhost:9999/hystrix，如下图所示

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210716113523.png" alt="image-20210716113523538" style="zoom: 33%;" />

##### 在需要被监控的微服务（provider）中添加hystrix依赖

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>
</dependency>
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-netflix-hystrix</artifactId>
</dependency>
<!--监控-->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>

```



##### 在其主启动类上开启hystrix

```java
@SpringBootApplication
@EnableEurekaClient
@EnableCircuitBreaker
public class ProviderApplication {
    public static void main(String[] args) {
        SpringApplication.run(ProviderApplication.class, args);
    }
}

```



**<font color='red'>在需要被监控的方法上添加@HystrixCommand并指定fallback，只有加了@HystrixCommand注解的方法才能被dashboard监控</font>**

```java
@GetMapping("/all")
@HystrixCommand(fallbackMethod = "fallback")
public List<Goods> all(){
    System.out.println(port);
    return Arrays.asList(
            new Goods(1001,"手机"),
            new Goods(1002,"电脑")
    );
}
public List<Goods> fallback(){
    System.out.println(port);
    return Arrays.asList(
            new Goods(6001,"手机"),
            new Goods(6002,"电脑")
    );
}

```



##### 在provider 的application.yml文件中暴露监控端口

```yaml
management:
  endpoints:
    web:
      exposure:
        include: hystrix.stream

```



##### 启动provider，然后在dashboard的地址栏中输入：localhost:8080/actuator/hystrix.stream并指定名字，点击按钮进行监控

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210716114152.png" alt="image-20210716114152535" style="zoom: 33%;" />

如果一切正常，会得到如下页面



<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210716121859.png" alt="image-20210716121859144" style="zoom:33%;" />

①圆点：微服务的健康状态，颜色有绿色、黄色、橙色、红色，健康状态依次降低

②线条：流量变化

③请求的方法

④成功请求（绿色）

⑤短路请求（蓝色）

⑥坏请求（青色）

⑦超时请求（黄色）

⑧被拒绝的请求（紫色）

⑨失败请求（红色）

⑩最近10秒钟内请求错误的百分比

11请求频率

12熔断器状态

13数据延迟统计

14线程池



<font color='red'>**注意：如果出不来仪表盘界面，需要反复确认以上步骤有没有问题。如果确定了没问题，在被监控的微服务中可以配置以下bean之后再测试（不需要额外导入依赖）**</font>

```java
@Bean
public ServletRegistrationBean servletRegistrationBean(){
    ServletRegistrationBean registrationBean = new ServletRegistrationBean(new HystrixMetricsStreamServlet());
    registrationBean.setLoadOnStartup(1);
    registrationBean.addUrlMappings("/actuator/hystrix.stream");
    return registrationBean;
}

```

指定URL处理的servlet（监控）



### Hystrix熔断实验（中 15）

#### 原理

Hystrix的作用就是保险箱的作用，如果它在一段时间内侦测到许多类似的错误，会强迫其以后的多个调用快速失败，不再访问远程服务器，从而防止应用程序不断地尝试执行可能会失败的操作，使得应用程序继续执行而不用等待修正错误，或者浪费CPU时间去等到长时间的超时产生。熔断器也可以使应用程序能够诊断错误是否已经修正，如果已经修正，应用程序会再次尝试调用操作。

熔断器模式就像是那些容易导致错误的操作的一种代理。这种代理能够记录最近调用发生错误的次数，然后决定使用允许操作继续，或者立即返回错误。熔断器开关相互转换的逻辑如下图:

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210715210631.png" alt="image-20210715210631335" style="zoom:67%;" />

#### 特点

·断路器机制

断路器很好理解,当Hystrix Command请求后端服务失败数量超过一定比例(默认50%),断路器会切换到开路状态(Open).这时所有请求会直接失败而不会发送到后端服务。断路器保持在开路状态一段时间后(默认5秒),自动切换到半开路状态(HAL F-OPEN)。这时会判断下一次请求的返回情况，如果请求成功，断路器切回闭路状态(CLOSED),否则重新切换到开路状态(OPEN)。



### Hystrix熔断设置（高 10）


详细参数设置参考com.netflix.hystrix.HystrixCommandProperties类



#### 在consumer-feign的application.yml文件中添加以下配置

```yaml
hystrix:
  command:
    default:
      execution:
        timeout:
          enabled: true #开启超时管理
        isolation:
          thread:
            timeoutInMilliseconds: 10000  #设置超时时间  默认1秒
      fallback:
        isolation:
          semaphore:
            maxConcurrentRequests: 10 #设置调用fallback函数的最大并发数（线程数）  默认10
        enabled: true  #开启fallback  默认true
      circuitBreaker:
        enabled: true  #设置断路器是否起作用 默认true
        sleepWindowInMilliseconds: 3000  #熔断器打开后多少秒内 熔断状态变成半开状态  默认5秒
        errorThresholdPercentage: 50 #错误百分比条件，
        requestVolumeThreshold: 10 #打开断路器的最少失败的请求数
        forceOpen: false  #强制打开断路器
        forceClosed: false #强制关闭断路器

```

##### hystrix.command.default

| 参数                                               | 解释                                                         |
| -------------------------------------------------- | ------------------------------------------------------------ |
| fallback.isolation.semaphore.maxConcurrentRequests | 设置调用fallback函数的最大并发数  默认10，如果并发数达到该设置值，请求会被拒绝和抛出异常并且fallback不会被调用 |
| fallback.enabled                                   | 开启fallback  默认true                                       |
| circuitBreaker.enabled                             | 设置断路器是否起作用 默认true                                |
| circuitBreaker.sleepWindowInMilliseconds           | 熔断器打开后多少秒内 熔断状态变成半熔断状态  默认5秒         |
| circuitBreaker.errorThresholdPercentage            | 错误百分比条件，达到熔断器最小请求数后错误率达到百分之多少后打开熔断器 默认50% |
| circuitBreaker.requestVolumeThreshold              | 打开断路器的最少请求数,比如：如果值是20，在一个窗口内（比如10秒），收到19个请求，即使这19个请求都失败了，断路器也不会打开。 |
| circuitBreaker.forceOpen                           | 是否强制打开断路器 默认false                                 |
| circuitBreaker.forceClosed                         | 是否强制关闭断路器 默认false                                 |

consumer-feign的pom文件中导入hystrix和actuator依赖

```xml
<!--hystrix依赖-->
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-netflix-hystrix</artifactId>
</dependency>
<!--监控-->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>

```

在application.yml中暴露监控端口

```yaml
management:
  endpoints:
    web:
      exposure:
        include: hystrix.stream

```

在主启动类上开启熔断器

```java
package com.woniuxy.consumerfeign;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.cloud.client.circuitbreaker.EnableCircuitBreaker;
import org.springframework.cloud.netflix.eureka.EnableEurekaClient;
import org.springframework.cloud.openfeign.EnableFeignClients;

//修改自动扫描的起始位置
@SpringBootApplication(scanBasePackages = "com.woniuxy")
@EnableEurekaClient //开启注册
@EnableFeignClients(basePackages = "com.woniuxy.commons.service")  //扫描service
@EnableCircuitBreaker
public class ConsumerFeignApplication {

    public static void main(String[] args) {
        SpringApplication.run(ConsumerFeignApplication.class, args);
    }

}

```

分别启动eureka、consumer-feign和dashboard

在dashboard中输入监控的url信息

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210804202547.png" alt="image-20210804202547080" style="zoom:33%;" />

另开一个窗口请求consumer-feign中的接口，然后观察dashboard，熔断器状态为closed

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210804203128.png" alt="image-20210804203128399" style="zoom:33%;" />

然后请求到10次的时候可以看到熔断器状态变为了open

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210804203249.png" alt="image-20210804203249517" style="zoom:33%;" />

然后启动provider，再次请求consumer-feign中的该接口，可以看到熔断器可以变为closed状态

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210804203513.png" alt="image-20210804203513766" style="zoom:33%;" />

<font color='red'>注意：启动provider之后如果立即访问consumer-feign的接口，可能不会正常得到数据，原因是此时consumer-feign微服务并不知道provider已经可用，其根本原因是微服务会每隔30秒钟去eureka中获取服务列表，只有获取到最新的服务列表consumer-feign才知道provider可用，才能调用成功</font>



# day03

### Zuul概述及使用（中 30）

#### 介绍

 <img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210716153731.png" alt="image-20210716153730904" style="zoom:50%;" />

外部的应用如何来访问内部各种各样的微服务呢?在微服务架构中， 后端服务往往不直接开放给调用端,而是通过于个API网关根据请求的url ,路由到相应的服务。当添加API网关后,在第三方调用端和服务提供方之间就创建了一面墙,这面墙直接与调用方通信进行权限控制,后将请求均衡分发给后台服务端。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210716153756.png" alt="image-20210716153756292" style="zoom:67%;" />

Spring Cloud Zuul路由是微服务架构中不可或缺的一部分提供动态路由,监控,弹性,安全等的边缘服务。Zuul 是Netflix出品的一个基于JVM路由和服务端的负载均衡器。

 

作用:就是服务转发,接收并转发所有内外部的客户端调用。使用Zuul可以作为资源的统一访问入口,同时也可以在网关做一些权限校验等类似的功能。



#### 路由的应用场景

##### 简化客户端调用复杂度

在微服务架构模式下,后端服务的实例数一般是动态的,对于客户端而言很难发现动态改变的服务实例的访问地址信息。因此在基于微服务的项目中为了简化前端的调用逻辑,通常会引入API Gateway作为轻量级网关,同时API Gateway中也会实现相关的认证逻辑从而简化内部服务之间相互调用的复杂度。

 

##### 数据裁剪以及聚合

通常而言不同的客户端对于显示时对于数据的需求是不一致的。比如手机端或者Web端又或者在低延迟的网络环境或者高延迟的网络环境。

因此为了优化客户端的使用体验,API Gateway可以对通用性的响应数据进行裁剪以适应不同客户端的使用需求。同时还可以将多个API调用逻辑进行聚合,从而减少客户端的请求数,优化客户端用户体验。

 

##### 多渠道支持

当然我们还可以针对不同的渠道和客户端提供不同的API Gateway,手机端、pc端和云端都可以提供不同的API Gateway.

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210716153856.png" alt="image-20210716153856496" style="zoom:67%;" />

#### 代码实现

##### 创建zuul微服务

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210716154057.png" alt="image-20210716154057097" style="zoom:50%;" />

##### pom.xml中配置父项目

```xml
<parent>
    <artifactId>springcloud-teach</artifactId>
    <groupId>com.woniuxy</groupId>
    <version>1.0</version>
</parent>
```



##### 在父项目中引入子模块

```xml
<modules>
   <module>eureka-server</module>
   <module>provider</module>
   <module>consumer</module>
   <module>commons</module>
   <module>consumer-feign</module>
   <module>dashboard</module>
   <module>zuul</module>
</modules>
```



##### 在zuul的application.yml中配置eureka、路由等信息

```yaml
spring:
  application:
    name: zuul
server:
  port: 9500
eureka:
  client: #客户端注册到eureka列表中
    service-url:
      defaultZone: http://127.0.0.1:9001/eureka
  instance:
    instance-id: zuul-9500  #注册中心status显示出来的微服务id
    prefer-ip-address: true #显示访问url
zuul:
  routes:
    provider: /goods/**    #goods开头的请求都交给provider微服务处理
info:
  app.name: SpringCloud
  company.name: woniuxy
  build.artifactId: $project.artifactId$
  build.version: $project.version$
```



##### 在zuul的主启动类上通过**<font color='red'>@EnableZuulProxy</font>**注解开启zuul

```java
@SpringBootApplication
@EnableEurekaClient //开启eureka
@EnableZuulProxy //开启路由
public class ZuulApplication {

    public static void main(String[] args) {
        SpringApplication.run(ZuulApplication.class, args);
    }

}
```



##### 分别启动eureka、provider、zuul



##### 通过zuul访问provider中的方法

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210716164425.png" alt="image-20210716164425478" style="zoom:50%;" />

也可以通过微服务的名字来访问

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210716164530.png" alt="image-20210716164529847" style="zoom:50%;" />

在application.yml中配置忽略微服务名字调用

```yaml
zuul:
  ignored-services: "*"
  routes:
    provider: /goods/**
```



再通过微服务名调用时报404

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210716164709.png" alt="image-20210716164709396" style="zoom:50%;" />



### Zuul配置（中 40）

配置路由规则、负载均衡、网关限流

#### 路由规则

##### 默认路由规则

如果不定义路由规则使用默认路由规则。

```yaml
#zuul:
#  ignored-services: "*"
#  routes:
#    provider: /goods/**
```

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210716165535.png" alt="image-20210716165535347" style="zoom:50%;" />



##### 自定义微服务访问URL

需要在zuul的配置文件中添加如下定义
比如：定义SERVICE-ORDER服务的URL

```yaml
zuul:
  ignored-services: "*"
  routes:
    provider: /goods/**
```



##### 定义微服务名与对应URL，需要在zuul的配置文件中添加如下定义

比如：定义SERVICE-ORDER服务的URL

```yaml
zuul:
  routes:
    abc: #路由名，用户自定义
      service-id: provider #调用的微服务名字，最好小写
      path: /goods/**  #匹配的路径，此处所有的请求都被provider微服务处理
    aaa:
      service-id: consumer #调用的微服务名字，最好小写
      path: /order/**  #匹配的路径，此处所有的请求都被provider微服务处理
```

访问

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210716170028.png" alt="image-20210716170027983" style="zoom:50%;" />



##### 指定微服务与具体访问地址

需要在zuul-proxy的配置文件中添加如下定义
比如：定义SERVICE-ORDER服务的URL

```yaml
zuul:
  routes:
    abc: #路由名，用户自定义
      path: /goods/**  #匹配的路径，此处所有的请求都被provider微服务处理
      url: http://localhost:8080/

```

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210716170028.png" alt="image-20210716170027983" style="zoom:50%;" />

**<font color='red'>注意：使用具体的微服务地址，无法使用Ribbon的负载均衡、服务降级、熔断功能</font>**



#### 负载均衡

zuul自动实现负载均衡，zuul实现负载均衡很简单，使用serviceId进行绑定后，如果有多个相同的serviceid，则会进行轮询的方式进行访问。而且实现是基于客户端负载均衡。



##### 客户端负载均衡

基于客户端的负载均衡，简单的说就是在客户端程序里面，自己设定一个调度算法，在向服务器发起请求的时候，先执行调度算法计算出向哪台服务器发起请求，然后再发起请求给服务器。

特点：

1. 由客户端内部程序实现，不需要额外的负载均衡器软硬件投入。
2. 程序内部需要解决业务服务器不可用的问题，服务器故障对应用程序的透明度小。
3. 程序内部需要解决业务服务器压力过载的问题。

使用场景：

1. 可以选择为初期简单的负载均衡方案，和DNS负载均衡一样。
2. 比较适合于客户端具有成熟的调度库函数，算法以及API等
3. 毕竟适合对服务器入流量较大的业务，如HTTP POST文件上传，FTP文件上传，Memcache大流量写入。
4. 可以结合其他负载均衡方案进行架构。



#### 网关限流（网关Filter）

Zuul的核心是一系列的filters, 其作用类似Servlet框架的Filter，Zuul把客户端请求路由到业务处理逻辑的过程中，这些filter在路由的特定时期参与了一些过滤处理，比如实现鉴权、流量转发、请求统计等功能。Zuul的整个运行机制，可以用下图来描述。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210717133732.png" alt="image-20210717133732577" style="zoom:50%;" />

##### 过滤器的生命周期

Filter的生命周期有4个，分别是“PRE”、“ROUTING”、“POST”、“ERROR”，整个生命周期可以用下图来表示。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210717133755.png" alt="image-20210717133755709" style="zoom:50%;" />

基于Zuul的这些过滤器，可以实现各种丰富的功能，而这些过滤器类型则对应于请求的典型生命周期。

a）PRE： 这种过滤器在请求被路由之前调用。我们可利用这种过滤器实现身份验证、在集群中选择请求的微服务、记录调试信息等。

 

b）ROUTING：这种过滤器将请求路由到微服务。这种过滤器用于构建发送给微服务的请求，并使用

Apache HttpClient或Netfilx Ribbon请求微服务。

 

c）POST：这种过滤器在路由到微服务以后执行。这种过滤器可用来为响应添加标准的HTTP Header、收集统计信息和指标、将响应从微服务发送给客户端等。

 

d）ERROR：在其他阶段发生错误时执行该过滤器。

 

除了默认的过滤器类型，Zuul还允许我们创建自定义的过滤器类型。例如，我们可以定制一种STATIC类型的过滤器，直接在Zuul中生成响应，而不将请求转发到后端的微服务。



##### Zuul中默认实现的Filter

Zuul默认实现了很多Filter，这些Filter如下面表格所示。

| **类型** | **顺序** | **过滤器**              | **功能**                   |
| -------- | -------- | ----------------------- | -------------------------- |
| pre      | -3       | ServletDetectionFilter  | 标记处理Servlet的类型      |
| pre      | -2       | Servlet30WrapperFilter  | 包装HttpServletRequest请求 |
| pre      | -1       | FormBodyWrapperFilter   | 包装请求体                 |
| route    | 1        | DebugFilter             | 标记调试标志               |
| route    | 5        | PreDecorationFilter     | 处理请求上下文供后续使用   |
| route    | 10       | RibbonRoutingFilter     | serviceId请求转发          |
| route    | 100      | SimpleHostRoutingFilter | url请求转发                |
| route    | 500      | SendForwardFilter       | forward请求转发            |
| post     | 0        | SendErrorFilter         | 处理有错误的请求响应       |
| post     | 1000     | SendResponseFilter      | 处理正常的请求响应         |



##### 自定义Filter

实现自定义滤器需要继承ZuulFilter，并实现ZuulFilter中的抽象方法。

```java
/**
 * 自定义过滤器
 */
@Component
public class CustomFilter extends ZuulFilter {

    //过滤器类型
    @Override
    public String filterType() {
        return "pre";
    }

    //执行顺序
    @Override
    public int filterOrder() {
        return 0;
    }

    //是否过滤
    @Override
    public boolean shouldFilter() {
        return true;
    }

    //对请求进行处理
    @Override
    public Object run() throws ZuulException {
        System.out.println("正在执行过滤...");
        return null;
    }
}

```



#### 常见限流算法

##### 漏桶算法

又称leaky bucket。为了理解漏桶算法，我们看一下对于该算法的示意图：

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210717135526.png" alt="image-20210717135526354" style="zoom: 33%;" />

从图中我们可以看到，整个算法其实十分简单。首先，我们有一个固定容量的桶，有水流进来，也有水流出去。对于流进来的水来说，我们无法预计一共有多少水会流进来，也无法预计水流的速度。但是对于流出去的水来说，这个桶可以固定水流出的速率。而且，当桶满了之后，多余的水将会溢出。

我们将算法中的水换成实际应用中的请求，我们可以看到漏桶算法天生就限制了请求的速度。当使用了漏桶算法，我们可以保证接口会以一个常速速率来处理请求。所以漏桶算法天生不会出现临界问题。

漏桶算法可以粗略的认为就是注水漏水过程，往桶中以一定速率流出水，以任意速率流入水，当水超过桶流量则丢弃，因为桶容量是不变的，保证了整体的速率。



##### 令牌桶算法

对于很多应用场景来说，除了要求能够限制数据的平均传输速率外，还要求允许某种程度的突发传输。这时候漏桶算法可能就不合适了，令牌桶算法更为适合。如图所示，令牌桶算法的原理是系统会以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务。



<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210717142953.png" alt="image-20210717142953331" style="zoom: 33%;" />



#### 基于令牌桶算法的网关限流

##### 为了提高对zuul的保护，先在zuul的pom.xml导入hystrix依赖并开启

```xml
<dependency>
     <groupId>org.springframework.cloud</groupId>
     <artifactId>spring-cloud-starter-netflix-hystrix</artifactId>
</dependency>

```

##### 开启熔断

```java
@SpringBootApplication
@EnableEurekaClient 
@EnableZuulProxy 
@EnableCircuitBreaker  //开启熔断
public class ZuulApplication {

    public static void main(String[] args) {
        SpringApplication.run(ZuulApplication.class, args);
    }

}

```



##### 自定义zuulfilter，添加实现限流代码

限流器：**<font color='red'>com.google.common.util.concurrent.RateLimiter</font>**

```java
package com.woniuxy.zuul.filter;

import com.commons.result.ResponseResult;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.google.common.util.concurrent.RateLimiter;
import com.netflix.zuul.ZuulFilter;
import com.netflix.zuul.context.RequestContext;
import com.netflix.zuul.exception.ZuulException;
import org.springframework.stereotype.Component;

import javax.servlet.http.HttpServletResponse;

/**
 * 自定义过滤器
 */
@Component
public class CustomFilter extends ZuulFilter {
    private static int count = 1;

    //创建限流器  500个令牌
    private static final RateLimiter RATE_LIMITER = RateLimiter.create(500);

    //过滤器类型
    @Override
    public String filterType() {
        return "pre";
    }

    //执行顺序
    @Override
    public int filterOrder() {
        return 0;
    }

    //是否过滤
    @Override
    public boolean shouldFilter() {
        return true;
    }

    //对请求进行处理
    @Override
    public Object run() throws ZuulException {
        //获取上下文对象
        RequestContext context = RequestContext.getCurrentContext();
        //获取response对象
        HttpServletResponse response = context.getResponse();
        //如果无法获取令牌
        if (!RATE_LIMITER.tryAcquire()){
            System.out.println("令牌不足，停止服务......." + count++);
            //停止访问
            context.setSendZuulResponse(false);

            // 返回消息
            response.setContentType("application/json;charset=utf-8");
            ResponseResult<Object> result = new ResponseResult<>(500,"系统繁忙,请稍后再试",null);
            try {
                response.getWriter().write(new ObjectMapper().writeValueAsString(result));
            }catch (Exception e){
                e.printStackTrace();
            }
        }
        return null;
    }
}


```

##### 运行eureka、两个provider、zuul，利用jemiter向zuul发送**<font color='red'>1000</font>**个请求



##### 如果请求失败的太多可以通过增加zuul超时时间解决

```yaml
zuul:
  host:
    connect-timeout-millis: 30000  #连接超时
    socket-timeout-millis: 10000  #请求超时

```



**<font color='red'>注意：第一次jemiter发送请求时请求失败的次数可能会比较多（原因暂不清楚），可以再执行一次查看结果</font>**



### Gateway简介（中 20）

#### 介绍

SpringCloud Gateway 是 Spring Cloud 的一个全新项目，该项目是基于 Spring 5.0，Spring Boot 2.0 和 Project Reactor 等技术开发的网关，它旨在为微服务架构提供一种简单有效的统一的 API 路由管理方式。

SpringCloud Gateway 作为 Spring Cloud 生态系统中的网关，目标是替代 Zuul，在Spring Cloud 2.0以上版本中，没有对新版本的Zuul 2.0以上最新高性能版本进行集成，仍然还是使用的Zuul 2.0之前的非Reactor模式的老版本。而为了提升网关的性能，SpringCloud Gateway是基于WebFlux框架实现的，而WebFlux框架底层则使用了高性能的Reactor模式通信框架Netty。

Spring Cloud Gateway 的目标，不仅提供统一的路由方式，并且基于 Filter 链的方式提供了网关基本的功能，例如：安全，监控/指标，和限流。



##### SpringCloud Gateway 特征

SpringCloud官方，对SpringCloud Gateway 特征介绍如下：

（1）基于 Spring Framework 5，Project Reactor 和 Spring Boot 2.0

（2）集成 Hystrix 断路器

（3）集成 Spring Cloud DiscoveryClient

（4）Predicates（谓词、断言） 和 Filters 作用于特定路由，易于编写的 Predicates 和 Filters

（5）具备一些网关的高级功能：动态路由、限流、路径重写

从以上的特征来说，和Zuul的特征差别不大。SpringCloud Gateway和Zuul主要的区别，还是在底层的通信框架上。



##### 专业术语

a）Filter（过滤器）：

和Zuul的过滤器在概念上类似，可以使用它拦截和修改请求，并且对上游的响应，进行二次处理。过滤器为org.springframework.cloud.gateway.filter.GatewayFilter类的实例。



b）Route（路由）：

网关配置的基本组成模块，和Zuul的路由配置模块类似。一个Route模块由一个 ID，一个目标 URI，一组断言和一组过滤器定义。如果断言为真，则路由匹配，目标URI会被访问。



c）Predicate（谓词、断言）：

这是一个 Java 8 的 Predicate，可以使用它来匹配来自 HTTP 请求的任何内容，例如 headers 或参数。断言的输入类型是一个 ServerWebExchange。



##### 工作流程

客户端向 Spring Cloud Gateway 发出请求。然后在 Gateway Handler Mapping 中找到与请求相匹配的路由，将其发送到 Gateway Web Handler。Handler 再通过指定的过滤器链来将请求发送到我们实际的服务执行业务逻辑，然后返回。过滤器之间用虚线分开是因为过滤器可能会在发送代理请求之前（“pre”）或之后（“post”）执行业务逻辑。

![Spring Cloud Gateway Diagram](https://docs.spring.io/spring-cloud-gateway/docs/3.0.4-SNAPSHOT/reference/html/images/spring_cloud_gateway_diagram.png)

| 类型 | 作用                                                         |
| ---- | ------------------------------------------------------------ |
| pre  | 这种过滤器在请求被路由之前调用。我们可利用这种过滤器实现身份验证、在集群中选择请求的微服务、记录调试信息等。 |
| post | 这种过滤器在路由到微服务以后执行。这种过滤器可用来为响应添加标准的HTTP Header、收集统计信息和指标、将响应从微服务发送给客户端等。 |



Filter在“pre”类型过滤器中可以做参数校验、权限校验、流量监控、⽇志输出、协议转换等，在“post”类型的过滤器中可以做响应内容、响应头的修改、⽇志的输出、流量监控等。



### Gateway路由配置（高 40）

#### 创建gateway微服务

##### 引入eureka、gateway、hystrix，**<font color='red'>因为gateway是基于webflux，与spring web不兼容，因此不要导入spring web</font>**

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210717164514.png" alt="image-20210717164513949" style="zoom:50%;" />

 

##### 在pom.xml文件中指定父项目

```xml
<parent>
    <artifactId>springcloud-teach</artifactId>
    <groupId>com.woniuxy</groupId>
    <version>1.0</version>
</parent>

```



##### 在父项目中引入子模块

```xml
<modules>
    <module>eureka-server</module>
    <module>provider</module>
    <module>consumer</module>
    <module>commons</module>
    <module>consumer-feign</module>
    <module>dashboard</module>
    <module>zuul</module>
    <module>gateway</module>
</modules>

```



##### 主启动类上开启eureka、hystrix

```java
@SpringBootApplication
@EnableEurekaClient
@EnableCircuitBreaker
public class GatewayApplication {

    public static void main(String[] args) {
        SpringApplication.run(GatewayApplication.class, args);
    }

}

```



##### 配置gateway的application.yml

```yaml
spring:
  application:
    name: gateway
  cloud:
    inetutils:
      default-ip-address: 127.0.0.1
    gateway:
      routes:
        - id: provider  #路由规则命名   自定义，不重复   一个id代表一个微服务，可以配置多个id
          uri: lb://provider   #lb loadbalance 负载均衡缩写
          predicates:
            - Path=/goods/**
#      discovery:
#        locator:
#          lower-case-service-id: true #eureka中微服务名字为大写，此处开启表示在gateway中所有微服务名称使用小写名称定义
#          enabled: true #开启从注册中心定位路由服务
server:
  port: 9600
eureka:
  client: #客户端注册到eureka列表中
    service-url:
      defaultZone: http://127.0.0.1:9001/eureka
  instance:
    instance-id: gateway-9600  #注册中心status显示出来的微服务id
    prefer-ip-address: true #显示访问url

```



**<font color='red'>说明：Path=/goods/... 是指以/goods/开头的url都交给provider微服务处理，但是在转发请求的时候，gateway不会去掉/goods/前缀，因此在provider的controller上需要加上基础url</font>**

**<font color='red'>@RequestMapping("/goods")</font>**

```java
@RestController
@RequestMapping("/goods")
public class GoodsController {
    @Value("${server.port}")
    private String port;

    @GetMapping("/all")
    public List<Goods> all(){
        System.out.println(port);
        return Arrays.asList(
                new Goods(1001,"手机"),
                new Goods(1002,"电脑")
        );
    }
}

```



##### 依次运行eureka、两个provider、gateway，通过gateway请求数据

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210717172010.png" alt="image-20210717172010427" style="zoom:50%;" />

#### 路由断言

Predicate（谓语、断言）：路由转发的判断条件，目前SpringCloud Gateway支持多种方式，常见如：Path、Host、Method、Query等。

##### Path 方式匹配转发

```yaml
routes:
   - id: provider  
     uri: lb://provider
     predicates:
        - Path=/goods/**

```



##### Host 方式匹配转发

Spring Cloud Gateway可以根据Host主机名进行匹配转发，如果我们的接口只允许**.woniuxy.com域名进行访问，那么配置如下所示：

```yaml
routes:
   - id: provider  
     uri: lb://provider
     predicates:
        - Host=**.woniuxy.com

```



##### Method断言

这个断言是专门验证HTTP Method的，在下面的例子中，当访问“/gateway/sample”并且HTTP Method是GET的时候，将适配下面的路由

```yaml
routes:
   - id: provider  
     uri: lb://provider
     predicates:
        - Path=/goods/**
        - Method=GET

```



##### Query断言

请求断言也是在业务中经常使用的，它会从ServerHttpRequest中的Parameters列表中查询指定的属性，有如下两种不同的使用方式

```yaml
routes:
   - id: provider  
     uri: lb://provider
     predicates:
        - Path=/goods/**
        - Query=name,zhangsan*

```

Query=name表示只要请求中包含 name 属性的参数即可匹配路由



Query也可以有两个参数，如：Query=name，zhangsan，表示请求中必须包含 name 属性而且name的值必须是zhangsan才能匹配路由

通配符

| 通配符 | 解释         |
| ------ | ------------ |
| .      | 任意一个字符 |
| *      | 任意多个字符 |

### Route Filter路由过滤器（高 40）

Spring Cloud Gateway除了具备请求路由功能之外，也支持对请求的过滤。通过Zuul网关类似，也是通过过滤器的形式来实现的。那么接下来我们一起来研究一下Gateway中的过滤器



#### 过滤器的生命周期

Spring Cloud Gateway 的 Filter 的生命周期不像 Zuul 的那么丰富，它只有两个：“pre” 和 “post”

| 类型 | 作用                                                         |
| ---- | ------------------------------------------------------------ |
| pre  | 这种过滤器在请求被路由之前调用。我们可利用这种过滤器实现身份验证、在集群中选择请求的微服务、记录调试信息等。 |
| post | 这种过滤器在路由到微服务以后执行。这种过滤器可用来为响应添加标准的HTTP Header、收集统计信息和指标、将响应从微服务发送给客户端等。 |



#### 过滤器类型

Spring Cloud Gateway 的 Filter 从作用范围可分为另外两种GatewayFilter 与 GlobalFilter。

| 类型          | 作用                                 |
| ------------- | ------------------------------------ |
| GatewayFilter | 应用到单个路由或者一个分组的路由上。 |
| GlobalFilter  | 应用到所有的路由上。                 |



##### 局部过滤器

局部过滤器（GatewayFilter），是针对单个路由的过滤器。可以对访问的URL过滤，进行切面处理。在Spring Cloud Gateway中通过GatewayFilter的形式内置了很多不同类型的局部过滤器。这里简单将Spring Cloud Gateway内置的所有过滤器工厂整理成了一张表格，虽然不是很详细，但能作为速览使用。如下：

| 过滤器工厂                  | 作用                                                         | 参数                                                         |
| --------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| AddRequestHeader            | 为原始请求添加Header                                         | Header的名称及值                                             |
| AddRequestParameter         | 为原始请求添加请求参数                                       | 参数名称及值                                                 |
| AddResponseHeader           | 为原始响应添加Header                                         | Header的名称及值                                             |
| DedupeResponseHeader        | 剔除响应头中重复的值                                         | 需要去重的Header名称及去重策路                               |
| Hystrix                     | 为路由引入Hystrix的断路器保护                                | Hystrixcommand的名称                                         |
| FallbackHeaders             | 为fallbackUri的请求头中添加具体的异常信息                    | Header的名称                                                 |
| prefixPath                  | 为原始请求路径添加前缀                                       | 前缀路径                                                     |
| PreserveHostHeader          | 为请求添加一个preserveHostHeader=true的属性，路由过滤器会检查该属性以决定是否要发送原始的Host | 无                                                           |
| RequestRateLimiter          | 用于对请求限流，限流算法为令牌桶                             | KeyResolver、rateLimiter、statusCode、denyEmptyKey、emptyKeyStatus |
| RedirectTo                  | http状态码及重定向的URL                                      | 将原始请求重定向到指定的URL                                  |
| RemoveHopByHopHeadersFilter | 为原始请求册除IETF组织规定的一系列Header                     | 默认就会启用，可以通过配置指定仅出除比Header                 |
| RemoveRequestHeader         | 为原始请求删除某个Header                                     | Header名称                                                   |
| RemoveResponseHeader        | 为原始响应册除某个Header                                     | Header名称                                                   |
| RewritePath                 | 重写原始的请求路径                                           | 原始路径正则表达式以及重写后路径的正则表达式                 |
| RewriteResponseHeader       | 重写原始响应中的某个Header                                   | Header名称，值的正则表达式，重写后的值                       |
| SaveSession                 | 在转发请求之前，强制执行websession : :save操作               | 无                                                           |
| secureHeaders               | 为原始响应添加一系列起安全作用的响应头                       | 无，支持修改这些安全响应头的值                               |
| SetPath                     | 修改原始的请求路径                                           | 修改后的路径                                                 |
| SetResponseHeader           | 修改原始响应中某个Header的值                                 | Header名称，修改后的值                                       |
| SetStatus                   | 修改原始响应的状态码                                         | HTTP状态码，可以是数字，也可以是字符串                       |
| StripPrefix                 | 用于截断原始请求的路径                                       | 使用数字表示要截断的路径的数量                               |
| Retry                       | 针对不同的响应进行重试                                       | retries、statuses、methods、series                           |
| RequestSize                 | 设置允许接收最大请求包的大小。如果请求包大小超过设置的值，则返回413 Payload TooLarge | 请求包大小，单位为字节，默认值为5M                           |
| wModifyRequestBody          | 在转发请求之前修改原始请求体内容                             | 修改后的请求体内容                                           |
| ModifyResponseBody          | 修改原始响应体的内容                                         | 修改后的响应体内容                                           |



每个过滤器工厂都对应一个实现类，并且这些类的名称必须以 GatewayFilterFactory 结尾，这是Spring Cloud Gateway的一个约定，例如 AddRequestHeader 对应的实现类为AddRequestHeaderGatewayFilterFactory 。

 

##### 全局过滤器

全局过滤器（GlobalFilter）作用于所有路由，Spring Cloud Gateway 定义了Global Filter接口，用户可以自定义实现自己的Global Filter。通过全局过滤器可以实现对权限的统一校验，安全性验证等功能，并且全局过滤器也是程序员使用比较多的过滤器。Spring Cloud Gateway内部也是通过一系列的内置全局过滤器对整个路由转发进行处理如下：

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210718163636.png" alt="image-20210718163636616" style="zoom: 50%;" />

##### 自定义全局过滤器：实现GlobalFilter和Ordered接口

```java
package com.woniuxy.gateway.filter;

import org.reactivestreams.Publisher;
import org.springframework.cloud.gateway.filter.GatewayFilterChain;
import org.springframework.cloud.gateway.filter.GlobalFilter;
import org.springframework.core.Ordered;
import org.springframework.core.io.buffer.DataBuffer;
import org.springframework.http.HttpStatus;
import org.springframework.http.server.reactive.ServerHttpRequest;
import org.springframework.stereotype.Component;
import org.springframework.web.server.ServerWebExchange;
import reactor.core.publisher.Flux;
import reactor.core.publisher.Mono;

import java.nio.charset.StandardCharsets;
import java.util.LinkedHashMap;
import java.util.List;
import java.util.Map;

@Component
public class CustomFilter implements GlobalFilter, Ordered {
    /**
     * 过滤器执行过滤代码
     */
    @Override
    public Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) {
        //获取request对象
        ServerHttpRequest request = exchange.getRequest();
        //获取请求头
        String token = request.getHeaders().get("authorization").get(0);

        //继续执行
		return chain.filter(exchange);
    }

    /*
     * 指定过滤器的顺序，值越小越先执行
     */
    @Override
    public int getOrder() {
        return 0;
    }
}

```



##### 通过response对象返回JSON数据

```java
//获取response对象
ServerHttpResponse response = exchange.getResponse();

//准备数据
ResponseResult<Object> result = new ResponseResult<>(500,"error",null);
//将数据转换成byte数组
byte[] data = null;
try {
    data = new ObjectMapper().writeValueAsString(result).getBytes(StandardCharsets.UTF_8);
}catch (Exception e){
    e.printStackTrace();
}

//创建数据缓存对象
DataBuffer buffer = response.bufferFactory().wrap(data);

//设置响应头
response.getHeaders().add("Content-Type","application/json;charset=utf-8");

//返回数据
return response.writeWith(Mono.just(buffer));

```



### 微服务的认证方案简介（中 25）

基于Session的认证简介，基于Token的认证简介，JWT基本含义及其应用领域，传统Session认证优缺点

#### 传统的session认证

我们知道，http协议本身是一种无状态的协议，而这就意味着如果用户向我们的应用提供了用户名和密码来进行用户认证，那么下一次请求时，用户还要再一次进行用户认证才行，因为根据http协议，我们并不能知道是哪个用户发送的请求，所以为了让我们的应用能识别是哪个用户发出的，我们只能在服务器存储一份用户登陆的信息，这份登陆信息会在响应时传递给服务器，告诉其保存为cookie，以便下次请求时发送给我们的应用，这样我们的应用就能识别请求来自哪个用户了，这就是传统的基于sessino认证

 

但是这种基于session的认证使应用本身很难得扩展，随着不用客户端的增加，独立的服务器已无法承载更多的用户，而这个时候基于session认证应用的问题就会暴露出来



#### 基于session认证所显露的问题

- Session：每个用户经过我们的应用认证之后，我们的应用都要在服务端做一次记录，以便用户下次请求的鉴别，通常而言session都是保存在内存中，而随着认证用户的增多，服务端的开销会明显增大。

 

- 扩展性：用户认证之后，服务端做认证记录，如果认证的记录被保存在内存的话，这意味着用户下次请求还必须要请求在这台服务器上，这样才能拿到授权的资源，这样在分布式的应用上，响应的限制了负载均衡器的能力，也意味着限制了应用的扩展性。



#### 基于token的鉴权机制

基于token的鉴权机制类似于http协议也是无状态的，它不需要在服务端去保留用户的认证信息或会话信息。这也就意味着基于token认证机制的应用不需要去考虑用户在哪一台服务器登陆了，这就为应用的扩展提供了便利。

 

流程

- 用户使用用户名密码请求服务器

- 服务器进行验证用户信息

- 服务器通过验证发送给用户一个token

- 客户端存储token，并在每次请求时附加这个token值

- 服务器验证token，并返回数据

 

这个token必须要在每次请求时发送给服务器，它应该保存在请求头中，另外服务器要支持CORS（跨来源资源共享）策略，一般我们在服务端这么做就可以了： Access-Control-Allow-Origin：*

 

（Access-Control-Allow-Origin是HTML5中定义的一种解决资源跨域的策略。他是通过服务器端返回带有Access-Control-Allow-Origin标识的Response header，用来解决资源的跨域权限问题。）



### CSRF（中 20）

CSRF基本原理、GET和POST型CSRF

跨站请求伪造（英语：Cross-site request forgery），也被称为 one-click attack 或者 session riding，通常缩写为 CSRF 或者 XSRF， 是一种挟制用户在当前已登录的Web应用程序上执行非本意的操作的攻击方法。

 

#### CSRF原理

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210719093005.png" alt="image-20210719093005022" style="zoom: 50%;" />

A并不知道(5)中的请求是C发出的还是B发出的，由于浏览器会自动带上用户C的Cookie，所以A会根据用户的权限出(5)的请求，这样B就达到了模拟用户操作的目的

 

从上图能够看出，要完毕一次CSRF攻击，受害者必须依次完毕两个步骤：

- 登录受信任站点A，并在本地生成Cookie。

- 在不登出A的情况下，訪问危急站点B。



#### 常见的攻击类型

##### GET类型的CSRF

仅仅须要一个HTTP请求。就能够构造一次简单的CSRF。

案例：

```html
<!-- 银行站点A：它以GET请求来完毕银行转账的操作，如：-->
http://www.mybank.com/Transfer.php?toBankId=11&money=1000

<!-- 危急站点B：它里面有一段HTML的代码例如以下：-->
<img src=http://www.mybank.com/Transfer.php?toBankId=11&money=1000>

```

首先。你登录了银行站点A，然后訪问危急站点B，这时你会发现你的银行账户少了1000块

为什么会这样呢？原因是银行站点A违反了HTTP规范，使用GET请求更新资源。
在访问危急站点B的之前。你已经登录了银行站点A，而B中的 一个合法的请求，但这里被不法分子利用了）。所以你的浏览器会带上你的银行站点A的Cookie发出Get请求，去获取资源以GET的方式请求第三方资源（这里的第三方就是指银行站点了，原本这是http://www.mybank.com/Transfer.php?toBankId=11&money=1000 ，结果银行站点服务器收到请求后，觉得这是一个更新资源操作（转账操作），所以就立马进行转账操作。



##### POST类型的CSRF

这种类型的CSRF危害没有GET型的大，利用起来通常使用的是一个自动提交的表单

案例：

```html
<form action=http://www.mybank.com/Transfer.php method=POST>
	<input type="text" name="toBankId" value="11" />
	<input type="text" name="money" value="1000" />
</form>
<script> document.forms[0].submit(); </script> 

```

访问该页面后，表单会自动提交，相当于模拟用户完成了一次POST操作。



**<font color='red'>目前主流的做法是使用Token抵御CSRF攻击。</font>**



#### JWT

官网：https://jwt.io/

一般用于身份验证和数据信息交换

Json web token（JWT）是为了在网络应用环境间传递声明而执行的一种基于JSON的开发标准（RFC 7519），该token（令牌）被设计为紧凑且安全的，特别适用于分布式站点的单点登陆（SSO）场景。JWT的声明一般被用来在身份提供者和服务提供者间传递被认证的用户身份信息，以便于从资源服务器获取资源，也可以增加一些额外的其它业务逻辑所必须的声明信息，该token也可直接被用于认证，也可被加密。



### 基于JWT的认证流程及JWT组成结构（高 15）

Header的基本作用、构成；payload的基本作用、构成，共有声明、私有声明；signature的基本含义及其作用

#### JWT的构成

JWT是由三部分构成，将这三段信息文本用链接构成了JWT字符串。就像这样

 	<font color='red'>eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9</font>.<font color='green'>eyJVc2VySWQiOjEyMywiVXNlck5hbWUiOiJhZG1pbiJ9</font>.<font color='blue'>Qjw1epD5P6p4Yy2yju3-fkq28PddznqRj3ESfALQy_U</font>

第一部分我们称它为头部（header）第二部分我们称其为载荷（payload，类似于飞机上承载的物品），第三部分是签证（signature）

 

##### header

JWT的头部承载的两部分信息：

- 声明类型，这里是jwt

- 声明加密的算法，通常直接使用HMAC SHA256或RSA

 

完整的头部就像下面这样的JSON

```json
{ 'typ':'JWT', 'alg':'HSA256' }

```

然后将头部进行base64加密（该加密是可以对称解密的），构成了第一部分	

​	eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9



##### plyload

也称为JWT Claims，包含用户的一些非隐私数据

- 标准中注册的声明

- 公共的声明

- 私有的声明

 

a）标注中注册的声明（建议不强制使用）

​	·iss (issuer)			签发人

​	·exp (expiration time)		过期时间

​	·sub (subject)			主题

​	·aud (audience)			受众用户

​	·nbf (Not Before)			在此之前不可用

​	·iat (Issued At)			签发时间

​	·jti (JWT ID)			JWT唯一标识，能用于防止JWT重复使用

 

b）公共的声明（用户自定义）：

公共的声明可以添加任何的信息，一般添加用户的相关信息或其它业务需要的必要信息，但不建议添加敏感信息，因为该部分在客户端可解密；

 

c）私有的声明

私有的声明是提供者和消费者功能定义的声明，一般不建议存放敏感信息，因为base64是对称解密的，意味着该部分信息可以归类为名文信息。

 

定义一个payload

```json
{ "sub": "1234567890", "name": "John Doe", "admin": true }

```

然后将其base64加密，得到jwt的一部分

​	eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9



##### Signature

jwt的第三部分是一个签证信息，这个签证信息由三部分组成：

​	·header(base64后的)

​	·payload(base64后的)

​	·secred

 

这个部分需要base64加密后的header和base64加密后的payload使用“.”连接组成的字符串，然后通过header中声明的加密方式进行加secret组合加密，然后就构成了jwt的第三部分。将这三部分用“.”连接成一个完整的字符串，构成了最终的jwt：

eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ

 

注意：secret是保存在服务器端的，jwt的签发也是在服务端的，secret就是用来进行jwt的签发和jwt的验证，所以它就是你服务端的私钥，在任何场景都不应该流露出去，一旦客户端得知这个secret，那就意味着客户端可以自我签发jwt了



##### 流程

·一种做法是放在HTTP请求的头信息字段里面，格式如下：

Token: <token>

 

·另一种做法是，JWT就放在POST请求的数据体里面。

服务端会验证token，如果验证通过就会返回相应的资源，整个流程就是这样

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210719094230.png" alt="image-20210719094230501" style="zoom:50%;" />

详细流程(时序图)

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210719094259.png" alt="image-20210719094259072" style="zoom:50%;" />



### SpringBoot中使用JWT（高  40）

#### 在父项目中引入redis依赖

```xml
<!--redis-->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-redis</artifactId>
    <version>2.3.7.RELEASE</version>
</dependency>

```



#### 在commons模块中导入jwt、Redis、jackson依赖

```xml
<!-- JWT -->
<dependency>
	<groupId>com.auth0</groupId>
	<artifactId>java-jwt</artifactId>
	<version>3.4.0</version>
</dependency>
<!--redis-->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-redis</artifactId>
</dependency>
<!--jackson-->
<dependency>
    <groupId>com.fasterxml.jackson.core</groupId>
    <artifactId>jackson-databind</artifactId>
    <version>2.12.3</version>
</dependency>

```



##### 在commons模块中创建JWT用到的工具类和枚举

```java
package com.commons.enums;

public enum TokenEnum {
    TOKEN_EXPIRE,TOKEN_BAD,TOKEN_SUCCESS
}

```

```java
package com.commons.utils;

import java.util.Date;

import com.auth0.jwt.JWT;
import com.auth0.jwt.JWTVerifier;
import com.auth0.jwt.algorithms.Algorithm;
import com.auth0.jwt.exceptions.TokenExpiredException;
import com.commons.enums.TokenEnum;

public class JWTUtil {
    public static final String SECRET_KEY = "123456"; //秘钥
    public static final long TOKEN_EXPIRE_TIME = 1 * 60 * 1000; //token过期时间
    public static final long REFRESH_TOKEN_EXPIRE_TIME = 10 * 60 * 1000; //refreshToken过期时间
    private static final String ISSUER = "issuer"; //签发人

    /**
     * 生成签名
     */
    public static String generateToken(String uname){
        Date now = new Date();
        //创建签名算法对象
        Algorithm algorithm = Algorithm.HMAC256(SECRET_KEY); //算法

        String token = JWT.create()
                .withIssuer(ISSUER) //签发人
                .withIssuedAt(now)  //签发时间
                .withExpiresAt(new Date(now.getTime() + TOKEN_EXPIRE_TIME)) //过期时间
                .withClaim("uname", uname) //保存身份标识
                .sign(algorithm);
        return token;
    }

    /**
     * 验证token
     */
    public static TokenEnum verify(String token){
        try {
            //签名算法
            Algorithm algorithm = Algorithm.HMAC256(SECRET_KEY); //算法
            JWTVerifier verifier = JWT.require(algorithm)
                    .withIssuer(ISSUER)
                    .build();
            verifier.verify(token);
            return TokenEnum.TOKEN_SUCCESS;
        } catch (TokenExpiredException ex){
            return TokenEnum.TOKEN_EXPIRE;
            //ex.printStackTrace();
        } catch (Exception e) {
            return TokenEnum.TOKEN_BAD;
        }
    }

    /**
     * 从token获取uname
     */
    public static String getUname(String token){
        try{
            return JWT.decode(token).getClaim("uname").asString();
        }catch(Exception ex){
            ex.printStackTrace();
        }
        return "";
    }
}

```



##### 在commons模块中添加Redis配置类

```java
package com.commons.configuration;

import org.springframework.cache.annotation.CachingConfigurerSupport;
import org.springframework.cache.annotation.EnableCaching;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.data.redis.connection.RedisConnectionFactory;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer;
import org.springframework.data.redis.serializer.StringRedisSerializer;

import com.fasterxml.jackson.annotation.JsonAutoDetect;
import com.fasterxml.jackson.annotation.PropertyAccessor;
import com.fasterxml.jackson.databind.ObjectMapper;

@EnableCaching
@Configuration
public class RedisConfiguration extends CachingConfigurerSupport{

    @Bean
    @SuppressWarnings("all")
    public RedisTemplate<String, Object> redisTemplate(RedisConnectionFactory factory) {
        RedisTemplate<String, Object> template  = new RedisTemplate<>();
        //设置工厂
        template.setConnectionFactory(factory);
        //使用Jackson2JsonRedisSerializer来序列化和反序列化redis的value值（默认使用JDK的序列化方式）
        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer =
                new Jackson2JsonRedisSerializer<>(Object.class);
        //创建对象映射
        ObjectMapper mapper = new ObjectMapper();
        //指定要序列化的域，field,get和set,以及修饰符范围，ANY是都有包括private和public
        mapper.setVisibility(PropertyAccessor.ALL,JsonAutoDetect.Visibility.ANY);
        //指定序列化输入的类型，类必须是非final修饰的，final修饰的类，比如String,Integer等会抛出异常
        mapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);
        //
        jackson2JsonRedisSerializer.setObjectMapper(mapper);
        //字符串序列化器
        StringRedisSerializer stringRedisSerializer = new StringRedisSerializer();
        //key采用String的序列化方式
        template.setKeySerializer(stringRedisSerializer);
        //hash的key也采用String的方式
        template.setHashKeySerializer(stringRedisSerializer);
        //value采用jackson的方式
        template.setValueSerializer(jackson2JsonRedisSerializer);
        //hash的value也采用Jackson
        template.setHashValueSerializer(jackson2JsonRedisSerializer);

        template.afterPropertiesSet();
        return template;
    }
}

```



#### 创建auth模块，导入web、eureka依赖

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210719100717.png" alt="image-20210719100717522" style="zoom:33%;" />

##### auth中指定父项目

```xml
<parent>
   <artifactId>springcloud-teach</artifactId>
   <groupId>com.woniuxy</groupId>
   <version>1.0</version>
</parent>

```



##### 父项目指定子模块

```xml
<modules>
    <module>auth</module>
</modules>

```



##### 在auth中引入commons模块，主要是引入Redis

```xml
<dependency>
    <groupId>com.woniuxy</groupId>
    <artifactId>commons</artifactId>
    <version>1.0</version>
</dependency>

```



##### 在auth主启动类上开启eureka

```java
@SpringBootApplication
@EnableEurekaClient
public class AuthApplication {
    public static void main(String[] args) {
        SpringApplication.run(AuthApplication.class, args);
    }
}

```



##### 在auth中添加controller

```java
package com.woniuxy.auth.controller;

import com.woniuxy.auth.entity.User;
import com.woniuxy.commons.util.JWTUtil;
import com.woniuxy.commons.util.ResStatus;
import com.woniuxy.commons.util.ResponseResult;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestBody;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

import javax.servlet.http.HttpServletResponse;

@RestController
@RequestMapping("/user")
public class AuthController {

    //认证
    @PostMapping("/login")
    public ResponseResult<Object> login(@RequestBody User user, HttpServletResponse response){
        // 先通过账号去数据库中查询用户信息，然后对比密码

        // 假设用户认证成功
        // 生成token
        String token = JWTUtil.generateToken(user.getUname());

        // 将token放到redis

        // 将token放到响应头，返回给前端
        response.setHeader("Authorization",token);
        // 暴露头：为了能够在前端代码中能访问到token
        response.setHeader("Access-Control-Expose-Headers","Authorization");

        // 返回登录的结果
        ResponseResult<Object> responseResult = new ResponseResult<>();
        responseResult.setCode(200);
        responseResult.setStatus(ResStatus.LOGIN_SUCCESS);
        responseResult.setMsg("登录成功");

        return responseResult;
    }
    //鉴权
}

```

#### 运行eureka、auth，请求login方法

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210719150917.png" alt="image-20210719150917101" style="zoom: 25%;" />

得到数据表明OK



### Gateway网关鉴权+JWT（高 60）

#### gateway微服务中添加全局过滤器

```java
package com.woniuxy.gateway.filter;

import com.fasterxml.jackson.databind.ObjectMapper;
import com.woniuxy.commons.util.JWTUtil;
import com.woniuxy.commons.util.ResStatus;
import com.woniuxy.commons.util.ResponseResult;
import com.woniuxy.commons.util.TokenEnum;
import org.springframework.cloud.gateway.filter.GatewayFilterChain;
import org.springframework.cloud.gateway.filter.GlobalFilter;
import org.springframework.core.Ordered;
import org.springframework.core.io.buffer.DataBuffer;
import org.springframework.http.server.reactive.ServerHttpRequest;
import org.springframework.http.server.reactive.ServerHttpResponse;
import org.springframework.stereotype.Component;
import org.springframework.web.server.ServerWebExchange;
import reactor.core.publisher.Mono;

import java.util.Arrays;
import java.util.List;

/**
 * 自定义过滤器实现根据uri判断是否需要认证、token是否合法
 */

@Component
public class AuthFilter implements GlobalFilter, Ordered {
    // 执行过滤的操作：写具体的业务
    @Override
    public Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) {
        //1.获取uri
        ServerHttpRequest request = exchange.getRequest();
        String uri = request.getURI().getPath();
        System.out.println(uri + "===============");

        // 获取response对象
        ServerHttpResponse response = exchange.getResponse();

        //2.判断该uri是否需要认证
        if (requireAuth(uri)){
            //3.需要认证
            System.out.println("需要认证");

            //4.去请求头中获取token
            // 如果请求头中没有Authorization，获取到的list的值为null
            List<String> tokens = request.getHeaders().get("Authorization");
            if (tokens != null){
                String token = tokens.get(0);
                System.out.println(token);

                //5.校验token
                TokenEnum result = JWTUtil.verify(token);
                if (result != TokenEnum.TOKEN_SUCCESS){
                    // 过期、非法
                    return goLogin(response);
                }

            }else {
                // 没token，返回结果叫别人去登录
                return goLogin(response);
            }
        }

        return chain.filter(exchange);  // 放行
    }

    // 返回结果：叫用户登录
    private Mono<Void> goLogin(ServerHttpResponse response) {
        // 设置响应头
        response.getHeaders().add("Content-Type","application/json;charset=utf-8");

        // 返回的数据
        ResponseResult<Object> responseResult = new ResponseResult<>();
        responseResult.setCode(401);
        responseResult.setStatus(ResStatus.NO_LOGIN);
        responseResult.setMsg("请登录");

        try {
            // 将对象转换成JSON
            String data = new ObjectMapper().writeValueAsString(responseResult);

            // 将数据返回给浏览器、并停止当前请求
            DataBuffer buffer = response.bufferFactory().wrap(data.getBytes());

            return response.writeWith(Mono.just(buffer));
        }catch (Exception e){
            e.printStackTrace();
        }
        return null;
    }

    // 判断uri是否需要认证
    private boolean requireAuth(String uri){
        // 罗列所有不需要认证的uri：uri别写死，应该在配置文件、数据库中去指定
        // 假设加载到了uri信息
        List<String> no_auth_uri = Arrays.asList("/user/login","/user/regist");

        // 遍历判断当前uri是否需要认证
        for(String nau : no_auth_uri){
            if (uri.startsWith(nau))  return false;
        }

        return true;
    }


    @Override
    public int getOrder() {
        return 0;
    }
}

```

# day04

#### gateway微服务中添加全局过滤器

```java
package com.woniuxy.gateway.filter;

import com.commons.enums.TokenEnum;
import com.commons.result.ResponseResult;
import com.commons.utils.JWTUtil;
import com.fasterxml.jackson.databind.ObjectMapper;
import org.springframework.cloud.gateway.filter.GatewayFilterChain;
import org.springframework.cloud.gateway.filter.GlobalFilter;
import org.springframework.core.Ordered;
import org.springframework.core.io.buffer.DataBuffer;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.http.server.reactive.ServerHttpRequest;
import org.springframework.http.server.reactive.ServerHttpResponse;
import org.springframework.stereotype.Component;
import org.springframework.web.server.ServerWebExchange;
import reactor.core.publisher.Mono;

import javax.annotation.Resource;
import java.nio.charset.StandardCharsets;
import java.util.Arrays;
import java.util.List;

@Component
public class CustomFilter implements GlobalFilter, Ordered {
    @Resource
    private RedisTemplate<String,Object> redisTemplate;

    /**
     * 过滤器执行过滤代码
     */
    @Override
    public Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) {
        //准备数据
        ResponseResult<Object> result = new ResponseResult<>(500,"error",null);
        byte[] data = null;

        //获取request对象
        ServerHttpRequest request = exchange.getRequest();
        //获取response对象
        ServerHttpResponse response = exchange.getResponse();

        //获取请求的URL
        String path = request.getPath().toString();

        //判断是否需要认证
        if (requireAuth(path)){
            //获取请求头
            List<String> refreshTokens = request.getHeaders().get("refreshToken");
            //获取token
            List<String> tokens = request.getHeaders().get("authorization");

            //判断是否有refreshToken
            if (refreshTokens == null || !redisTemplate.hasKey(refreshTokens.get(0)) || tokens == null || JWTUtil.verify(tokens.get(0))== TokenEnum.TOKEN_BAD) {
                //没登录
                try {
                    data = new ObjectMapper().writeValueAsString(result).getBytes(StandardCharsets.UTF_8);
                } catch (Exception e) {
                    e.printStackTrace();
                }
                //创建数据缓存对象
                DataBuffer buffer = response.bufferFactory().wrap(data);
                //设置响应头
                response.getHeaders().add("Content-Type", "application/json;charset=utf-8");
                //中断请求
                //response.setComplete();
                //返回数据
                return response.writeWith(Mono.just(buffer));
            }
            System.out.println(JWTUtil.verify(tokens.get(0)));
            //如果token过期
            if (JWTUtil.verify(tokens.get(0)) == TokenEnum.TOKEN_EXPIRE){
                //生成新的token，并设置到响应头
                String token = JWTUtil.generateToken(JWTUtil.getUname(tokens.get(0)));
                response.getHeaders().add("authorization",token);
                //暴露头
                response.getHeaders().add("Access-Control-Expose-Headers", "authentication");

            }
        }
        //
        //继续执行
        return chain.filter(exchange);
    }

    /*
     * 指定过滤器的顺序，值越小越先执行
     */
    @Override
    public int getOrder() {
        return 0;
    }

    //验证请求的URL是否需要认证
    private boolean requireAuth(String path){
        //需要认证操作的url
        List<String> paths = Arrays.asList(
                "/goods",
                "/order"
        );
        for (String url: paths){
            if (path.startsWith(url)) return true;
        }
        return false;
    }
}
```



#### 在commons中添加自定义注解

```java
package com.commons.annotations;

import java.lang.annotation.*;

@Documented
@Retention(RetentionPolicy.RUNTIME)
@Target(ElementType.METHOD)
public @interface RequirePerms {
    String value();
}
```



##### 在commons中引入spring boot web依赖

```xml
<!--web-->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-web</artifactId>
    <version>2.3.7.RELEASE</version>
</dependency>
```



##### 在commons中自定义拦截器

```java
package com.commons.interceptors;

import com.commons.annotations.RequirePerms;
import com.commons.result.ResponseResult;
import com.commons.service.AuthService;
import com.commons.utils.JWTUtil;
import com.fasterxml.jackson.databind.ObjectMapper;
import org.springframework.stereotype.Component;
import org.springframework.web.method.HandlerMethod;
import org.springframework.web.servlet.handler.HandlerInterceptorAdapter;

import javax.annotation.Resource;
import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpServletResponse;
import java.lang.reflect.Method;


@Component
public class Authinterceptor extends HandlerInterceptorAdapter {

    @Resource
    private AuthService authService;

    @Override
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {
        //得到token
        String token = request.getHeader("authorization");
        System.out.println("拦截器:"+token);

        //方法
        if (handler instanceof HandlerMethod){
            HandlerMethod handlerMethod = (HandlerMethod)handler;
            //
            Method method = handlerMethod.getMethod();
            //
            if (method.isAnnotationPresent(RequirePerms.class)){
                //得到权限信息
                RequirePerms requirePerms = method.getDeclaredAnnotation(RequirePerms.class);
                String perms = requirePerms.value();
                
                //得到账号
                String account = JWTUtil.getUname(token);
                
                //使用token和perms请求auth模块的验证权限方法
                ResponseResult<String> result = authService.isPerms(account,perms);
                if (result.getMessage().equals("success")){
                    //有权限，放行
                    return true;
                }else {
                    //没有权限   返回结果
                    response.setContentType("application/json;charset=utf-8");
                    try {
                        response.getWriter().write(new ObjectMapper().writeValueAsString(result));
                    }catch (Exception e){
                        e.printStackTrace();
                    }
                    return false;
                }
            }
        }
        return super.preHandle(request, response, handler);
    }
}
```



##### 在commons中添加AuthService接口

```java
package com.commons.service;

import com.commons.result.ResponseResult;
import org.springframework.cloud.openfeign.FeignClient;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;


@FeignClient(name = "AUTH")
public interface AuthService {
    //校验权限
    @GetMapping("/auth/isPerms/{account}/{perms}")
    public ResponseResult<String> isPerms(@PathVariable("account") String account, @PathVariable("perms") String perms);

}
```



#### 在auth的AuthController中添加对应方法

```java
@RestController
@RequestMapping("/auth")
public class AuthController {
	//.....其它代码....
    //校验权限
    @GetMapping("/isPerms/{account}/{perms}")
    public ResponseResult<String> isPerms(@PathVariable("account") String account,@PathVariable("perms") String perms){
        //校验权限
        System.out.println("校验权限"+account+","+perms);
        if (new Random().nextInt(2) == 1){
            //
            return new ResponseResult<>(200,"success",null);
        }
        //
        return new ResponseResult<>(500,"你没有权限",null);
    }
}
```



#### 在commons中添加拦截器配置类

```java
package com.commons.interceptors.configuration;

import com.commons.interceptors.Authinterceptor;
import org.springframework.context.annotation.Configuration;
import org.springframework.web.servlet.config.annotation.InterceptorRegistry;
import org.springframework.web.servlet.config.annotation.WebMvcConfigurer;

import javax.annotation.Resource;

@Configuration
public class InterceptorConfiguration implements WebMvcConfigurer {
    @Resource
    private Authinterceptor authinterceptor;

    @Override
    public void addInterceptors(InterceptorRegistry registry) {
        registry.addInterceptor(authinterceptor).addPathPatterns("/**");
    }
}
```



#### 在provider的controller对应方法上添加注解，指定访问的权限

```java
@RequirePerms("goods:all")
@GetMapping("/all")
@HystrixCommand(fallbackMethod = "fallback")
public List<Goods> all(){
    System.out.println(port);
    return Arrays.asList(
            new Goods(1001,"手机"),
            new Goods(1002,"电脑")
    );
}
```



##### 在provider的主启动类上开启相关注解

```java
@SpringBootApplication(scanBasePackages = "com")//扫描到拦截器
@EnableEurekaClient
@EnableCircuitBreaker
@EnableFeignClients(basePackages = "com.commons.service")//得到openfeign对象
public class ProviderApplication {

    public static void main(String[] args) {
        SpringApplication.run(ProviderApplication.class, args);
    }

}

```



#### auth加载时排除拦截器

```java
@SpringBootApplication
@EnableEurekaClient
@ComponentScan(basePackages = "com.woniuxy",
        excludeFilters = @ComponentScan.Filter(
                type = FilterType.REGEX,
                pattern = "com.woniuxy.commons.interceptor.*")
)
public class AuthApplication {

    public static void main(String[] args) {
        SpringApplication.run(AuthApplication.class, args);
    }

}

```



#### gateway的commons包中去掉web模块

```xml
<dependency>
    <groupId>com.woniuxy</groupId>
    <artifactId>commons</artifactId>
    <version>1.0</version>
    <exclusions>
        <exclusion>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </exclusion>
    </exclusions>
</dependency>

```



#### gateway禁止加载拦截器

```java
@SpringBootApplication
@EnableEurekaClient
@EnableCircuitBreaker
@ComponentScan(basePackages = "com.woniuxy",
        excludeFilters = @ComponentScan.Filter(
                type = FilterType.REGEX,
                pattern = "com.woniuxy.commons.interceptor.*")
)
public class GatewayApplication {

    public static void main(String[] args) {
        SpringApplication.run(GatewayApplication.class, args);
    }

}

```

<font color='red'>**注意：不能在@SpringBootApplication扫包然后在@ComponentScan排除包，因为只要配置了@ComponentScan则@SpringBootApplication就失效了**</font>

依次运行eureka、provider、auth、gateway模块进行测试



#### 注意

- 如果出现调用某个微服务只有第一次成功，后序的请求报500错误，（后台日志包404错误：feign.FeignException$NotFound: [404] during   -需要设置日志级别为debug才能看到），可能的原因是该微服务的ribbon赋值均衡配置的问题，应该写成以下方式

```java
@Configuration
@RibbonClient(name = "goods",configuration = RandomRule.class)
public class RibbonConfiguration {
//    @Bean
//    public IRule rule(){
//        return new RandomRule();
//    }
}

```

通过@RibbonClient指定对应微服务的负载均衡策略





#### 解决openfeign调用token丢失问题

在commons中添加openfeign拦截器配置，实现**RequestInterceptor**接口

```java
package com.woniuxy.commons.config;

import feign.RequestInterceptor;
import feign.RequestTemplate;
import org.springframework.context.annotation.Configuration;
import org.springframework.web.context.request.RequestContextHolder;
import org.springframework.web.context.request.ServletRequestAttributes;

import javax.servlet.http.HttpServletRequest;

@Configuration
public class FeignConfig implements RequestInterceptor {
    @Override
    public void apply(RequestTemplate template) {
        //获取到request
        ServletRequestAttributes attributes = (ServletRequestAttributes)RequestContextHolder.getRequestAttributes();
        HttpServletRequest request = attributes.getRequest();
        //将token添加到头上
        template.header("authorization",request.getHeader("authorization"));
    }
}

```

但是如果feign接口熔断机制为线程模式，此时可能会导致hystrix熔断机制失效，出现以下异常

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211011142202.png" alt="image-20211011142202417" style="zoom:50%;" />

##### 出现该错误原因

在feign调用之前，拦截器 RequestInterceptor实现类里面有使用到ServletRequestAttributes 获取请求数据，当feign开启熔断模式的时候，feign 调用会失败 （feign: hystrix: enabled: true）

**原因**

feign 使用的是线程池模式，当开启熔断的时候，feign 所在的服务端不在同一个线程，这是attributes取到的将会是空值

**解决方案**
将hystrix熔断方式从线程模式改为信号量模式

**strategy: SEMAPHORE**

```yaml
feign:
  hystrix:
    enabled: true
  client:
    config:
      default:
        connectTimeout: 100000
        readTimeout: 100000
hystrix:
 command:
   default:
     execution:
       isolation:
         thread:
           timeoutInMilliseconds: 30000
         strategy: SEMAPHORE  
ribbon:
  ReadTimeout: 60000
  ConnectTimeout: 60000

```





# day05

### 分布式事务基本概念（中 15）

#### 产生的背景

在微服务环境下，因为会根据不同的业务将拆分成不同的服务，比如会员服务、订单服务、商品服务等等，每个服务都有自己独立的数据库并且是独立运行的，互不影响的。服务与服务之间通讯采用RPC远程调用技术，但是每个服务中都有自己独立的数据源，即自己独立的本地事务；两个服务相互进行通讯的时候，两个本地事务互不影响，从而出现分布式事务产生的原因。

 

传统项目大部分情况下，不会产生分布式事务，但是在项目中如果采用多数据源的方式就会产生分布式事务；

 

案例：

假设银行(bank)中有两个客户(name)张三和李四

我们需要将张三的1000元存款(sal)转到李四的账户上

目标就是张三账户减1000，李四账户加1000，不能出现中间步骤(张三减1000，李四没加)

 

#### 事务

·原子性（A）

所谓的原子性就是说，在整个事务中的所有操作，要么全部完成，要么全部不做，没有中间状态。对于事务在执行中发生错误，所有的操作都会被回滚，整个事务就像从没被执行过一样。

·一致性（C）

事务的执行必须保证系统的一致性，就拿转账为例，A有500元，B有300元，如果在一个事务里A成功转给B50元，那么不管并发多少，不管发生什么，只要事务执行成功了，那么最后A账户一定是450元，B账户一定是350元。

·隔离性（I）

所谓的隔离性就是说，事务与事务之间不会互相影响，一个事务的中间状态不会被其他事务感知。

·持久性（D）

所谓的持久性，就是说一单事务完成了，那么事务对数据所做的变更就完全保存在了数据库中，即使发生停电，系统宕机也是如此。

 

#### 微服务落地存在的问题

虽然微服务现在如火如荼，但对其实践其实仍处于探索阶段。很多中小型互联网公司，鉴于经验、技术实力等问题，微服务落地比较困难，目前存在的主要困难有如下几方面：

1）单体应用拆分为分布式系统后，进程间的通讯机制和故障处理措施变的更加复杂。

2）系统微服务化后，一个看似简单的功能，内部可能需要调用多个服务并操作多个数据库实现，服务调用的分布式事务问题变的非常突出。

3）微服务数量众多，其测试、部署、监控等都变的更加困难。

 

随着RPC框架的成熟，第一个问题已经逐渐得到解决。例如dubbo可以支持多种通讯协议，springcloud可以非常好的支持restful调用。对于第三个问题，随着docker、devops技术的发展以及各公有云paas平台自动化运维工具的推出，微服务的测试、部署与运维会变得越来越容易。

 

而对于第二个问题，现在还没有通用方案很好的解决微服务产生的事务问题。分布式事务已经成为微服务落地最大的阻碍，也是最具挑战性的一个技术难题。



### 解决方案（中  15）

#### 基于消息的最终一致性方案

例如：RocketMQ、rabbitMQ等

消息一致性方案是通过消息中间件保证上、下游应用数据操作的一致性。基本思路是将本地操作和发送消息放在一个事务中，保证本地操作和消息发送要么两者都成功或者都失败。下游应用向消息系统订阅该消息，收到消息后执行相应操作。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720114130.png" alt="image-20210720114129917" style="zoom:50%;" />

- 实现：业务处理服务在业务事务提交之前，向实时消息服务请求发送消息，实时消息服务只记录消息数据，而不是真正的发送。业务处理服务在业务事务提交之后，向实时消息服务确认发送。只有在得到确认发送指令后，实时消息服务才会真正发送。
- 消息：业务处理服务在业务事务回滚后，向实时消息服务取消发送。消息发送状态确认系统定期找到未确认发送或者回滚发送的消息，向业务处理服务询问消息状态，业务处理服务根据消息ID或者消息内容确认该消息是否有效。被动方的处理结果不会影响主动方的处理结果，被动方的消息处理操作是幂等操作。
- 成本：可靠的消息系统建设成本，一次消息发送需要两次请求，业务处理服务需要实现消息状态回查接口。
- 优点：消息数据独立存储，独立伸缩，降低业务系统和消息系统之间的耦合。对最终一致性时间敏感度较高，降低业务被动方的实现成本。兼容所有实现JMS标准的MQ中间件，确保业务数据可靠的前提下，实现业务的最终一致性，理想状态下是准实时的一致性。



消息方案从本质上讲是将分布式事务转换为两个本地事务，然后依靠下游业务的重试机制达到最终一致性。基于消息的最终一致性方案对应用侵入性也很高，应用需要进行大量业务改造，成本较高。



#### TCC事务补偿型方案

<div align="center">
<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720110954.png" alt="image-20210720110954541" style="zoom:50%;;" />
</div>


- 实现：业务应用负责发起并完成整个业务活动。其它业务服务提供TCC型业务操作。事务协调器控制业务活动的一致性，它登记业务活动的操作，并在业务活动提交时确认所有的TCC型操作的Confirm操作，在业务活动取消时调用所有TCC型操作的Cancel操作。
- 成本：实现TCC操作的成本较高，业务活动结束的时候Confirm和Cancel操作的执行成本。业务活动的日志成本。
- 使用范围：强隔离性，严格一致性要求的业务活动。适用于执行时间较短的业务，比如处理账户或者收费等等。
- 特点：不与具体的服务框架耦合，位于业务服务层，而不是资源层，可以灵活的选择业务资源的锁定粒度。TCC里对每个服务资源操作的是本地事务，数据被锁住的时间短，可扩展性好，可以说是为独立部署的SOA服务而设计的。



#### 最大努力通知型

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720115527.png" alt="image-20210720115527200" style="zoom:50%;" />

- 实现：业务活动的主动方在完成处理之后向业务活动的被动方发送消息，允许消息丢失。业务活动的被动方根据定时策略，向业务活动的主动方查询，恢复丢失的业务消息。
- 约束：被动方的处理结果不影响主动方的处理结果。
- 成本：业务查询与校对系统的建设成本。
- 使用范围：对业务最终一致性的时间敏感度低。跨企业的业务活动。
- 特点：业务活动的主动方在完成业务处理之后，向业务活动的被动方发送通知消息。主动方可以设置时间阶梯通知规则，在通知失败后按规则重复通知，知道通知N次后不再通知。主动方提供校对查询接口给被动方按需校对查询，用户恢复丢失的业务消息。
- 适用范围：银行通知，商户通知。



### Seata基础（中 15）

#### 背景

2019年1月，阿里巴巴中间件团队发起了开源项目 Fescar（Fast & EaSy Commit And Rollback），和社区一起共建开源分布式事务解决方案。Fescar 的愿景是让分布式事务的使用像本地事务的使用一样，简单和高效，并逐步解决开发者们遇到的分布式事务方面的所有难题。

 

Fescar 开源后，蚂蚁金服加入 Fescar 社区参与共建，并在 Fescar 0.4.0 版本中贡献了 TCC 模式。

 

为了打造更中立、更开放、生态更加丰富的分布式事务开源社区，经过社区核心成员的投票，大家决定对 Fescar 进行品牌升级，并更名为 Seata，意为：Simple Extensible Autonomous Transaction Architecture，是一套一站式分布式事务解决方案。

 

Seata 项目地址：https://github.com/seata/seata

 

Seata 是一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata 将为用户提供了 AT、TCC、SAGA 和 XA 事务模式，为用户打造一站式的分布式解决方案。



#### 专业术语

##### TC(Transaction Coordinator) - 事务协调器

​			维护全局和分支事务的状态，驱动全局事务提交或回滚。

##### TM(Transaction Manager) - 事务管理器

​			定义全局事务的范围：开始全局事务、提交或回滚全局事务。

##### RM(Resource Manager) - 资源管理器

​			管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720165056.png" alt="image-20210720165055913" style="zoom:67%;" />

#### 下载地址

https://github.com/seata/seata/releases



### Seata安装（中 15）

#### seata-server

a）备份seata-server中的conf/file.conf、registry.conf

b）修改file.conf

##### 设置自定义事务组名称

<div align="center">
<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720121915.png" alt="image-20210720121915344" style="zoom: 50%;" />
</div>


##### 修改日志存储模式为db,事务信息用db存储

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720122112.png" alt="image-20210720122112796" style="zoom: 50%;" />


##### 修改数据库配置

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720122209.png" alt="image-20210720122209354" style="zoom:50%;" />

#### 修改registry.conf文件，指定注册中心及其地址

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720122246.png" alt="image-20210720122246019" style="zoom:50%;" />

#### 准备数据库

**<font color='red'>注意：seata管理的表必须设置主键</font>**

```sql
-- seata
DROP DATABASE IF EXISTS seata;
CREATE DATABASE seata DEFAULT CHARACTER SET utf8;
USE seata;
-- the table to store GlobalSession data
DROP TABLE IF EXISTS `global_table`;
CREATE TABLE `global_table` (
  `xid` VARCHAR(128)  NOT NULL,
  `transaction_id` BIGINT,
  `status` TINYINT NOT NULL,
  `application_id` VARCHAR(32),
  `transaction_service_group` VARCHAR(32),
  `transaction_name` VARCHAR(128),
  `timeout` INT,
  `begin_time` BIGINT,
  `application_data` VARCHAR(2000),
  `gmt_create` DATETIME,
  `gmt_modified` DATETIME,
  PRIMARY KEY (`xid`),
  KEY `idx_gmt_modified_status` (`gmt_modified`, `status`),
  KEY `idx_transaction_id` (`transaction_id`)
);

-- the table to store BranchSession data
DROP TABLE IF EXISTS `branch_table`;
CREATE TABLE `branch_table` (
  `branch_id` BIGINT NOT NULL,
  `xid` VARCHAR(128) NOT NULL,
  `transaction_id` BIGINT ,
  `resource_group_id` VARCHAR(32),
  `resource_id` VARCHAR(256) ,
  `lock_key` VARCHAR(128) ,
  `branch_type` VARCHAR(8) ,
  `status` TINYINT,
  `client_id` VARCHAR(64),
  `application_data` VARCHAR(2000),
  `gmt_create` DATETIME,
  `gmt_modified` DATETIME,
  PRIMARY KEY (`branch_id`),
  KEY `idx_xid` (`xid`)
);

-- the table to store lock data
DROP TABLE IF EXISTS `lock_table`;
CREATE TABLE `lock_table` (
  `row_key` VARCHAR(128) NOT NULL,
  `xid` VARCHAR(96),
  `transaction_id` LONG ,
  `branch_id` LONG,
  `resource_id` VARCHAR(256) ,
  `table_name` VARCHAR(32) ,
  `pk` VARCHAR(36) ,
  `gmt_create` DATETIME ,
  `gmt_modified` DATETIME,
  PRIMARY KEY(`row_key`)
);
-- the table to store seata xid data  回滚日志表
DROP TABLE `undo_log`;
CREATE TABLE `undo_log` (
  `id` BIGINT(20) NOT NULL AUTO_INCREMENT,
  `branch_id` BIGINT(20) NOT NULL,
  `xid` VARCHAR(100) NOT NULL,
  `context` VARCHAR(128) NOT NULL,
  `rollback_info` LONGBLOB NOT NULL,
  `log_status` INT(11) NOT NULL,
  `log_created` DATETIME NOT NULL,
  `log_modified` DATETIME NOT NULL,
  `ext` VARCHAR(100) DEFAULT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `ux_undo_log` (`xid`,`branch_id`)
) ENGINE=INNODB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;

-- bank_a
DROP DATABASE IF EXISTS bank_a;
CREATE DATABASE bank_a DEFAULT CHARACTER SET utf8;
USE bank_a;
CREATE TABLE bank_a(
	id INT PRIMARY KEY,
	money INT,
	`user` CHAR(20)
); 
INSERT INTO bank_a VALUES(1001,5000,'zhangsan');
-- the table to store seata xid data
DROP TABLE `undo_log`;
CREATE TABLE `undo_log` (
  `id` BIGINT(20) NOT NULL AUTO_INCREMENT,
  `branch_id` BIGINT(20) NOT NULL,
  `xid` VARCHAR(100) NOT NULL,
  `context` VARCHAR(128) NOT NULL,
  `rollback_info` LONGBLOB NOT NULL,
  `log_status` INT(11) NOT NULL,
  `log_created` DATETIME NOT NULL,
  `log_modified` DATETIME NOT NULL,
  `ext` VARCHAR(100) DEFAULT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `ux_undo_log` (`xid`,`branch_id`)
) ENGINE=INNODB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;

-- bank_b
DROP DATABASE IF EXISTS bank_b;
CREATE DATABASE bank_b DEFAULT CHARACTER SET utf8;
USE bank_b;
CREATE TABLE bank_b(
	id INT PRIMARY KEY,
	money INT,
	`user` CHAR(20)
); 
INSERT INTO bank_b VALUES(2001,5000,'lisi');
-- the table to store seata xid data
DROP TABLE `undo_log`;
CREATE TABLE `undo_log` (
  `id` BIGINT(20) NOT NULL AUTO_INCREMENT,
  `branch_id` BIGINT(20) NOT NULL,
  `xid` VARCHAR(100) NOT NULL,
  `context` VARCHAR(128) NOT NULL,
  `rollback_info` LONGBLOB NOT NULL,
  `log_status` INT(11) NOT NULL,
  `log_created` DATETIME NOT NULL,
  `log_modified` DATETIME NOT NULL,
  `ext` VARCHAR(100) DEFAULT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `ux_undo_log` (`xid`,`branch_id`)
) ENGINE=INNODB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;
```



##### 启动eureka，然后双击seata/bin/seata-server.bat运行seata服务器，出现以下信息运行成功

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720121646.png" alt="image-20210720121646560" style="zoom: 33%;" />




### SpringBoot整合Seata（高 50）

#### 在commons模块中创建Bank实体类

```java
package com.commons.entity;

import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;

@Data
@NoArgsConstructor
@AllArgsConstructor
public class Bank {
    private int id;
    private int money;
    private String user;
}
```



#### 创建bankB模块

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720160831.png" alt="image-20210720160831510" style="zoom: 50%;" />

##### 在pom.xml中导入druid连接池、父项目依赖，以及改造seata依赖

```xml
<parent>
    <artifactId>springcloud-teach</artifactId>
    <groupId>com.woniuxy</groupId>
    <version>1.0</version>
</parent>
```

```xml
<!--公共模块-->
<dependency>
    <groupId>com.woniuxy</groupId>
    <artifactId>commons</artifactId>
    <version>1.0</version>
</dependency>

<!--druid-->
<dependency>
    <groupId>com.alibaba</groupId>
    <artifactId>druid</artifactId>
    <version>1.1.15</version>
</dependency>
<!--seata-->
<dependency>
    <groupId>com.alibaba.cloud</groupId>
    <artifactId>spring-cloud-starter-alibaba-seata</artifactId>
    <version>2.1.0.RELEASE</version>
    <exclusions>
        <exclusion>
            <groupId>io.seata</groupId>
            <artifactId>seata-all</artifactId>
        </exclusion>
    </exclusions>
</dependency>
<dependency>
    <groupId>io.seata</groupId>
    <artifactId>seata-all</artifactId>
    <version>0.9.0</version>
</dependency>
```



##### 将seata-server中的file.conf文件拷贝到resources目录下，并修改代码，如下：

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720161312.png" alt="image-20210720161312144" style="zoom:50%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720161346.png" alt="image-20210720161346144" style="zoom: 50%;" />



##### 将seata-server中的registry.conf文件拷贝到resources目录下，并修改代码，如下：

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720161444.png" alt="image-20210720161443901" style="zoom:50%;" />



##### 在application.yml中添加以下配置

```yaml
server:
  port: 8182
mybatis:
  mapperLocations: classpath:mapper/*.xml
  typeAliasesPackage: com.commons.entity
spring:
  application:
    name: bank-b
  cloud:
    alibaba:
      seata:
        tx-service-group: fsp_tx_group
  datasource:
    driver-class-name: com.mysql.jdbc.Driver
    url: jdbc:mysql://127.0.0.1:3306/bank_b?useUnicode=true&characterEncoding=utf8&serverTimezone=UTC
    username: root
    password: root
eureka:
  instance:
    hostname: localhost
    prefer-ip-address: true
  client:
    serviceUrl:
      defaultZone: http://127.0.0.1:9001/eureka/
logging:
  level:
    io:
      seata: info
```



##### 创建数据源配置类

```java
package com.woniuxy.bankb.configuration;

import com.alibaba.druid.pool.DruidDataSource;
import io.seata.rm.datasource.DataSourceProxy;
import org.apache.ibatis.session.SqlSessionFactory;
import org.mybatis.spring.SqlSessionFactoryBean;
import org.mybatis.spring.transaction.SpringManagedTransactionFactory;
import org.springframework.boot.context.properties.ConfigurationProperties;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.Primary;
import org.springframework.core.io.support.PathMatchingResourcePatternResolver;

import javax.sql.DataSource;


@Configuration
public class DataSourceConfiguration {
    /*
     * @ConfigurationProperties用于application.yml中的配置信息
     * prefix：前缀定义了读取到application.yml中哪些属性，在创建完对象之后，在加入IOC
     * 容器里面之后会自动给该对象的属性赋值
     */
    @Bean
    @ConfigurationProperties(prefix = "spring.datasource")
    public DataSource druidDataSource(){
        DruidDataSource druidDataSource = new DruidDataSource();
        return druidDataSource;
    }
    /*
     * 设置DataSource代理，主要目的是让mybatis在获取datasource时获取到由druid代理的dataSource
     * 能够让seata管理到数据库的操作，实现分布式事务
     * 通过DataSourceProxy能在业务代码的事务提交时，seata通过这个切入点，来给TC发送RM的处理结果
     *
     * 当一个接口有2个不同实现时,使用@Autowired注解时会报
     * org.springframework.beans.factory.NoUniqueBeanDefinitionException异常信息
     * Primary用于高速spring在不知道该注入哪个bean时，优先使用选择该bean
     *
     * DataSourceProxy extends AbstractDataSourceProxy
     * AbstractDataSourceProxy implements javax.sql.DataSource
     *
     */
    @Primary
    @Bean("dataSource")
    public DataSourceProxy dataSource(DataSource druidDataSource){
        return new DataSourceProxy(druidDataSource);
    }

    /*
     * 创建SqlSessionFactory
     */
    @Bean
    public SqlSessionFactory sqlSessionFactory(DataSourceProxy dataSourceProxy)throws Exception{
        SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean();
        //设置数据源   javax.sql.DataSource
        sqlSessionFactoryBean.setDataSource(dataSourceProxy);
        //加载mapper文件
        sqlSessionFactoryBean.setMapperLocations(new PathMatchingResourcePatternResolver()
                .getResources("classpath*:/mapper/*.xml"));
        //设置事务工厂，用于创建事务
        sqlSessionFactoryBean.setTransactionFactory(new SpringManagedTransactionFactory());
        //创建工厂对象
        return sqlSessionFactoryBean.getObject();
    }
}
```



##### 创建mapper接口

```java
package com.woniuxy.bankb.mapper;

import com.commons.entity.Bank;
import org.apache.ibatis.annotations.Mapper;

@Mapper
public interface BankMapper {
    //加钱
    public int update(Bank bank);
}
```



##### 在resources下创建mapper目录，并创建mapper.xml

```xml
<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd" >
<mapper namespace="com.woniuxy.bankb.mapper.BankMapper" >
    <update id="update">
    update bank_b set money = money + #{money} where id=#{id};
  </update>
</mapper>
```



##### 创建service接口及实现类

```java
package com.woniuxy.bankb.service;

import com.commons.entity.Bank;

public interface BankService {
    public int update(Bank bank);
}

```

##### 实现类

```java
package com.woniuxy.bankb.service.impl;

import com.commons.entity.Bank;
import com.woniuxy.bankb.service.BankService;
import com.woniuxy.bankb.mapper.BankMapper;
import io.seata.spring.annotation.GlobalTransactional;
import org.springframework.stereotype.Service;

import javax.annotation.Resource;

@Service
public class BankServiceImpl implements BankService {
    @Resource
    private BankMapper bankMapper;

    @Override
    public int update(Bank bank) {
        int res = bankMapper.update(bank);
        return res;
    }
}

```



##### 创建controller

```java
package com.woniuxy.bankb.controller;

import com.commons.entity.Bank;
import com.woniuxy.bankb.service.BankService;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

import javax.annotation.Resource;

@RestController
@RequestMapping("/bankb")
public class BankBController {
    @Resource
    private BankService bankService;

    @RequestMapping("/update/{id}/{money}")
    public String update(@PathVariable("id") int id,@PathVariable("money") int money){
        Bank bank = new Bank(id,money,null);
        if (bankService.update(bank) > 0){
            return "success";
        }
        return "error";
    }
}

```



##### 在主启动类上开启eureka、禁止springboot自动注入数据源配置**<font color='red'>DataSourceAutoConfiguration</font>**

```java
package com.woniuxy.bankb;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration;
import org.springframework.cloud.netflix.eureka.EnableEurekaClient;

/*
 * 禁止springboot自动注入数据源配置，不让springboot给mybatis注入默认数据源
 */
@SpringBootApplication(exclude = DataSourceAutoConfiguration.class)
@EnableEurekaClient
public class BankbApplication {

    public static void main(String[] args) {
        SpringApplication.run(BankbApplication.class, args);
    }

}

```



##### 在commons模块中添加BankB的service接口

```java
package com.commons.service;

import org.springframework.cloud.openfeign.FeignClient;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.RequestMapping;

@FeignClient(name = "BANK-B")
public interface BankBService {
    @RequestMapping("/bankb/update/{id}/{money}")
    public String update(@PathVariable("id") int id, @PathVariable("money") int money);
}

```



#### 创建bankA模块

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720160831.png" alt="image-20210720160831510" style="zoom: 50%;" />

在pom.xml中导入druid连接池、父项目依赖，以及改造seata依赖

```xml
<parent>
    <artifactId>springcloud-teach</artifactId>
    <groupId>com.woniuxy</groupId>
    <version>1.0</version>
</parent>

```

```xml
<!--公共模块-->
<dependency>
    <groupId>com.woniuxy</groupId>
    <artifactId>commons</artifactId>
    <version>1.0</version>
</dependency>

<!--druid-->
<dependency>
    <groupId>com.alibaba</groupId>
    <artifactId>druid</artifactId>
    <version>1.1.15</version>
</dependency>
<!--seata-->
<dependency>
    <groupId>com.alibaba.cloud</groupId>
    <artifactId>spring-cloud-starter-alibaba-seata</artifactId>
    <version>2.1.0.RELEASE</version>
    <exclusions>
        <exclusion>
            <groupId>io.seata</groupId>
            <artifactId>seata-all</artifactId>
        </exclusion>
    </exclusions>
</dependency>
<dependency>
    <groupId>io.seata</groupId>
    <artifactId>seata-all</artifactId>
    <version>0.9.0</version>
</dependency>

```



##### 将seata-server中的file.conf文件拷贝到resources目录下，并修改代码，如下：

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720161312.png" alt="image-20210720161312144" style="zoom:50%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720162543.png" alt="image-20210720162543602" style="zoom:50%;" />



##### 将seata-server中的registry.conf文件拷贝到resources目录下，并修改代码，如下：

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720161444.png" alt="image-20210720161443901" style="zoom:50%;" />

##### 在application.yml中添加以下配置

```yaml
server:
  port: 8181
mybatis:
  mapperLocations: classpath:mapper/*.xml
  typeAliasesPackage: com.commons.entity
spring:
  application:
    name: bank-a
  cloud:
    alibaba:
      seata:
        tx-service-group: fsp_tx_group
  datasource:
    driver-class-name: com.mysql.jdbc.Driver
    url: jdbc:mysql://127.0.0.1:3306/bank_a?useUnicode=true&characterEncoding=utf8&serverTimezone=UTC
    username: root
    password: root
eureka:
  instance:
    hostname: localhost
    prefer-ip-address: true
  client:
    serviceUrl:
      defaultZone: http://127.0.0.1:9001/eureka/
logging:
  level:
    io:
      seata: info

```



##### 创建数据源配置类

```java
package com.woniuxy.bankb.configuration;

import com.alibaba.druid.pool.DruidDataSource;
import io.seata.rm.datasource.DataSourceProxy;
import org.apache.ibatis.session.SqlSessionFactory;
import org.mybatis.spring.SqlSessionFactoryBean;
import org.mybatis.spring.transaction.SpringManagedTransactionFactory;
import org.springframework.boot.context.properties.ConfigurationProperties;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.Primary;
import org.springframework.core.io.support.PathMatchingResourcePatternResolver;

import javax.sql.DataSource;


@Configuration
public class DataSourceConfiguration {
    /*
     * @ConfigurationProperties用于application.yml中的配置信息
     * prefix：前缀定义了读取到application.yml中哪些属性，在创建完对象之后，在加入IOC
     * 容器里面之后会自动给该对象的属性赋值
     */
    @Bean
    @ConfigurationProperties(prefix = "spring.datasource")
    public DataSource druidDataSource(){
        DruidDataSource druidDataSource = new DruidDataSource();
        return druidDataSource;
    }
    /*
     * 设置DataSource代理，主要目的是让mybatis在获取datasource时获取到由druid代理的dataSource
     * 能够让seata管理到数据库的操作，实现分布式事务
     * 通过DataSourceProxy能在业务代码的事务提交时，seata通过这个切入点，来给TC发送RM的处理结果
     *
     * 当一个接口有2个不同实现时,使用@Autowired注解时会报
     * org.springframework.beans.factory.NoUniqueBeanDefinitionException异常信息
     * Primary用于高速spring在不知道该注入哪个bean时，优先使用选择该bean
     *
     * DataSourceProxy extends AbstractDataSourceProxy
     * AbstractDataSourceProxy implements javax.sql.DataSource
     *
     */
    @Primary
    @Bean("dataSource")
    public DataSourceProxy dataSource(DataSource druidDataSource){
        return new DataSourceProxy(druidDataSource);
    }

    /*
     * 创建SqlSessionFactory
     */
    @Bean
    public SqlSessionFactory sqlSessionFactory(DataSourceProxy dataSourceProxy)throws Exception{
        SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean();
        //设置数据源   javax.sql.DataSource
        sqlSessionFactoryBean.setDataSource(dataSourceProxy);
        //加载mapper文件
        sqlSessionFactoryBean.setMapperLocations(new PathMatchingResourcePatternResolver()
                .getResources("classpath*:/mapper/*.xml"));
        //设置事务工厂，用于创建事务
        sqlSessionFactoryBean.setTransactionFactory(new SpringManagedTransactionFactory());
        //创建工厂对象
        return sqlSessionFactoryBean.getObject();
    }
}

```



##### 创建mapper

```java
package com.woniuxy.banka.mapper;

import com.commons.entity.Bank;
import org.apache.ibatis.annotations.Mapper;

@Mapper
public interface BankMapper {
    //减钱
    public int update(Bank bank);
}

```

##### resources下创建mapper/xml文件

```xml
<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd" >
<mapper namespace="com.woniuxy.banka.mapper.BankMapper" >
    <update id="update">
    update bank_a set money = money - #{money} where id=#{id};
  </update>
</mapper>

```



##### 创建service及实现类

```java
package com.woniuxy.banka.service;

import com.commons.entity.Bank;

public interface BankAService {
    public int update(Bank src, Bank dest);
}

```



实现类**<font color='red'>@GlobalTransactional，全局事务，只需要加在业务发起方即可</font>**

```java
package com.woniuxy.banka.service.impl;

import com.commons.entity.Bank;
import com.commons.service.BankBService;
import com.woniuxy.banka.mapper.BankMapper;
import com.woniuxy.banka.service.BankAService;
import io.seata.spring.annotation.GlobalTransactional;
import org.springframework.stereotype.Service;

import javax.annotation.Resource;

@Service
public class BankServiceImpl implements BankAService {
    @Resource
    private BankMapper bankMapper;

    @Resource
    private BankBService bankBService;

    @Override
    @GlobalTransactional
    public int update(Bank src, Bank dest) {
        //1.先修改对方+钱
        String result = bankBService.update(dest.getId(), dest.getMoney());
        //模拟运行时异常
        int n = 1;
        if (n==1) {
            throw new RuntimeException();   //模拟异常
        }
        int res = 0;
        if (result.equals("success")) {
            //加钱成功
            //2.减自己的
            res = bankMapper.update(src);
        }
        return res;
    }
}


```



##### 创建controller

```java
package com.woniuxy.banka.controller;

import com.commons.entity.Bank;
import com.woniuxy.banka.service.BankAService;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

import javax.annotation.Resource;

@RestController
@RequestMapping("/banka")
public class BankAController {
    @Resource
    private BankAService bankAService;

    @RequestMapping("/start")
    public String begin(){
        Bank src = new Bank(1001,100,"zhangsan");	    //转出账户
        Bank dest = new Bank(2001, 100, "lisi");        //转入账户
        if(bankAService.update(src,dest)>0){
            return "转账成功!";
        }
        return "转账失败!";
    }
}

```



##### 分别启动eureka、seata、bankb、banka，确保后三者都注册到seata中，后两者都注册到seata中

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720163237.png" alt="image-20210720163236771" style="zoom: 33%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720163304.png" alt="image-20210720163303773" style="zoom: 33%;" />







### AT模式（高 30）

#### 基于XA协议的两阶段提交方案（2pc）

X/Open DTP(X/Open Distributed Transaction Processing Reference Model) 是X/Open 这个组织定义的一套分布式事务的标准，也就是了定义了规范和API接口，由各个厂商进行具体的实现。 X/Open DTP 定义了三个组件： AP，TM，RM

<div align="center">
<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720165131.jpg" alt="img" style="zoom:50%;" /> 
</div>

 

·AP(Application Program)	

也就是应用程序，可以理解为使用DTP(分布式事务处理)的程序

·RM(Resource Manager)

资源管理器，这里可以理解为一个DBMS系统，或者消息服务器管理系统，应用程序通过资源管理器对资源进行控制。资源必须实现XA定义的接口

·TM(Transaction Manager)

事务管理器，负责协调和管理事务，提供给AP应用程序编程接口以及管理资源管理器

 

其中在DTP定义了以下几个概念：

| 概念     | 解释                                                         |
| -------- | ------------------------------------------------------------ |
| 事务     | 一个事务是一个完整的工作单元，由多个独立的计算任务组成，这多个任务在逻辑上是原子的 |
| 全局事务 | 对于一次性操作多个资源管理器的事务，就是全局事务。           |
| 分支事务 | 在全局事务中，某一个资源管理器有自己独立的任务，这些任务的集合作为这个资源管理器的分支任务。 |
| 控制线程 | 用来表示一个工作线程，主要是关联AP,TM,RM三者的一个线程，也就是事务上下文环境。<br />简单的说，就是需要标识一个全局事务以及分支事务的关系 |

消息中间件与数据库通过 XA 接口规范，使用两阶段(2PC)提交来完成一个全局事务， XA 规范的基础是两阶段提交协议。

·第一阶段是准备阶段，所有参与者都将本事务能否成功的信息反馈发给协调者；

·第二阶段是提交阶段，协调者根据所有参与者的反馈，通知所有参与者，步调一致地在所有分支上提交或者回滚。


<div align="center">
<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720165156.png" alt="image-20210720165156022" style="zoom: 50%;" />
</div>

#### seata AT模式

Seata AT模式是基于XA事务演进而来的一个分布式事务中间件，XA是一个基于数据库实现的分布式事务协议，本质上和两阶段提交一样，需要数据库支持，Mysql5.6以上版本支持XA协议，其他数据库如Oracle，DB2也实现了XA接口

 

基本处理逻辑如下：

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720163932.png" alt="image-20210720163932837" style="zoom:67%;" />

##### 第一阶段

Seata 的 JDBC 数据源代理通过对业务 SQL 的解析，把业务数据在更新前后的数据镜像组织成回滚日志，利用本地事务 的 ACID 特性，将业务数据的更新和回滚日志的写入在同一个 本地事务 中提交。

 

这样，可以保证：**任何提交的业务数据的更新一定有相应的回滚日志存在**

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720163955.png" alt="image-20210720163955686" style="zoom:67%;" />

基于这样的机制，分支的本地事务便可以在全局事务的第一阶段提交，并马上释放本地事务锁定的资源。

 

这也是Seata和XA事务的不同之处，两阶段提交往往对资源的锁定需要持续到第二阶段实际的提交或者回滚操作，而有了回滚日志之后，可以在第一阶段释放对资源的锁定，降低了锁范围，提高效率，即使第二阶段发生异常需要回滚，只需找对undolog中对应数据并反解析成sql来达到回滚目的。

 

同时Seata通过代理数据源将业务sql的执行解析成undolog来与业务数据的更新同时入库，达到了对业务无侵入的效果。



##### 第二阶段

如果决议是全局提交，此时分支事务此时已经完成提交，不需要同步协调处理（只需要异步清理回滚日志），第二节段可以非常快速地完成。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720164033.png" alt="image-20210720164033242" style="zoom:67%;" />

如果决议是全局回滚，RM 收到协调器发来的回滚请求，通过 XID 和 Branch ID 找到相应的回滚日志记录，通过回滚记录生成反向的更新 SQL 并执行，以完成分支的回滚。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720164053.png" alt="image-20210720164052932" style="zoom:67%;" />



### Config概述（中 10）

Config分布式配置中心的概念及作用

 <img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210719210621.png" alt="image-20210719210621454" style="zoom:33%;" />

#### 基本概念

随着线上项目变的日益庞大,每个项目都散落着各种配置文件，如果采用分布式的开发模式，需要的配置文件随着服务增加而不断增多。某一个基础服务信息变更,都会引起一系列的更新和重启, 运维苦不堪言也容易出错。配置中心便是解决此类问题的灵丹妙药。

 

·简化集群yml文件配置

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210719210647.png" alt="image-20210719210647481" style="zoom: 67%;" />

目前支持本地存储、Git 以及SVN。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210719210707.png" alt="image-20210719210707304" style="zoom:67%;" />



Spring Cloud Config分服务端和客户端,服务端负责将git( svn )中存储的配置文件发布成REST接口,客户端可以从服务端REST接口获取配置。但客户端并不能主动感知到配置的变化,从而主动去获取新的配置，这需要每个客户端通过POST方法触发各自的/refresh。



### Config搭建（高 20）

搭建Config配置中心，微服务与配置中心通信

#### 配置文件

##### 先在gitee上创建一个远程仓库

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210719210859.png" alt="image-20210719210859320" style="zoom: 25%;" />

##### 本地创建一个文件夹，将远程仓库克隆到其中

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210719211145.png" alt="image-20210719211145266" style="zoom:33%;" />

##### 在克隆下来的文件夹中创建application.yml文件，添加以下内容并保存

```yaml
spring: 
    profiles: dev   #开发环境
    application: 
        name: provider-dev
 
---
 
 spring: 
    profiles: test   #测试环境
    application: 
        name: provider-test

---

spring: 
    profiles: pro   #生产环境
    application: 
        name: provider-pro 

```

**<font color='red'>注意：编码集一定要设置成UTF-8</font>**

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210719211527.png" alt="image-20210719211527305" style="zoom: 50%;" />

##### 添加application.yml到缓存区中

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210719211340.png" alt="image-20210719211340601" style="zoom:33%;" />

##### 提交	git commit -m "add file application.yml

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210719211721.png" alt="image-20210719211721464" style="zoom:33%;" />

##### 推送到远程仓库	git push origin master

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210719211943.png" alt="image-20210719211943061" style="zoom:33%;" />

#### 创建config模块

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210719212339.png" alt="image-20210719212339402" style="zoom:33%;" />

##### 如果出现config-server引入失败，可以自定义引入版本

```xml
<!--config-server-->
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-config-server</artifactId>
    <version>2.1.1.RELEASE</version>
    <exclusions>
        <exclusion>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-config-client</artifactId>
        </exclusion>
    </exclusions>
</dependency>
<!--config-client-->
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-config-client</artifactId>
    <version>2.1.1.RELEASE</version>
</dependency>

```

##### 在主启动类上开启eureka和config

```java
@SpringBootApplication
@EnableConfigServer
@EnableEurekaClient
public class ConfigApplication {

    public static void main(String[] args) {
        SpringApplication.run(ConfigApplication.class, args);
    }

}

```

##### 在application.yml中添加配置信息

```yaml
server:
  port: 7000

spring:
  application:
    name: config
  cloud:
    config:
      server:
        git:
          uri: https://gitee.com/xiangweilll/config-79.git  #仓库地址
          #search-paths: config-repo      #仓库下的相对地址，可以有多个，用逗号隔开
          username: xiangweilll   #账号
          password: xw20200401    #密码
eureka:
  client: #客户端注册到eureka列表中
    service-url:
      defaultZone: http://127.0.0.1:9001/eureka
  instance:
    instance-id: config-7000  #注册中心status显示出来的微服务id
    prefer-ip-address: true #显示访问url

```

##### 依次运行eureka、config

##### 浏览器上访问配置中心，获取配置信息

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210719214657.png" alt="image-20210719214657078" style="zoom:33%;" />

或者

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210719214730.png" alt="image-20210719214730709" style="zoom:33%;" />

#### 配置中心访问规则

```
/{application}/{profile}[/{label}]
/{application}-{profile}.yml
/{label}/{application}-{profile}.yml
/{application}-{profile}.properties
/{label}/{application}-{profile}.properties

```



#### 模拟需要从配置中心获取配置文件的微服务

##### 在本地仓库中添加application-client.yml配置文件

```yml
server: 
  port: 7500
 
spring: 
  profile: dev      #开发环境
  application:
    name: config-client-dev #当前项目的名字

eureka:
  client: #客户端注册到eureka列表中
    service-url:
      defaultZone: http://localhost:9001/eureka/
  instance:
    instance-id: config-client  #配置中心显示出来的微服务名称
    prefer-ip-address: true #显示访问url

---

server: 
  port: 7500
 
spring: 
  profile: test      #开发环境
  application:
    name: config-client-test #当前项目的名字

eureka:
  client: #客户端注册到eureka列表中
    service-url:
      defaultZone: http://localhost:9001/eureka/
  instance:
    instance-id: config-test  #配置中心显示出来的微服务名称
    prefer-ip-address: true #显示访问url 

```

##### 并推送到远程仓库

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210719215919.png" alt="image-20210719215919792" style="zoom:33%;" />



##### 创建config-client微服务

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210719215213.png" alt="image-20210719215212841" style="zoom:33%;" />

如果config依赖导入不了，自定义导入

```xml
<!--config-client-->
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-config-client</artifactId>
    <version>2.1.1.RELEASE</version>
</dependency>

```



在config-client下创建bootstrap.yml，并添加以下配置

```yaml
#连接config-server服务
spring:
  cloud:
    config:
      name: application-client    #要读取配置文件的名字
      profile: test                 #要加载的环境
      label: master                 #git上的哪个分支
      uri: http://localhost:7000  #连接到config-server的路径

```



为了方便观察效果，创建一个controller，用于得到从git上过去到的配置文件信息

```java
@RestController
public class ClientController {
    @Value("${spring.application.name}")
    private String applicationName;

    @RequestMapping("/name")
    public String name(){
        return applicationName;
    }
}

```



在主启动类上开启eureka

```java
@SpringBootApplication
@EnableEurekaClient
public class ConfigClientApplication {

    public static void main(String[] args) {
        SpringApplication.run(ConfigClientApplication.class, args);
    }

}

```

分别启动eureka、config、config-client，通过浏览器访问config-client，正常情况下可以得到配置信息，如下图所示

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210719220403.png" alt="image-20210719220403570" style="zoom:33%;" />



# Redis相关

### Redis的简介（15）

Redis中文网：http://www.redis.cn/

 

Redis是一种NoSql（NoSQL，泛指非关系型的数据库）数据库，区别于关系数据库，它们不保证关系数据的ACID特性。NoSQL是一项全新的数据库革命性运动，其拥护者们提倡运用非关系型的数据存储，相对于铺天盖地的关系型数据库运用，这一概念无疑是一种全新的思维的注入。NoSQL有如下优点：易扩展，NoSQL数据库种类繁多，但是一个共同的特点都是去掉关系数据库的关系型特性。数据之间无关系，这样就非常容易扩展。无形之间也在架构的层面上带来了可扩展的能力。大数据量，高性能，NoSQL数据库都具有非常高的读写性能，尤其在大数据量下，同样表现优秀。这得益于它的无关系性，数据库的结构简单。

 

Redis 是完全开源免费的，遵守BSD协议，是一个高性能的key-value数据库。

Redis 与其他 key - value 缓存产品有以下三个特点：

- Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。

- Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。

- Redis支持数据的备份，即master-slave模式的数据备份。

 

#### Redis 优势

- 性能极高 – Redis能读的速度是220000次/s,写的速度是162000次/s 。  redis5  redis6

- 丰富的数据类型 – Redis支持二进制案例的 String, List, Hash, Set 及 Ordered Set 数据类型操作。

- 原子 – Redis的所有操作都是原子性的，意思就是要么成功执行要么失败完全不执行。单个操作是原子性的。多个操作也支持事务，即原子性，通过MULTI和EXEC指令包起来。

- 丰富的特性 – Redis还支持 publish/subscribe, 通知, key 过期等等特性。

 

#### 为什么要用Redis

##### Redis都可以干什么事儿

- 缓存，毫无疑问这是Redis当今最为人熟知的使用场景。再提升服务器性能方面非常有效；

- 排行榜，如果使用传统的关系型数据库来做这个事儿，非常的麻烦，而利用Redis的SortSet数据结构能够非常方便搞定；

- 计算器/限速器，利用Redis中原子性的自增操作，我们可以统计类似用户点赞数、用户访问数等，这类操作如果用MySQL，频繁的读写会带来相当大的压力；限速器比较典型的使用场景是限制某个用户访问某个API的频率，常用的有抢购时，防止用户疯狂点击带来不必要的压力；

- 好友关系，利用集合的一些命令，比如求交集、并集、差集等。可以方便搞定一些共同好友、共同爱好之类的功能；

- 简单消息队列，除了Redis自身的发布/订阅模式，我们也可以利用List来实现一个队列机制，比如：到货通知、邮件发送之类的需求，不需要高可靠，但是会带来非常大的DB压力，完全可以用List来完成异步解耦；

- Session共享（spring session），以PHP为例，默认Session是保存在服务器的文件中，如果是集群服务，同一个用户过来可能落在不同机器上，这就会导致用户频繁登陆；采用Redis保存Session后，无论用户落在那台机器上都能够获取到对应的Session信息。

##### Redis不能干什么事儿

Redis感觉能干的事情特别多，但它不是万能的，合适的地方用它事半功倍。如果滥用可能导致系统的不稳定、成本增高等问题。

比如，用Redis去保存用户的基本信息，虽然它能够支持持久化，但是它的持久化方案并不能保证数据绝对的落地，并且还可能带来Redis性能下降，因为持久化太过频繁会增大Redis服务的压力。

简单总结就是数据量太大、数据访问频率非常低的业务都不适合使用Redis，数据太大会增加成本，访问频率太低，保存在内存中纯属浪费资源。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211018171433.png" alt="image-20211018171433449" style="zoom:50%;" /> 

#### 为什么要使用Redis

上面说了Redis的一些使用场景，那么这些场景的解决方案也有很多其它选择，比如缓存可以用Memcache，Session共享还能用MySql来实现，消息队列可以用RabbitMQ，我们为什么一定要用Redis呢？

速度快，完全基于内存，使用C语言实现，网络层使用epoll解决高并发问题，单线程模型避免了不必要的上下文切换及竞争条件；

注意：单线程仅仅是说在网络请求这一模块上用一个请求处理客户端的请求，像持久化它就会重开一个线程/进程去进行处理

丰富的数据类型，Redis有8种数据类型，当然常用的主要是 String、Hash、List、Set、 SortSet 这5种类型，他们都是基于键值的方式组织数据。每一种数据类型提供了非常丰富的操作命令，可以满足绝大部分需求，如果有特殊需求还能自己通过 lua 脚本自己创建新的命令（具备原子性）；

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211018171510.png" alt="image-20211018171510917" style="zoom:50%;" /> 

除了提供的丰富的数据类型，Redis还提供了像慢查询分析、性能测试、Pipeline、事务、Lua自定义命令、Bitmaps、HyperLogLog、发布/订阅、Geo等个性化功能。

Redis的代码开源在GitHub，代码非常简单优雅；它的编译安装也是非常的简单，没有任何的系统依赖；有非常活跃的社区，各种客户端的语言支持也是非常完善。另外它还支持事务（没用过）、持久化、主从复制让高可用、分布式成为可能。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211018171531.png" alt="image-20211018171531306" style="zoom:50%;" /> 



### Redis的安装（15）

下载地址：http://redis.io/download，下载最新稳定版本。

- 在/opt下创建redis文件夹，并即将redis-5.0.7.tar.gz拷贝到该目录下，同时解压

  mkdir /opt/redis

  cd /opt/redis

  tar -zxvf xxx.ta.gz

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211018171622.png" alt="image-20211018171622439" style="zoom:50%;" />

- 安装gcc编译器

  yum -y install gcc gcc-c++ kernel-devel

如果出现下图所示的错误

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211018171641.png" alt="image-20211018171641105" style="zoom:50%;" />

可能是系统自动升级正在运行，yum在锁定状态中，可以通过输入以下命令强制关闭yum

  rm -f /var/run/yum.pid

 然后在执行yum -y install gcc gcc-c++ kernel-devel指令安装gcc

- 进入redis-5.0.7目录，输入make MALLOC=libc命令进行安装，出现以下结果表示安装成功

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211018171701.png" alt="image-20211018171701309" style="zoom:50%;" />

- 安装redis服务

  make install

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211018171720.png" alt="image-20211018171720272" style="zoom:50%;" />

- 创建存储redis文件目录

  mkdir -p /usr/local/redis

- 复制redis-server redis-cli redis-sentinel到新建立的文件夹

  cp /opt/redis/redis-5.0.7/src/redis-server /usr/local/redis/

  cp /opt/redis/redis-5.0.7/src/redis-cli /usr/local/redis/

   cp /opt/redis/redis-5.0.7/src/redis-sentinel /usr/local/redis

- 将redis配置文件复制一份到redis目录

  cp /opt/redis/redis-5.0.7/redis.conf /usr/local/redis/

- 然后切换到该目录下，编辑redis配置文件

  cd /usr/local/redis/

  vi /usr/local/redis/redis.conf

  在bind 127.0.0.1前加“#”将其注释掉（如果有注释）

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211018171801.png" alt="image-20211018171801171" style="zoom:50%;" />

默认为保护模式，把 protected-mode yes 改为 protected-mode no

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211018171817.png" alt="image-20211018171817717" style="zoom:50%;" />

默认为不守护进程模式，把daemonize no 改为daemonize yes

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211018171830.png" alt="image-20211018171830885" style="zoom:50%;" />

- 启动redis

  redis-server redis.conf

- 通过客户端连接redis

  redis-cli -h 127.0.0.1 -p 6378

### Redis基本配置及通用命令（45）

#### 启动、停止Redis

- 启动redis

  redis-server redis.conf

  检查是否正常与运行

  ps -ef|grep redis

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211018171905.png" alt="image-20211018171905308" style="zoom:50%;" />

- 停止redis

  ./redis-cli shutdown



#### 常用配置

- daemonize  

指定redis是否为后台运行，为true表示后台运行redis，false表示前台运行redis

 

- port

指定端口号，默认为6379

 

- logfile

指定日志文件，可以记录Redis运行时信息

 

- requirepass

  指定登录密码

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211018171945.png" alt="image-20211018171945567" style="zoom:50%;" />

登录时可以不需要指定密码，能够登录上，但是没有权限进行任何操作

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211018171958.png" alt="image-20211018171958727" style="zoom:50%;" />

可以使用auth指令进行授权

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211018172010.png" alt="image-20211018172010581" style="zoom:50%;" />



#### Redis 客户端的基本语法为：

​	$ redis-cli

在远程服务上执行命令

如果需要在远程 redis 服务上执行命令，同样我们使用的也是 redis-cli 命令。

语法

​	$ redis-cli -h host -p port -a password

实例

以下实例演示了如何连接到主机为 127.0.0.1，端口为 6379 ，密码为 mypass 的 redis 服务上。

​	$redis-cli -h 127.0.0.1 -p 6379 -a "mypass"

​	redis 127.0.0.1:6379>

 

#### Redis 键(key)

Redis 键命令用于管理 redis 的键。

语法

Redis 键命令的基本语法如下：

​	redis 127.0.0.1:6379> COMMAND KEY_NAME

实例

​	redis 127.0.0.1:6379> SET myKey redis

​	OK

​	redis 127.0.0.1:6379> GET myKey

​	1

​	redis 127.0.0.1:6379> DEL myKey

​	(integer) 1

在以上实例中 DEL 是一个命令， myKey 是一个键。 如果键被删除成功，命令执行后输出 (integer) 1，否则将输出 (integer) 0

如何在get时取到它的中文呢？只需要在redis-cli 后面加上 --raw

#### 通用命令

| 命令                                 | 描述                                                         |
| ------------------------------------ | ------------------------------------------------------------ |
| DEL key                              | 该命令用于在 key 存在时删除 key                              |
| DUMP key                             | 序列化给定 key ，并返回被序列化的值                          |
| EXISTS key                           | 检查给定 key 是否存在                                        |
| EXPIRE key seconds                   | 为给定 key 设置过期时间，以秒为单位                          |
| EXPIREAT key timestamp               | EXPIREAT 的作用和 EXPIRE 类似，都用于为 key 设置过期时间。 不同在于 EXPIREAT 命令接受的时间参数是 UNIX 时间戳(unix timestamp)。 |
| PEXPIRE key milliseconds             | 设置 key 的过期时间以毫秒计。                                |
| PEXPIREAT key milliseconds-timestamp | 设置 key 过期时间的时间戳(unix timestamp) 以毫秒计           |
| KEYS pattern                         | 查找所有符合给定模式( pattern)的 key                         |
| MOVE key db                          | 将当前数据库的 key 移动到给定的数据库 db 当中                |
| PERSIST key                          | 移除 key 的过期时间，key 将持久保持                          |
| PTTL key                             | 以毫秒为单位返回 key 的剩余的过期时间                        |
| TTL key                              | 以秒为单位，返回给定 key 的剩余生存时间(TTL, time to live)   |
| RANDOMKEY                            | 从当前数据库中随机返回一个 key                               |
| RENAME key newkey                    | 修改 key 的名称                                              |
| RENAMENX key newkey                  | 仅当 newkey 不存在时，将 key 改名为 newkey                   |
| TYPE key                             | 返回 key 所储存的值的类型                                    |



### String类型（30）

#### 基本指令

string 是 redis 最基本的类型，一个 key 对应一个 value，是二进制安全的。

注意:string 类型的值最大能存储 512MB

下表列出了常用的 redis 字符串命令：

| 命令                             | 描述                                                         |
| -------------------------------- | ------------------------------------------------------------ |
| SET key value                    | 设置指定 key 的值                                            |
| GET key                          | 获取指定 key 的值                                            |
| GETRANGE key start end           | 返回 key 中字符串值的子字符[start,end]                       |
| GETSET key value                 | 将给定 key 的值设为 value ，并返回 key 的旧值(old value)     |
| GETBIT key offset                | 对key 所储存的字符串值，获取指定偏移量上的位(bit)            |
| MGET key1 [key2..]               | 获取所有(一个或多个)给定 key 的值                            |
| SETBIT key offset value          | 对key所储存的字符串值，设置或清除指定偏移量上的位(bit)       |
| SETEX key seconds value          | 将值 value 关联到 key ，并将 key 的过期时间设为 seconds (以秒为单位) |
| SETNX key value                  | 只有在 key 不存在时设置 key 的值（分布式锁）                 |
| SETRANGE key offset value        | 用 value 参数覆写给定 key 所储存的字符串值，从偏移量 offset 开始 |
| STRLEN key                       | 返回 key 所储存的字符串值的长度                              |
| MSET key value [key value ...]   | 同时设置一个或多个 key-value 对                              |
| MSETNX key value [key value ...] | 同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在 |
| PSETEX key milliseconds value    | 这个命令和 SETEX 命令相似，但它以毫秒为单位设置 key 的生存时间，而不是像 SETEX 命令那样，以秒为单位 |
| INCR key                         | 将 key 中储存的数字值增一  ++                                |
| INCRBY key increment             | 将 key 所储存的值加上给定的增量值（increment） i+=2          |
| INCRBYFLOAT key increment        | 将 key 所储存的值加上给定的浮点增量值（increment）           |
| DECR key                         | 将 key 中储存的数字值减一 --                                 |
| DECRBY key decrement             | key 所储存的值减去给定的减量值（decrement）  i-=2            |
| APPEND key value                 | 如果 key 已经存在并且是一个字符串， APPEND 命令将指定的 value 追加到该 key 原来值（value）的末尾 |

 

#### 应用场景 

- 访问量统计：每次访问博客和文章使用 INCR 命令进行递增

- 将数据以二进制序列化的方式进行存储

 

#### 业务场景

- “某某综艺”，启动海选投票，只能通过微信投票，每个微信号每天只能投1票。

- 电商商家开启热门商品推荐，热门商品不能一直处于热门期，每种商品热门期维持3天，3天后自动取消热门

- 新闻网站会出现热点新闻，热点新闻最大的特征是对时效性，如何自动控制热点新闻的时效性

- 手机验证码

- 点赞数、在线人数、点击量

 

##### 解决思路

给用户设置一个唯一的id，并为其设置一个有效时长，当时间已经超过设定时间后将id删除。

 

### List类型（20）

#### 基本指令

Redis列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）

一个列表最多可以包含 2^32 - 1 个元素 (4294967295, 每个列表超过40亿个元素)。

格式：

​	LPUSH list列表名 value1 [value2 ...]

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211018172225.png" alt="image-20211018172225822" style="zoom:50%;" />

在以上实例中我们使用了 LPUSH 将三个值插入了名为 listKey 的列表当中。

Redis 列表命令

下表列出了列表相关的基本命令：

| 命令                                  | 描述                                                         |
| ------------------------------------- | ------------------------------------------------------------ |
| BLPOP key1 [key2 ] timeout            | 移出并获取列表的第一个元素，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止 |
| BRPOP key1 [key2 ] timeout            | 移出并获取列表的最后一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止 |
| BRPOPLPUSH source destination timeout | 从列表中弹出一个值，将弹出的元素插入到另外一个列表中并返回它； 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止 |
| LINDEX key index                      | 通过索引获取列表中的元素                                     |
| LINSERT key BEFORE\|AFTER pivot value | 在列表的元素前或者后插入元素                                 |
| LLEN key                              | 获取列表长度                                                 |
| LPOP key                              | 移出并获取列表的第一个元素                                   |
| LPUSH key value1 [value2]             | 将一个或多个值插入到列表头部                                 |
| LPUSHX key value                      | 将一个值插入到已存在的列表头部                               |
| LRANGE key start stop                 | 获取列表指定范围内的元素                                     |
| LREM key count value                  | 移除列表元素                                                 |
| LSET key index value                  | 通过索引设置列表元素的值                                     |
| LTRIM key start stop                  | 对一个列表进行修剪(trim)，就是说，让列表只保留指定区间内的元素，不在指定区间之内的元素都将被删除 |
| RPOP key                              | 移除列表的最后一个元素，返回值为移除的元素                   |
| RPOPLPUSH source destination          | 移除列表的最后一个元素，并将该元素添加到另一个列表并返回     |
| RPUSH key value1 [value2]             | 在列表中添加一个或多个值                                     |
| RPUSHX key value                      | 为已存在的列表添加值                                         |

 

#### 应用场景

- 最新消息排行等功能(比如朋友圈的时间线)

- 消息队列

 

#### 业务场景

- 微信朋友圈点赞，要求按照点赞顺序显示点赞好友信息。如果取消点赞，移除对应好友信息。

- twitter、新浪微博、腾讯微博中个人用于的关注列表需要按照用户的关注顺序进行展示，粉丝列表需要将最近关注的粉丝列在前面

- 新闻、资讯类网站如何将最新的新闻或资讯按照发生的时间顺序展示

 

##### 解决方案

- 依赖list的数据具有顺序的特征对信息进行管理

- 使用队列模型解决多路信息汇总合并的问题

- 使用栈模型解决最新消息的问题

 

 ### Hash类型（20）

#### 基本指令

Redis hash 是一个键值(key=>value)对集合。

格式：

HMSET hash名 key value [key value]

存储用的是HMSET命令

获取用的是 HGET 命令

每个 hash 可以存储很多对键值对，最多可以存储2^32 -1 键值对（40多亿）。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211018172322.png" alt="image-20211018172322214" style="zoom:50%;" />

Redis hash 命令

下表列出了 redis hash 基本的相关命令：

| 命令                                           | 描述                                                  |
| ---------------------------------------------- | ----------------------------------------------------- |
| HDEL key field1 [field2]                       | 删除一个或多个哈希表字段                              |
| HEXISTS key field                              | 查看哈希表 key 中，指定的字段是否存在                 |
| HGET key field                                 | 获取存储在哈希表中指定字段的值                        |
| HGETALL key                                    | 获取在哈希表中指定 key 的所有字段和值                 |
| HINCRBY key field increment                    | 为哈希表 key 中的指定字段的整数值加上增量 increment   |
| HINCRBYFLOAT key field increment               | 为哈希表 key 中的指定字段的浮点数值加上增量 increment |
| HKEYS key                                      | 获取所有哈希表中的字段                                |
| HLEN key                                       | 获取哈希表中字段的数量                                |
| HMGET key field1 [field2]                      | 获取所有给定字段的值                                  |
| HMSET key field1 value1 [field2 value2 ]       | 同时将多个 field-value (域-值)对设置到哈希表 key 中   |
| HSET key field value                           | 将哈希表 key 中的字段 field 的值设为 value            |
| HSETNX key field value                         | 只有在字段 field 不存在时，设置哈希表字段的值         |
| HVALS key                                      | 获取哈希表中所有值                                    |
| HSCAN key cursor [MATCH pattern] [COUNT count] | 迭代哈希表中的键值对                                  |

 

#### 应用场景

存储、读取、修改对象属性，比如：用户（姓名、性别、爱好），文章（标题、发布时间、作者、内容）

 

#### 业务场景

1）电商网站购物车的设计与实现。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211018172345.png" alt="image-20211018172345787" style="zoom:50%;" />

解决方案：

- 以客户id作为key，每位客户创建一个hash存储结构存储对应的购物车信息

- 将商品编号作为field，购买数量作为value进行存储

- 添加商品:追加全新的field与value

- 遍历hash实现浏览购物车信息

- 更改数量:自增/自减，设置value值

- 删除商品:删除field

- 清空:删除key

2）Hash实现抢购，限购发放优惠券，激活码等

例如：蜗牛学院派发劳斯莱斯购车抵用券

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211018172417.png" alt="image-20211018172417624" style="zoom:50%;" />

解决方案

- 以商家id作为key

- 将参与抢购的商品id作为field

- 将参与抢购的商品数量作为对应的value

- 抢购时使用降至的方式控制产品数量



### Set类型（20）

#### 基础指令

Redis 的 Set 是 String 类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据。

Redis 中集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。

集合中最大的成员数为 2^32 - 1 (4294967295, 每个集合可存储40多亿个成员)。

格式

​	SADD Set名 value1 [value2 ...]

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211018172447.png" alt="image-20211018172446979" style="zoom:50%;" />

在以上实例中我们通过 SADD 命令向名为 setKey 的集合插入的三个元素。

Redis 集合命令

下表列出了 Redis 集合基本命令：

| 命令                                           | 描述                                                |
| ---------------------------------------------- | --------------------------------------------------- |
| SADD key member1 [member2]                     | 向集合添加一个或多个成员                            |
| SCARD key                                      | 获取集合的成员数                                    |
| SDIFF key1 [key2]                              | 返回给定所有集合的差集                              |
| SDIFFSTORE destination key1 [key2]             | 返回给定所有集合的差集并存储在 destination 中       |
| SINTER key1 [key2]                             | 返回给定所有集合的交集                              |
| SINTERSTORE destination key1 [key2]            | 返回给定所有集合的交集并存储在 destination 中       |
| SISMEMBER key member                           | 判断 member 元素是否是集合 key 的成员               |
| SMEMBERS key                                   | 返回集合中的所有成员                                |
| SMOVE source destination member                | 将 member 元素从 source 集合移动到 destination 集合 |
| SPOP key                                       | 移除并返回集合中的一个随机元素                      |
| SRANDMEMBER key [count]                        | 返回集合中一个或多个随机数                          |
| SREM key member1 [member2]                     | 移除集合中一个或多个成员                            |
| SUNION key1 [key2]                             | 返回所有给定集合的并集                              |
| SUNIONSTORE destination key1 [key2]            | 所有给定集合的并集存储在 destination 集合中         |
| SSCAN key cursor [MATCH pattern] [COUNT count] | 迭代集合中的元素                                    |

 

#### 应用场景

- 共同好友

- 利用唯一性，统计访问网站的所有独立ip

- 好友推荐时，根据tag求交集，大于某个阈值就可以推荐

 

#### 业务场景-共同好友

解决方案

- 求两个集合的交、并、差集

- 求两个集合的交、并、差集并存储到指定集合中

- 将指定数据从原始集合移动到目标集合中

 

### ZSet类型（20）

Redis 有序集合和集合一样也是string类型元素的集合,且不允许重复的成员。

不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。

有序集合的成员是唯一的,但分数(score)却可以重复。

 

集合中最大的成员数为 2^32 - 1 (4294967295, 每个集合可存储40多亿个成员)。

格式：

ZADD key score member [score member]

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211018172539.png" alt="image-20211018172539433" style="zoom:50%;" />

Redis 有序集合命令

下表列出了 redis 有序集合的基本命令:

| 命名                                           | 描述                                                         |
| ---------------------------------------------- | ------------------------------------------------------------ |
| ZADD key score1 member1 [score2 member2]       | 向有序集合添加一个或多个成员，或者更新已存在成员的分数       |
| ZCARD key                                      | 获取有序集合的成员数（length）                               |
| ZCOUNT key min max                             | 计算在有序集合中指定区间分数的成员数                         |
| ZINCRBY key increment member                   | 有序集合中对指定成员的分数加上增量 increment                 |
| ZINTERSTORE destination numkeys key [key ...]  | 计算给定的一个或多个有序集的交集并将结果集存储在新的有序集合 key 中ZINTERSTORE sum_point 2 mid_test fin_test |
| ZRANGE key start stop [WITHSCORES]             | 通过索引区间返回有序集合成指定区间内的成员                   |
| ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT] | 通过分数返回有序集合指定区间内的成员ZRANGEBYSCORE grades (1 100  1<score<=5ZRANGEBYSCORE grades (5 (100  5<score<100 |
| ZRANK key member                               | 返回有序集合中指定成员的索引                                 |
| ZREM key member [member ...]                   | 移除有序集合中的一个或多个成员                               |
| ZREMRANGEBYRANK key start stop                 | 移除有序集合中给定的排名区间的所有成员ZREMRANGEBYRANK salary 0 1    # 移除下标 0 至 1 区间内的成员 |
| ZREMRANGEBYSCORE key min max                   | 移除有序集合中给定的分数区间的所有成员ZREMRANGEBYSCORE salary 1500 3500    # 移除所有薪水在 1500 到 3500 内的员工 |
| ZREVRANGE key start stop [WITHSCORES]          | 返回有序集中指定区间内的成员，通过索引，分数从高到低ZREVRANGE salary 0 -1 WITHSCORES   # 递减排列 |
| ZREVRANK key member                            | 返回有序集合中指定成员的排名，有序集成员按分数值递减(从大到小)排序ZREVRANK salary tom    # 结果为0，tom 的工资最高 |
| ZSCORE key member                              | 返回有序集中，成员的分数值                                   |
| ZUNIONSTORE destination numkeys key [key ...]  | 计算给定的一个或多个有序集的并集，并存储在新的 key 中ZUNIONSTORE salary 2 programmer manager WEIGHTS 1 3两个集合中scope的乘法系数 |

#### 应用场景

- 排行榜，取TopN操作

- 带权重的消息队列

 

### redis事务（30）

#### 相关命令

| 命令    | 描述                                                         |
| ------- | ------------------------------------------------------------ |
| multi   | 开始事务用于标记事务块的开始。Redis会将后续的命令逐个放入队列中，然后才能使用EXEC命令原子化地执行这个命令序列。 |
| exec    | 执行事务在一个事务中执行所有先前放入队列的命令，然后恢复正常的连接状态。当使用WATCH命令时，只有当受监控的键没有被修改时，EXEC命令才会执行事务中的命令，这种方式利用了检查再设置（CAS）的机制。这个命令的返回值是一个数组，其中的每个元素分别是原子化事务中的每个命令的返回值。 当使用WATCH命令时，如果事务执行中止，那么EXEC命令就会返回一个Null值。 |
| discard | 回滚清除所有先前在一个事务中放入队列的命令，然后恢复正常的连接状态。如果使用了WATCH命令，那么DISCARD命令就会将当前连接监控的所有键取消监控。 |
| watch   | 监控指定的key当某个事务需要按条件执行时，就要使用这个命令将给定的键设置为受监控的。 |
| unwatch | 撤销监控                                                     |

 

#### 实例

以下是一个事务的例子， 它先以 MULTI 开始一个事务，然后将多个命令入队到事务中，最后由 EXEC命令触发事务， 一并执行事务中的所有命令

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211018172621.png" alt="image-20211018172621054" style="zoom:50%;" />

单个 Redis 命令的执行是原子性的，但 Redis 没有在事务上增加任何维持原子性的机制，所以 Redis 事务的执行并不是原子性的。

事务可以理解为一个打包的批量执行脚本，但批量指令并非原子化的操作，中间某条指令的失败不会导致前面已做指令的回滚，也不会造成后续的指令不做。

例如：

redis 127.0.0.1:6379> multi

OK

redis 127.0.0.1:6379> set name xiaoming

QUEUED

redis 127.0.0.1:6379> incr name

QUEUED

redis 127.0.0.1:6379> set age 10

QUEUED

redis 127.0.0.1:6379> exec

1) OK

2) (error) ERR value is not an integer or out of range 

3) OK

如果在 incr name 处失败，set name 已成功不会回滚，set age 还会继续执行。

 

在事务运行期间，虽然Redis命令可能会执行失败，但是Redis仍然会执行事务中余下的其他命令，而不会执行回滚操作，你可能会觉得这种行为很奇怪，然而，这种行为也有其合理之处：

 

只有当被调用的Redis命令有语法错误时，这条命令才会执行失败（在将这个命令放入事务队列期间，Redis能够发现此类问题），或者对某个键执行不符合其数据类型的操作：实际上，这就意味着只有程序错误才会导致Redis命令执行失败，这种错误很有可能在程序开发期间发现，一般很少在生产环境发现。

Redis已经在系统内部进行功能简化，这样可以确保更快的运行速度，因为Redis不需要事务回滚的能力。

 

#### watch

用于监控一个key，在并发情况下保证数据的安全

案例：开启两个终端，分别连接上redis，模拟两个用户操作

终端1：

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211018172647.png" alt="image-20211018172647669" style="zoom:50%;" />

终端2：

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211018172658.png" alt="image-20211018172658797" style="zoom:50%;" />

终端1：输入exec执行事务，结果为（nil）执行失败，保证了数据的安全性

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211018172712.png" alt="image-20211018172712076" style="zoom:50%;" />



### redis持久化之RDB（30）

#### redis持久化

Redis是一种高级key-value数据库。它跟memcached类似，不过数据可以持久化，而且支持的数据类型很丰富。有字符串，链表，集 合和有序集合。支持在服务器端计算集合的并，交和补集(difference)等，还支持多种排序功能。所以Redis也可以被看成是一个数据结构服务器。

Redis的所有数据都是保存在内存中，然后不定期的通过异步方式保存到磁盘上(这称为“半持久化模式”)；也可以把每一次数据变化都写入到一个append only file(aof)里面(这称为“全持久化模式”)。 

 

由于Redis的数据都存放在内存中，如果没有配置持久化，redis重启后数据就全丢失了，于是需要开启redis的持久化功能，将数据保存到磁 盘上，当redis重启后，可以从磁盘中恢复数据。redis提供两种方式进行持久化，一种是RDB持久化（原理是将Reids在内存中的数据库记录定时 dump到磁盘上的RDB持久化），另外一种是AOF（append only file）持久化（原理是将Reids的操作日志以追加的方式写入文件）。

 

- RDB：在指定的时间间隔能对你的数据进行快照存储。（默认开启）

- AOF：记录每次对服务器写的操作,当服务器重启的时候会重新执行这些命令来恢复原始的数据。（默认关闭）

 

#### RDB（快照）

##### 持久化配置

​	vi /usr/local/redis/redis.conf

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019170729.png" alt="image-20211019170729389" style="zoom:50%;" />

RDB的持久化配置

```
# 时间策略
save 900 1
save 300 10
save 60 10000

# 文件名称
dbfilename dump.rdb

# 文件保存路径  redis.conf所在目录下
dir ./

# 导入时是否检查
rdbchecksum yes
```

配置解释

- save 900 1 表示900s内如果有1条是写入命令，就触发产生一次快照，可以理解为就进行一次备份

- save 300 10 表示300s内有10条写入，就产生快照

下面的类似，那么为什么需要配置这么多条规则呢？因为Redis每个时段的读写请求肯定不是均衡的，为了平衡性能与数据安全，我们可以自由定制什么情况下触发备份。所以这里就是根据自身Redis写入情况来进行合理配置。

 

当然如果想要禁用RDB配置，也是非常容易的，只需将save 900 1等注释起来，然后在save的最后一行写上：save ""

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019170808.png" alt="image-20211019170808587" style="zoom:50%;" />

修改时间配置

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019170821.png" alt="image-20211019170821086" style="zoom:50%;" />

修改完之后一定要重启redis，输入shutdown停止redis服务器，然后进入/usr/local/redis/目录输入以下命令重启redis

redis-server ./redis.conf

然后连接redis，在2分钟内快速设置10个key-value，等待2分钟时间到了之后查看指定位置是否有指定的rdb文件

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019170839.png" alt="image-20211019170839502" style="zoom:50%;" />

##### RDB文件备份，快速恢复数据

一般在生产环境我们除了用RDB文件对redis中的数据进行备份以外，还会对RDB进行备份，以防止不小心删除RDB文件时数据丢失

- 将dump.rdb文件拷贝一份到备份位置

  cp dump.rdb abc.rdb

- shutdown关闭redis（在关闭时redis会自动备份数据到RDB文件中）

  127.0.0.1:6379>shutdown

- 删除dump.rdb文件

  rm -f dump.rdb

- 启动redis，输入keys * 查看redis中所有的key，可以看到现在是没有任何数据的

  redis-server redis.conf

  redis-cli

  127.0.0.1:6379>keys *

- shutdown关闭redis

  127.0.0.1:6379>shutdown

- 将备份的RDB文件拷贝到当前位置，名字还是叫做dump.rdb

  cp abc.rdb dump.rdb

- redis-server redis.conf重启redis，再次输入keys *，可以看到数据已经恢复

  redis-server redis.conf

  redis-cli

  127.0.0.1:6379>keys *

#### RDB的原理

在Redis中RDB持久化的触发分为两种：自己手动触发与Redis定时触发。

针对RDB方式的持久化，手动输入以下命令完成手动持久化：

- save：会阻塞当前Redis服务器，直到持久化完成，线上应该禁止使用。

- bgsave：该触发方式会fork一个子线程，由子进程负责持久化过程，因此阻塞只会发生在fork子进程的时候。

 

而自动触发的场景主要是有以下几点：

- 根据我们的 save m n 配置规则自动触发；

- 从节点全量复制时，主节点发送rdb文件给从节点完成复制操作，主节点会触发 bgsave；

- 执行 debug reload 时；

- 执行 shutdown时，如果没有开启aof，也会触发。

由于 save 基本不会被使用到，我们重点看看 bgsave 这个命令是如何完成RDB的持久化的。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019171019.png" alt="image-20211019171019469" style="zoom:50%;" />

这里注意的是 fork 操作会阻塞，导致Redis读写性能下降。我们可以控制单个Redis实例的最大内存，来尽可能降低Redis在fork时的事件消耗。

 

### redis持久化之AOF（30）

#### AOF的配置

AOF是redis的一种持久化方式，用来记录所有的写操作，但是随着时间增加，aof文件会越来越大，所以需要进行重写，将内存中的数据重新以命令的方式写入aof文件。

在重写的过程中，由于redis还会有新的写入，为了避免数据丢失，会开辟一块内存用于存放重写期间产生的写入操作，等到重写完毕后会将这块内存中的操作再追加到aof文件中。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019171041.png" alt="image-20211019171041836" style="zoom:50%;" />

```
# 是否开启aof
appendonly yes

# 文件名称
appendfilename "appendonly.aof"

# 同步方式
appendfsync everysec

# 重写触发配置
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
```

配置解释

- appendfsync everysec 它其实有三种模式:

  always			把每个写命令都立即同步到aof，很慢，但是很安全

  everysec		每秒同步一次，是折中方案

  no					redis不处理交给OS来处理，非常快，但是也最不安全

一般情况下都采用 everysec 配置，这样可以兼顾速度与安全，最多损失1s的数据。

 

- auto-aof-rewrite-percentage 是设置aof rewrite触发时机的一个参数，当当前的aof文件大小超过上一次rewrite后aof文件的百分比后触发rewrite

  例如将100改为800 ，即当前的aof文件超过上一次重写后aof文件的8倍时才会再次rewrite，这样可以保证短期内不会再次进行重写操作。

 

- auto-aof-rewrite-min-size

  aof文件重写最小的文件大小，即最开始aof文件必须要达到这个文件时才触发，后面的每次重写就不会根据这个变量了(根据上一次重写完成之后的大小).此变量仅初始化启动redis有效.如果是redis恢复时，则lastSize等于初始aof文件大小.

 

修改之后要重启redis

向redis中添加一些key-value

然后在redis文件夹下查看是否有appendonly.aof文件

 

#### 利用appendonly.aof文件恢复数据

- 关闭redis

- 重启redis

- 连接redis，输入keys *查看数据

可以看到数据只有appendonly.aof中保存的数据，redis启动时会先检查AOF文件是否存在，如果不存在就尝试加载RDB。那么为什么会优先加载AOF呢？因为AOF保存的数据更完整，通过上面的分析我们知道AOF基本上最多损失1s的数据。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019171201.png" alt="image-20211019171201896" style="zoom:50%;" />

可以删除appendonly.aof文件，然后在重启redis看看数据有哪些

 

#### AOF的原理

由于AOF 文件都是追加的，随着服务器的运行 AOF 文件会越来越大，体积过大的 AOF 文件对 redis 服务器甚至是主机都会有影响，而且在 Redis 重启时加载过大的 AOF 文件需要过多的时间，这些都是不友好的，那 Redis 是如何解决这个问题的呢？Redis 引入了重写机制来解决 AOF 文件过大的问题。

 

AOF的整个流程大体来看可以分为两步，一步是命令的实时写入（如果是 appendfsync everysec 配置，会有1s损耗），第二步是对aof文件的重写。

 

对于增量追加到文件这一步主要的流程是：命令写入→追加到aof_buf→同步到aof磁盘。那么这里为什么要先写入buf在同步到磁盘呢？如果实时写入磁盘会带来非常高的磁盘IO，影响整体性能。

 

Redis AOF 文件重写是把 Redis 进程内的数据转化为写命令同步到新 AOF 文件的过程，重写之后的 AOF 文件会比旧的 AOF 文件占更小的体积，这是由以下几个原因导致的：

- 进程内已经超时的数据不再写入文件

- 旧的 AOF 文件含有无效命令，如 del key1、hdel key2、srem keys、set a111、set a222等。重写使用进程内数据直接生成，这样新的AOF文件只保 留最终数据的写入命令

- 多条写命令可以合并为一个，如：lpush list a、lpush list b、lpush list c可以转化为：lpush list a b c。为了防止单条命令过大造成客户端缓冲区溢 出，对于 list、set、hash、zset 等类型操作，以64个元素为界拆分为多条。

 

重写之后的 AOF 文件体积更小了，不但能够节约磁盘空间，更重要的是在 Redis 数据恢复时，更小体积的 AOF 文件加载时间更短。AOF 文件重写跟 RDB 持久化一样分为手动触发和自动触发，手动触发直接调用 bgrewriteaof 命令就好了，我们后面会详细聊一聊这个命令，自动触发就需要我们在 redis.conf 中修改以下几个配置

**auto-aof-rewrite-percentage 800**

**auto-aof-rewrite-min-size 64mb**

- auto-aof-rewrite-percentage：代表当前 AOF文件空间 （aof_current_size）和上一次重写后 AOF 文件空间（aof_base_size）的比值，默认是 100%，也就是一样大的时候

- auto-aof-rewrite-min-size：表示运行 AOF 重写时 AOF 文件最小体积，默认为 64MB，也就是说 AOF 文件最小为 64MB 才有可能触发重写

满足了这两个条件，Redis 就会自动触发 AOF 文件重写，AOF 文件重写的细节跟 RDB 持久化生成快照有点类似，下面是 AOF 文件重写流程图：

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019171248.png" alt="image-20211019171248386" style="zoom:50%;" />

- 在重写期间，由于主进程依然在响应命令，为了保证最终备份的完整性；因此它依然会写入旧的AOF file中，如果重写失败，能够保证数据不丢失。

- 为了把重写期间响应的写入信息也写入到新的文件中，因此也会为子进程保留一个buf，防止新写的file丢失数据。

- 重写是直接把当前内存的数据生成对应命令，并不需要读取老的AOF文件进行分析、命令合并。

- AOF文件直接采用的文本协议，主要是兼容性好、追加方便、可读性高可认为修改修复。

不论是RDB还是AOF都是先写入一个临时文件，然后通过 rename 完成文件的替换工作。



#### RDB与AOF的区别

##### RDB存在哪些优势

- 一旦采用该方式，那么你的整个Redis数据库将只包含一个文件，这对于文件备份而言是非常完美的。比如，你可能打算每个小时归档一次最近24小时的数据，同时还要每天归档一次最近30天的数据。通过这样的备份策略，一旦系统出现灾难性故障，我们可以非常容易的进行恢复。

- 对于灾难恢复而言，RDB是非常不错的选择。因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。

- 性能最大化。对于Redis的服务进程而言，在开始持久化时，它唯一需要做的只是fork出子进程，之后再由子进程完成这些持久化的工作，这样就可以极大的避免服务进程执行IO操作了。

- 相比于AOF机制，如果数据集很大，RDB的启动效率会更高。

 

##### RDB又存在哪些劣势

- 如果你想保证数据的高可用性，即最大限度的避免数据丢失，那么RDB将不是一个很好的选择。因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。

- 由于RDB是通过fork子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是1秒钟。

 ##### AOF的优势

- 该机制可以带来更高的数据安全性，即数据持久性。Redis中提供了3种同步策略，即每秒同步、每修改同步和不同步。事实上，每秒同步也是异步完成的，其效率也是非常高的，所差的是一旦系统出现宕机现象，那么这一秒钟之内修改的数据将会丢失。而每修改同步，我们可以将其视为同步持久化，即每次发生的数据变 化都会被立即记录到磁盘中。可以预见，这种方式在效率上是最低的。至于无同步，无需多言，我想大家都能正确的理解它。

- 由于该机制对日志文件的写入操作采用的是append模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。然而如果我们本次操作只是写入了一半数据就出现了系统崩溃问题，不用担心，在Redis下一次启动之前，我们可以通过redis-check-aof（./redis-check-aof --fix appendonly.aof）工具来帮助我们解决数据一致性的问题。

- 如果日志过大，Redis可以自动启用rewrite机制。即Redis以append模式不断的将修改数据写入到老的磁盘文件中，同时Redis还会创建一个新的文件用于记录此期间有哪些修改命令被执行。因此在进行rewrite切换时可以更好的保证数据安全性。

- AOF包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作。事实上，我们也可以通过该文件完成数据的重建。

##### AOF的劣势

- 对于相同数量的数据集而言，AOF文件通常要大于RDB文件。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。

- 根据同步策略的不同，AOF在运行效率上往往会慢于RDB。总之，每秒同步策略的效率是比较高的，同步禁用策略的效率和RDB一样高效。

 

二者选择的标准，就是看系统是愿意牺牲一些性能，换取更高的缓存一致性（aof），还是愿意写操作频繁的时候，不启用备份来换取更高的性能，待手动运行save的时候，再做备份（rdb）。rdb这个就更有些 eventually consistent的意思了。

 

##### 最后

我们的Redis必须使用数据持久化吗？如果我们的Redis服务器只作为缓存使用，Redis中存储的所有数据都是从其他地方同步过来的备份，那么就没必要开启数据持久化的选项。

不过大多数应用场景下，建议至少开启RDB方式的数据持久化。Redis 对于数据备份是非常友好的， 因为我们可以在服务器运行的时候对 RDB 文件进行复制： RDB 文件一旦被创建， 就不会进行任何修改。 

当服务器要创建一个新的 RDB 文件时， 它先将文件的内容保存在一个临时文件里面， 当临时文件写入完毕时，程序才使用 rename 原子地用临时文件替换原来的 RDB 文件。

 

### redis主从复制（45）

#### 什么是主从复制

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019171458.png" alt="image-20211019171458006" style="zoom:50%;" />

主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后者称为从节点(slave),数据的复制是单向的，只能由主节点到从节点。

默认情况下，每台Redis服务器都是主节点；且一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点。

#### 主从复制的作用

- 数据冗余		主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。

- 故障恢复		当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。

- 负载均衡		在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。

- 读写分离		可以用于实现读写分离，主库写、从库读，读写分离不仅可以提高服务器的负载能力，同时可根据需求的变化，改变从库的数量；

- 高可用基石	除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。

 

#### 常见主从结构

- 一主一从：用于主节点故障转移从节点，当主节点的“写”命令并发高且需要持久化，可以只在从节点开启AOF（主节点不需要），这样即保证了数据的安全性，也避免持久化对主节点的影响

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019171600.png" alt="image-20211019171600775" style="zoom:50%;" />

- 一主多从：针对“读”较多的场景，“读”由多个从节点来分担，但节点越多，主节点同步到多节点的次数也越多，影响带宽，也加重主节点的稳定

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019171612.png" alt="image-20211019171612581" style="zoom:50%;" />

- 树状主从：一主多从的缺点（主节点推送次数多压力大）可用些方案解决，主节点只推送一次数据到从节点B，再由从节点B推送到C，减轻主节点推送的压力。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019171627.png" alt="image-20211019171627037" style="zoom:50%;" />

#### 实例演示

- 在一台电脑上模拟多个redis服务器。

一般至少需要一主两从，将redis.conf拷贝两份，分别打开修改以下内容

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019171645.png" alt="image-20211019171645240" style="zoom:50%;" />

修改以下配置

```
92 		prot	6379
158 	pidfile /var/run/redis_6379.pid
171		logfile "redis6379.log"
253		dbfilename dump6379.rdb
```



- 分别启动三台服务器

  redis-server redis6379.conf

  redis-server redis6380.conf

  redis-server redis6381.conf

- 开启三个终端连接不同的redis服务器

  redis-cli -h 127.0.0.1 -p 6379		或者		redis-cli -p 6379

  redis-cli -h 127.0.0.1 -p 6380		或者		redis-cli -p 6380

  redis-cli -h 127.0.0.1 -p 6381		或者		redis-cli -p 6381

现在三台服务器是互相独立的，没有任何联系

输入info replication 查看当前服务器的角色

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019171805.png" alt="image-20211019171805779" style="zoom:50%;" />

- 在6380、6381下输入：slaveof 127.0.0.1 6379 设置当前服务器的主机是谁

6380

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019171830.png" alt="image-20211019171830496" style="zoom:50%;" />

6379

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019171842.png" alt="image-20211019171842593" style="zoom:50%;" />

- 主机中存放内容时，会自动将数据同步到从机上

6379

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019171904.png" alt="image-20211019171904691" style="zoom:50%;" />

6380/6381

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019171914.png" alt="image-20211019171914705" style="zoom:50%;" />

在从机上不能进行set key value的操作，因为在redis中主从策略为主机做写的操作，从机做读的操作

6380/6381

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019171925.png" alt="image-20211019171925713" style="zoom:50%;" />

当从机关闭然后重新启动时，不会自动变成从机，还是需要再次指定其为从机

6380/6381

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019171943.png" alt="image-20211019171943033" style="zoom:50%;" />

当主机关闭或遇到问题停止运行，然后再次启动之后还是会做为主机，同时与从机保持主从关系

6379

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019171959.png" alt="image-20211019171959397" style="zoom:50%;" />

#### 主从复制原理

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019172013.png" alt="image-20211019172013563" style="zoom:50%;" />

### redis哨兵模式（45）

#### 哨兵模式

当主机在停机期间怎么实现功能能正常使用呢？使用哨兵机制（哨兵模式）

主从切换技术的方法是：当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间内服务不可用。这不是一种推荐的方式，更多时候，我们优先考虑哨兵模式。

##### 哨兵模式概述

哨兵模式是一种特殊的模式，首先Redis提供了哨兵的命令，哨兵是一个独立的进程，作为进程，它会独立运行。其原理是哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个Redis实例。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019172038.png" alt="image-20211019172038879" style="zoom:50%;" />

这里的哨兵有两个作用

- 通过发送命令，让Redis服务器返回监控其运行状态，包括主服务器和从服务器。

- 当哨兵监测到master宕机，会自动将slave切换成master，然后通过发布订阅模式通知其他的从服务器，修改配置文件，让它们切换主机。

然而一个哨兵进程对Redis服务器进行监控，可能会出现问题，为此，我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，这样就形成了多哨兵模式。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019172058.png" alt="image-20211019172058582" style="zoom:50%;" />

用文字描述一下**故障切换**（failover）的过程。假设主服务器宕机，哨兵1先检测到这个结果，系统并不会马上进行failover过程，仅仅是哨兵1主观的认为主服务器不可用，这个现象成为**主观下线**。当后面的哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由一个哨兵发起，进行failover操作。切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为**客观下线**。这样对于客户端而言，一切都是透明的。

 

为了方便测试，请将redis6379.conf、redis6380.conf、redis6381.conf中bind 127.0.0.1中的IP地址改为0.0.0.0

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019172111.png" alt="image-20211019172111102" style="zoom:50%;" />

##### 单个哨兵配置操作步骤

- 所有redis配置文件中的bind 127.0.0.1中的IP地址改为0.0.0.0

- 分别在所有的redis配置文件中搜索查看是否包含有 slave xxx.xxx.xxx.xxx的配置，如果有则删除。搜索字符串方式：在命令模式下输入”/要搜索的字符串”，按n搜索下一个

- 启动主机6379

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019172147.png" alt="image-20211019172146924" style="zoom:50%;" />

启动从机6380

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019172157.png" alt="image-20211019172157594" style="zoom:50%;" />

启动从机6381

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019172209.png" alt="image-20211019172209103" style="zoom:50%;" />

分别在从机6380、6381中设置主机

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019172221.png" alt="image-20211019172221283" style="zoom:50%;" />

- 在redis目录下创建sentinel6379.conf，并添加以下内容

```
protected-mode no				# 关闭保护模式，方便测试
port 26379						# 哨兵的端口
sentinel monitor mymaster 192.168.41.226 6379 1		# 192.168.41.226：主机ip 6379：端口 1：至少几个哨兵认为主机下线时进行故障切换
```

注意：不要添加注释

- 输入redis-sentinel sentinel6379.conf 启动哨兵，看到以下界面表示成功

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019172325.png" alt="image-20211019172325633" style="zoom:50%;" />

此时哨兵已经对主机以及从机进行监控

- 在主机6379中输入shutdown命令关闭主机，然后注意观察哨兵的反应（反应会有点慢）

- 哨兵

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019172343.png" alt="image-20211019172343834" style="zoom:50%;" />

可以看到现在的主机已经变成6381了，我们可以在6381上查看一下自己的身份

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019172355.png" alt="image-20211019172355607" style="zoom:50%;" />

可以看到身份已经是master了

那么如果现在原来的主机6379又重新启动，会是什么样的情况呢？

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019172408.png" alt="image-20211019172408476" style="zoom:50%;" />

可用看到原来的主机现在变为从机了

保存，并重新启动6379

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019172421.png" alt="image-20211019172421310" style="zoom:50%;" />

此时查看6380的身份，可以看到6379已经成为它的从机了

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019172434.png" alt="image-20211019172433972" style="zoom:50%;" />

##### 多哨兵操作步骤：

- 拷贝两份sentinel6379.conf，分别为命名为sentinel6380.conf、sentinel6380.conf

- 分别打开两个文件，修改sentinel的运行端口为26380、26381，同时将选举哨兵数修改成2

- 分别运行两个哨兵



### 缓存穿透（15）

#### 产生原因

程序在处理缓存时，一般是先从缓存查询，如果缓存没有这个key获取为null，则会从DB中查询，并设置到缓存中去。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019172511.png" alt="image-20211019172511807" style="zoom:33%;" />

按这种做法，那查询一个一定不存在的数据值，由于缓存是不命中时需要从数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，造成缓存穿透。

 

#### 解决办法

- 最好对于每一个缓存key都有一定的规范约束，这样在程序中对不符合parttern的key 的请求可以拒绝。（但一般key都是通过程序自动生成的）

- 将可能出现的缓存key的组合方式的所有数值以hash形式存储在一个很大的bitmap中<布隆过滤器>（需要考虑如何将这个可能出现的数据的hash值之后同步到bitmap中，后端每次新增一个可能的组合就同步一次，或者穷举），一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力

- 常用：如果对应在数据库中的数据都不存在，我们将此key对应的value设置为一个默认的值，比如“NULL”，并设置一个缓存的失效时间。当然这个key的时效比正常的时效要小的多

 

### 缓存雪崩（15）

#### 产生原因

指的是大量缓存集中在一段时间内失效，发生大量的缓存穿透，所有的查询都落在数据库上，造成了缓存雪崩。

正常情况

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019172550.png" alt="image-20211019172550805" style="zoom:33%;" />

当大量数据失效或者redis宕机

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019172601.png" alt="image-20211019172601397" style="zoom:33%;" />

#### 解决办法

- 这个没有完美解决办法，但可以分析用户行为，尽量让失效时间点均匀分布，设置不同的过期时间。缓存的过期时间用随机值，尽量让不同的key的过期时间不同（例如：定时任务新建大批量key，设置的过期时间相同）

- 可以把缓存层设计成高可用的，即使个别节点、个别机器、甚至是机房宕掉，依然可以提供服务。利用sentinel或cluster实现。

- 采用多级缓存，本地进程作为一级缓存，redis作为二级缓存，不同级别的缓存设置的超时时间不同，即使某级缓存过期了，也有其他级别缓存兜底

 

### 缓存击穿（15）

#### 产生原因

缓存击穿是指一个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，瞬间对数据库的访问压力增大。

缓存击穿这里强调的是并发，造成缓存击穿的原因有以下两个：

- 该数据没有人查询过 ，第一次就大并发的访问。（冷门数据）

- 添加到了缓存，reids有设置数据失效的时间 ，这条数据刚好失效，大并发访问（热点数据）

 

对于缓存击穿的解决方案就是加锁，具体实现的原理图如下：

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019172643.png" alt="image-20211019172643238" style="zoom:50%;" />

当用户出现大并发访问的时候，在查询缓存的时候和查询数据库的过程加锁，只能第一个进来的请求进行执行，当第一个请求把该数据放进缓存中，接下来的访问就会直接集中缓存，防止了缓存击穿。

 

业界比价普遍的一种做法，即根据key获取value值为空时，锁上，从数据库中load数据后再释放锁。若其它线程获取锁失败，则等待一段时间后重试。



#### 解决办法

- 与缓存雪崩的解决方法类似： 用加锁或者队列的方式保证缓存的单线程（进程）写，在加锁方法内先从缓存中再获取一次，没有再查DB写入缓存。 

 

- 还有一种比较好用的（针对缓存雪崩与缓存击穿）：

  物理上的缓存是不设置超时时间的（或者超时时间比较长），但是在缓存的对象上增加一个属性来标识超时时间（此时间相对小）。当获取到数据后，校验数据内部的标记时间，判定是否快超时了，如果是，异步发起一个线程（控制好并发）去主动更新该缓存。

  这种方式会导致一定时间内，有些请求获取缓存会拿到过期的值，看业务是否能接受而定。

 

### 淘汰策略（15）

#### 热点数据

在现今的电商平台中都有会有些大卖的商品，我们称之为简爆品。这些商品会有个特点，就是访问量(查询)特别大。我们专业上面可以称之为热点数据，在处理这些热点商品时，系统需要做一些特殊的处理。我们常见的处理方式就是将这些数据放到redis缓存中去，但是redis是一种内存数据库，而内存的容量又是有限的。随着业务量的增长，我们放在Redis里面的数据越来越多了，导致内存严重不足，这个时候就需要我们将Redis缓存中一些不是那么常用的数据移除掉，为了更好的利用内存，使Redis存储的都是缓存的热点数据，Redis设计了相应的内存淘汰机制（也可以叫做缓存淘汰机制）。

 

#### 开启淘汰机制

修改redis缓存大小，单位是字节

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019172733.png" alt="image-20211019172733217" style="zoom:50%;" />

内存淘汰的过程

- 首先，客户端发起了需要申请更多内存的命令（如set）。

- 然后，Redis检查内存使用情况，如果已使用的内存大于maxmemory则开始根据用户配置的不同淘汰策略来淘汰内存（key），从而换取一定的内存。

- 最后，如果上面都没问题，则这个命令执行成功。

提示：maxmemory为0的时候表示我们对Redis的内存使用没有限制。



##### 淘汰策略

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019172806.png" alt="image-20211019172806084" style="zoom:50%;" />

LRU（Least Recently Used）

| 策略            | 解释                                                         |
| --------------- | ------------------------------------------------------------ |
| volatile-lru    | 从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰。注意：redis并不是保证取得所有数据集中最近最少使用的键值对，而只是随机挑选的几个键值对中的， 当内存达到限制的时候无法写入非过期时间的数据集。 |
| volatile-ttl    | 从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰。注意：redis 并不是保证取得所有数据集中最近将要过期的键值对，而只是随机挑选的几个键值对中的， 当内存达到限制的时候无法写入非过期时间的数据集。 |
| volatile-random | 从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰。当内存达到限制的时候无法写入非过期时间的数据集。 |
| allkeys-lru     | 从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰。当内存达到限制的时候，对所有数据集挑选最近最少使用的数据淘汰，可写入新的数据集。 |
| allkeys-random  | 从数据集（server.db[i].dict）中任意选择数据淘汰，当内存达到限制的时候，对所有数据集挑选随机淘汰，可写入新的数据集。 |
| no-enviction    | 当内存达到限制的时候，不淘汰任何数据，不可写入任何数据集，所有引起申请内存的命令会报错。 |

##### 淘汰策略选择

根据使用经验, 一般来说回收策略可以这样来配置:

- allkeys-lru：如果期望用户请求呈现幂律分布(power-law distribution)，也就是，期望一部分子集元素被访问得远比其他元素多时，可以使用allkeys-lru策略。在你不确定时这是一个好的选择。

- allkeys-random：如果期望是循环周期的访问，所有的键被连续扫描，或者期望请求符合平均分布(每个元素以相同的概率被访问)，可以使用allkeys-random策略。

- volatile-ttl：如果你期望能让 Redis 通过使用你创建缓存对象的时候设置的TTL值，确定哪些对象应该是较好的清除候选项，可以使用volatile-ttl策略。

另外值得注意的是，为键设置过期时间需要消耗内存，所以使用像allkeys-lru这样的策略会更高效，因为在内存压力下没有必要为键的回收设置过期时间。



##### 淘汰个数

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019172901.png" alt="image-20211019172901697" style="zoom:50%;" />



### 删除策略（15）

数据删除策略有三种

- 被动删除：只有key被操作时(如GET)，Redis才会被动检查该key是否过期，如果过期则删除之并且返回NIL。

- 主动删除：定期删除过期的数据

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019172923.png" alt="image-20211019172923589" style="zoom:50%;" />

默认是10，表示serverCron每秒执行10次

注意：hz调大将会提高Redis主动淘汰的频率，如果Redis存储中包含很多冷数据占用内存过大的话，可以考虑将这个值调大，但Redis作者建议这个值不要超过100。

- 当前已用内存超过maxmemory限定时，触发数据淘汰策略

 

#### 被动删除特点

- 这种删除策略对CPU是友好的，删除操作只有在不得不的情况下才会进行，不会其他的expire key上浪费无谓的CPU时间。

- 但是这种策略对内存不友好，一个key已经过期，但是在它被操作之前不会被删除，仍然占据内存空间。如果有大量的过期键存在但是又很少被访问到，那会造成大量的内存空间浪费。

 

### Java客户端Jedis（30）

#### 开启redis端口

firewall-cmd --zone=public --add-port=6379/tcp --permanent

sudo service firewalld restart

 

#### 基本操作

Jedis是Redis官方推荐的Java连接开发工具。

pom.xml中导入依赖

```xml
<!--redis-->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-redis</artifactId>
</dependency>
<!--jedis-->
<dependency>
    <groupId>redis.clients</groupId>
    <artifactId>jedis</artifactId>
</dependency>
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-web</artifactId>
</dependency>
<dependency>
    <groupId>junit</groupId>
    <artifactId>junit</artifactId>
    <scope>test</scope>
</dependency>
```

在项目的test包下创建测试类JedisTest

```java
import redis.clients.jedis.Jedis;

public class JedisTest {
    public static void main(String[] args) {
        //1.创建jedis对象
        Jedis jedis = new Jedis("127.0.0.1",6379);

        //2.如果有密码需要授权
        //jedis.auth("123456");

        //3.获取值
        String name = jedis.get("name");
        System.out.println(name);

        //4.设置值
        jedis.set("gender","man");

        //5.关闭连接
        jedis.close();
    }
}
```



Jedis基本使用十分简单，在每次使用时，构建Jedis对象即可。在Jedis对象构建好之后，Jedis底层会打开一条Socket通道和Redis服务进行连接。所以在使用完Jedis对象之后，需要调用Jedis.close()方法把连接关闭，否则会占用系统资源。当然，如果应用非常平凡的创建和销毁Jedis对象，对应用的性能是很大影响的，因为构建Socket的通道是很耗时的(类似数据库连接)。

##### string

```java
public static void string(){
    Jedis jedis = new Jedis("127.0.0.1",6379);
    //1.设置数据
    jedis.set("name","lisi");
    jedis.set("gender","man");

    //2.获取数据
    String name = jedis.get("name");
    System.out.println(name);

    //3.获取多个数据
    List<String> values = jedis.mget("name","gender");
    System.out.println(values);

    //4.自增长
    jedis.set("age","10");
    jedis.incr("age");
    System.out.println(jedis.get("age"));

    jedis.close();
}
```



##### list

```java
public static void list(){
    Jedis jedis = new Jedis("127.0.0.1",6379);
    //1.设置数据
    jedis.lpush("students","zhangsan","lisi","wangwu");

    //2.获取长度
    long len = jedis.llen("students");
    System.out.println(len);

    //3.通过索引获取数据
    String value = jedis.lindex("students",1);
    System.out.println(value);

    //4.获取指定范围内数据
    List<String> students = jedis.lrange("students", 0, 1);
    System.out.println(students);

    //5.删除数据
    jedis.rpop("students");

    jedis.close();
}
```

##### hash

```java
public static void hash(){
    Jedis jedis = new Jedis("127.0.0.1",6379);
    //1.设置数据
    Map teacher = new HashMap();
    teacher.put("name","laoli");
    teacher.put("age","40");  //注意数字写成字符串形式，不然会报错
    jedis.hmset("teacher",teacher);

    //2.获取值指定字段值
    List<String> value = jedis.hmget("teacher", "name");
    System.out.println(value);

    //3.获取所有值
    Map<String, String> data = jedis.hgetAll("teacher");
    System.out.println(data);

    //4.获取到所有key
    Set<String> keys = jedis.hkeys("teacher");
    System.out.println(keys);

    //5.删除数据
    jedis.hdel("teacher","age");
    String age = jedis.hget("teacher", "age");
    System.out.println(age);

    jedis.close();
}

```

##### set

```java
public static void set(){
    Jedis jedis = new Jedis("127.0.0.1",6379);
    //1.设置数据
    jedis.sadd("zhangsan","lisi","wangwu","zhaoliu");

    //2.获取数据
    Set<String> zhangsan = jedis.smembers("zhangsan");
    System.out.println(zhangsan);

    //3.计算交集
    jedis.sadd("lisi","zhangsan","wangwu","zhaoliu");
    //
    Set<String> sinter = jedis.sinter("zhangsan", "lisi");
    System.out.println(sinter);

    //4.计算差集：此处是找到lisi中哪些在zhangsan里没有
    Set<String> sdiff = jedis.sdiff("zhangsan", "lisi");
    System.out.println(sdiff);

    jedis.close();
}

```

##### zset

```java
public static void zset(){
    Jedis jedis = new Jedis("127.0.0.1",6379);

    //1.添加数据
    jedis.zadd("hot",105,"南非女子诞下十胞胎");
    jedis.zadd("hot",130,"核酸检测上河图");
    jedis.zadd("hot",100,"詹姆斯改穿湖人6号球衣");

    //2.获取成员数
    long count = jedis.zcard("hot");

    //3.获取指定范围内的数据
    Set<String> hot = jedis.zrange("hot", 0, count - 1);
    System.out.println(hot);

    //4.通过成员名删除数据
    jedis.zrem("hot","南非女子诞下十胞胎");

    count = jedis.zcard("hot");
    hot = jedis.zrange("hot", 0, count - 1);
    System.out.println(hot);

    //5.通过指定下标范围删除数据
    jedis.zremrangeByRank("hot",0,0); //闭区间

    count = jedis.zcard("hot");
    hot = jedis.zrange("hot", 0, count - 1);
    System.out.println(hot);

//6.获取成员和分数
Set<Tuple> hot = jedis.zrangeWithScores("zhangsan", 0, 2);
System.out.println(hot);

Iterator<Tuple> iterator = hot.iterator();
while (iterator.hasNext()){
    Tuple tuple = iterator.next();
    System.out.println(tuple.getElement()+"-"+tuple.getScore());

}


    jedis.close();
}

```



### 解决IDEA控制台乱码问题

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019173222.png" alt="image-20211019173222276" style="zoom:50%;" />

设置字符编码为：-Dfile.encoding=UTF-8

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019173232.png" alt="image-20211019173232633" style="zoom:50%;" />

如果还是乱码，找到IDEA安装目录/bin/idea64.exe.vmoptions文件在文件末尾指定字符编码，然后重启IDEA

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019173242.png" alt="image-20211019173242486" style="zoom:50%;" />

内容如下：

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211019173251.png" alt="image-20211019173251360" style="zoom:50%;" />



### Spring-Data-Redis（45）

配置RedisTemplate，简化Redis开发

引入redis依赖

```xml
<!-- redis -->
<dependency>
	<groupId>org.springframework.boot</groupId>
	<artifactId>spring-boot-starter-data-redis</artifactId>
</dependency>
<!-- 引入mybatis -->
<dependency>
	<groupId>org.mybatis.spring.boot</groupId>
	<artifactId>mybatis-spring-boot-starter</artifactId>
	<version>1.3.2</version>
</dependency>
				
<!-- 引入mysql -->
<dependency>
	<groupId>mysql</groupId>
	<artifactId>mysql-connector-java</artifactId>
</dependency> 

```

在application.properties配置文件中添加redis配置

```yaml
mybatis:
  config-location: classpath:mybatis/mybatis-config.xml
  type-aliases-package: com.woniuxy.main.pojo
spring:
  datasource:
    driver-class-name: com.mysql.jdbc.Driver
    url: jdbc:mysql://localhost:3306/mybatis?serverTimezone=UTC&useUnicode=true&characterEncoding=utf-8&useSSL=true
    username: root
    password: root
  redis: 
    database: 0           # 数据库编号
    host: 192.168.41.226  # redis服务器ip
    port: 6380        # 端口
    password: 123456  # 密码，如果redis没有设置密码，这一行千万别写，不然会报错
    pool:
      max-active: 8   # 连接池最大连接数（使用负值表示没有限制）
      max-wait: -1    # 连接池最大阻塞等待时间（使用负值表示没有限制）
      max-idle: 8     # 连接池中的最大空闲连接
      min-idle: 1     # 连接池中的最小空闲连接
    timeout: 30       # 连接超时时间（毫秒）

```

创建Redis配置类

```java
import java.lang.reflect.Method;

import org.springframework.cache.annotation.CachingConfigurerSupport;
import org.springframework.cache.annotation.EnableCaching;
import org.springframework.cache.interceptor.KeyGenerator;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.data.redis.connection.RedisConnectionFactory;
import org.springframework.data.redis.core.HashOperations;
import org.springframework.data.redis.core.ListOperations;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.data.redis.core.SetOperations;
import org.springframework.data.redis.core.ValueOperations;
import org.springframework.data.redis.core.ZSetOperations;
import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer;
import org.springframework.data.redis.serializer.StringRedisSerializer;

import com.fasterxml.jackson.annotation.JsonAutoDetect;
import com.fasterxml.jackson.annotation.PropertyAccessor;
import com.fasterxml.jackson.databind.ObjectMapper;
/*
 * 开启redis缓存，设置key的生产策略。主要用于注解情况下，默认使用方法的全限定名作为key    自动生成key
 */
@EnableCaching
@Configuration
public class RedisConfiguration extends CachingConfigurerSupport{
     /*
	 * key的生成策略
	 */
	@Override
	public KeyGenerator keyGenerator() {
		// TODO Auto-generated method stub
		return new KeyGenerator() {
			/*
			 * 参数1：要操作的目标对象
			 * 参数2：要操作的方法
			 * 参数3：执行方法时的参数
			 */
			@Override
			public Object generate(Object target, Method method, Object... params) {
				StringBuilder sBuilder = new StringBuilder();
				sBuilder.append(target.getClass().getName());
				sBuilder.append(".");
				sBuilder.append(method.getName());    //生成key
				for(Object object:params){
                     sBuilder.append(".");
					sBuilder.append(object.toString());
				}
				return sBuilder.toString();
			}
		};
	}
	/**
     * redisTemplate相关配置
     * @param factory
     * @return
     */
	@Bean
	@SuppressWarnings("all")
	public RedisTemplate<String, Object> redisTemplate(RedisConnectionFactory factory) {
		RedisTemplate<String, Object> template  = new RedisTemplate<>();
		//设置工厂
		template.setConnectionFactory(factory);
		//使用Jackson2JsonRedisSerializer来序列化和反序列化redis的value值
//（默认使用JDK的序列化方式）
		Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = 
new Jackson2JsonRedisSerializer<>(Object.class);
		//创建对象映射
		ObjectMapper mapper = new ObjectMapper();
		//指定要序列化的域，field,get和set,以及修饰符范围，ANY是都有包括private和public
		mapper.setVisibility(PropertyAccessor.ALL,JsonAutoDetect.Visibility.ANY);
		//指定序列化输入的类型，类必须是非final修饰的，final修饰的类，比如String,Integer
//等会抛出异常
		mapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);
		//
		jackson2JsonRedisSerializer.setObjectMapper(mapper);
		//字符串序列化器
		StringRedisSerializer stringRedisSerializer = new StringRedisSerializer();
		//key采用String的序列化方式
		template.setKeySerializer(stringRedisSerializer);
		//hash的key也采用String的方式
		template.setHashKeySerializer(stringRedisSerializer);
		//value采用jackson的方式
		template.setValueSerializer(jackson2JsonRedisSerializer);
		//hash的value也采用Jackson
		template.setHashValueSerializer(jackson2JsonRedisSerializer);
		
		template.afterPropertiesSet();
		return template;
	}
}	

```

在test/java下的测试类中测试redisTemplate

```java
package com.woniuxy.redis;

import org.junit.jupiter.api.Test;
import org.junit.runner.RunWith;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.test.context.junit4.SpringRunner;

import javax.annotation.Resource;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.concurrent.TimeUnit;

@SpringBootTest
class RedisApplicationTests {
    @Resource
    private RedisTemplate<String,Object> redisTemplate;

    @Test
    public void stringTest(){
        //opsForValue获取操作字符串的对象
        redisTemplate.opsForValue().set("age",10);

        redisTemplate.opsForValue().increment("age");

        Object name = redisTemplate.opsForValue().get("age");
        System.out.println(name);
    }
    @Test
    public void listTest(){
        //一个一个放
        redisTemplate.opsForList().leftPush("users","zhangsan1");
        redisTemplate.opsForList().leftPush("users","zhangsan2");
        redisTemplate.opsForList().leftPush("users","zhangsan3");

        //一次性放多个
        redisTemplate.opsForList().leftPushAll("stus","lisi","wangwu","zhaoliu");

        //拿
        List<Object> stus = redisTemplate.opsForList().range("stus", 0, 2);
        System.out.println(stus);

        //删除
        Object stu = redisTemplate.opsForList().leftPop("stus");
        System.out.println(stu);
    }
    //hash
    @Test
    public void hashTest(){
        //设置
        Map<String,Object> data = new HashMap<>();
        data.put("name","wangba");
        data.put("age",10);   // 如果field的值之后需要做自增长、自减最好存数字，不要存字符串
        redisTemplate.opsForHash().putAll("person",data);

        //获取指定字段值
        Object name = redisTemplate.opsForHash().get("person", "name");
        System.out.println(name);

        //修改指定字段值
        redisTemplate.opsForHash().increment("person","age",1);
    }

    //通用指令
    @Test
    public void commons(){
        //超时
        //redisTemplate.expire("person",100, TimeUnit.SECONDS);
        //删除
        redisTemplate.delete("person");
        //
    }
}

```

User类：必须序列化

```java
import java.io.Serializable;

@Data
@AllArgsConstructor
@NoArgsConstructor
@Accessors(chain = true)
public class User implements Serializable {
    private int id;
    private String account;
    private String pwd;
}

```

Mapper

```xml
<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE mapper
        PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN"
        "http://mybatis.org/dtd/mybatis-3-mapper.dtd">
<mapper namespace="com.woniuxy.redis79.mapper.UserMapper">
    <select id="all" resultType="User">
        select * from user
    </select>

    <select id="findById" resultType="User">
        select * from user where id = #{id}
    </select>

    <delete id="delById">
        delete from user where id = #{id}
    </delete>
</mapper>

```

service

```java
@Service
public class UserServiceImpl implements UserService {
    @Resource
    private UserMapper userMapper;

    @Resource
    private RedisTemplate<String,Object> redisTemplate;


    @Override
    @Cacheable(value = "alluser")
    public List<User> all() {
        System.out.println("执行SQL查询数据库");
        return userMapper.all();
    }

    //以id查询用户
    @Override
    @Cacheable(value = "findById",key = "#id")   //findById::1
    public User findById(int id) {
        return userMapper.findById(id);
    }

    @Override
    @Transactional
    //allEntries 表示是否删除value中对应的所有的key   spring expression language   SPEL
    //@CacheEvict(value = {"alluser","findById"},allEntries = true)  //删除缓存
    //@CacheEvict(value = "findById",key = "#id")//findById::2
    @Caching(evict = {
            @CacheEvict(value = "alluser",allEntries = true),
            @CacheEvict(value = "findById",key = "#id")
    })
    public int delById(int id) {
        //删除alluser中的部分数据
        //1.执行SQL删除数据库
        //2.读取出alluser中的数据
        //3.在java代码中删除
        //4.再重新放回redis缓存

        //思考：值不值得？

        return userMapper.delById(id);
    }
}


```



### SpringCache整合Redis（45）

#### 简介

Spring Cache是Spring框架提供的对缓存使用的抽象类，支持多种缓存，比如Redis、EHCache等，集成很方便。同时提供了多种注解来简化缓存的使用，可对方法进行缓存。

 

#### 相关注解

##### @Cacheable

标记在一个方法上，也可以标记在一个类上。主要是缓存标注对象的返回结果，标注在方法上缓存该方法的返回值，标注在类上，缓存该类所有的方法返回值。

参数： value缓存名、 key缓存键值、 condition满足缓存条件、unless否决缓存条件

| 参数      | 解释                                                         | 示例                                                         |
| --------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| value     | 缓存的名称                                                   | @Cacheable(value="mycache")@Cacheable(value={"mycache","mycache2"}) |
| key       | 缓存的key，可以为空，如果指定要按照 SpEL表达式编写，如果不指定，则缺省按照方法的所有参数进行组合 | @Cacheable(value="mycache",key="#userName")                  |
| condition | 缓存条件，可以为空，使用SpEL编写，返回true表示缓存，false表示不返回 | @Cacheable(value="mycache",condition="#userName.length()>5") |

##### @CacheEvict

从缓存中移除相应数据

| 参数             | 解释                                                         | 示例                                                         |
| ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| value            | 缓存的名称                                                   | @CachEvict(value="mycache")@CachEvict(value={"mycache","mycache2"}) |
| key              | 缓存的key。可以省略，自动按照方法的所有参数进行组合          | @CachEvict(value="mycache",key="#userName")                  |
| condition        | 缓存条件，可以为空，使用SpEL编写，返回true表示缓存，false表示不返回 | @CachEvict(value="mycache",condition="#userName.length()>5") |
| allEntries       | 是否清空所有缓存内容,缺省为false，如果指定为true，则方法调用后将立即清空所有缓存 | @CachEvict(value="testcache",allEntries=true)                |
| beforeInvocation | 是否在方法执行前就清空,缺省为false，如果指定为true，则在方法还没有执行的时候就清空缓存，缺省情况下，如果方法执行抛出异常，则不会清空缓存 | @CachEvict(value="testcache",beforeInvocation=true)          |

 ##### @CachePut

支持缓存功能。与@Cacheable不同的是使用@CachePut标注的方法在执行前不会去检查缓存中是否存在之前执行过的结果，而是每次都会执行该方法，并将执行结果以键值对的形式存入指定的缓存中。

| 参数      | 解释                                                         | 示例                                                         |
| --------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| value     | 缓存的名称                                                   | @Cacheable(value="mycache")@Cacheable(value={"mycache","mycache2"}) |
| key       | 缓存的key，可以为空，如果指定要按照 SpEL表达式编写，如果不指定，则缺省按照方法的所有参数进行组合 | @Cacheable(value="mycache",key="#userName")                  |
| condition | 缓存条件，可以为空，使用SpEL编写，返回true表示缓存，false表示不返回 | @Cacheable(value="mycache",condition="#userName.length()>5") |

 

##### @Caching

可以指定删除的key

```java
@Override
//@CacheEvict(value = {"findById","findAll"},allEntries = true)
@Caching(evict = {
    @CacheEvict(value = "findAll",allEntries = true),
    @CacheEvict(value = "findById",key = "#id")  //findById::1001
})
public boolean del(int id) {
    //假设删除数据库成功了    redis的数据是不是要删除
    return userMapper.del(id) > 0 ? true : false;
}

```



#### SpEL

SpEL（Spring Expression Language），即Spring表达式语言，是比JSP的EL更强大的一种表达式语言。为什么要总结SpEL，因为它可以在运行时查询和操作数据，尤其是数组列表型数据，因此可以缩减代码量，优化代码结构。

 

用法

SpEL常见的用法主要有：在注解@Value中、在XML配置、在SpringCache相关注解中。

 

##### @Value

```java
//@Value能修饰成员变量和方法形参
//#{}内就是表达式的内容
@Value("#{表达式}")
public String arg;

```

##### bean配置

```xml
<bean id="user" class="com.woniuxy.entity.User">
    <!-- 同@Value,#{}内是表达式的值，可放在property或constructor-arg内 -->
    <property name="uname" value="#{表达式}">
</bean>

```



##### 语法

- 字面量赋值

```xml
<!-- 整数 -->
<property name="count" value="#{5}" />
<!-- 小数 -->
<property name="frequency" value="#{13.2}" />
<!-- 科学计数法 -->
<property name="capacity" value="#{1e4}" />
<!-- 字符串  #{"字符串"} 或  #{'字符串'} -->
<property name="name" value="#{'我是字符串'}" />
<!-- Boolean -->
<property name="enabled" value="#{false}" />

```

注：

1）字面量赋值必须要和对应的属性类型兼容，否则会报异常。

2）一般情况下我们不会使用 SpEL字面量赋值，因为我们可以直接赋值。

 

- 引用Bean、属性和方法（必须是public修饰的）

```xml
<property name="car" value="#{car}" />
<!-- 引用其他对象的属性 -->
<property name="carName" value="#{car.name}" />
<!-- 引用其他对象的方法 -->
<property name="carPrint" value="#{car.print()}" />

```

- 运算符

算术运算符：+,-,*,/,%,^

```xml
<!-- 3 -->
<property name="num" value="#{2+1}" />
<!-- 1 -->
<property name="num" value="#{2-1}" />
<!-- 4 -->
<property name="num" value="#{2*2}" />
<!-- 3 -->
<property name="num" value="#{9/3}" />
<!-- 1 -->
<property name="num" value="#{10%3}" />
<!-- 1000 -->
<property name="num" value="#{10^3}" />

```

- 字符串连接符：+

```xml
<!-- 10年3个月 -->
<property name="numStr" value="#{10+'年'+3+'个月'}" />

```

- 比较运算符：<(<),>(>),==,<=,>=,lt,gt,eq,le,ge

```xml
<!-- false -->
<property name="numBool" value="#{10&lt;0}" />
<!-- false -->
<property name="numBool" value="#{10 lt 0}" />
<!-- true -->
<property name="numBool" value="#{10&gt;0}" />
<!-- true -->
<property name="numBool" value="#{10 gt 0}" />
<!-- true -->
<property name="numBool" value="#{10==10}" />
<!-- true -->
<property name="numBool" value="#{10 eq 10}" />
<!-- false -->
<property name="numBool" value="#{10&lt;=0}" />
<!-- false -->
<property name="numBool" value="#{10 le 0}" />
<!-- true -->
<property name="numBool" value="#{10&gt;=0}" />
<!-- true -->
<property name="numBool" value="#{10 ge 0}" />

```

- 逻辑运算符：and,or,not,&&(&&),||,!

```xml
<!-- false -->
<property name="numBool" value="#{true and false}" />
<!-- false -->
<property name="numBool" value="#{true&amp;&amp;false}" />
<!-- true -->
<property name="numBool" value="#{true or false}" />
<!-- true -->
<property name="numBool" value="#{true||false}" />
<!-- false -->
<property name="numBool" value="#{not true}" />
<!-- false -->
<property name="numBool" value="#{!true}" />

```

- 条件运算符：?true:false

```xml
<!-- 真 -->
<property name="numStr" value="#{(10>3)?'真':'假'}" />

```

- 正则表达式：matches

```xml
<!-- true -->
<property name="numBool" value="#{user.email matches '[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+.[a-zA-Z]{2,4}'}" />

```

- 调用静态方法或静态属性

通过 T() 调用一个类的静态方法，它将返回一个 Class Object，然后再调用相应的方法或属性：

```xml
<!-- 3.141592653589793 -->
<property name="PI" value="#{T(java.lang.Math).PI}" />

```



### SpringBoot整合Sentinel（15）

注意：

主从复制时slaveof指令后的ip应该为网络ip（虚拟机IP），不要写成127

哨兵配置文件中主机的IP也应该是网络ip（虚拟机IP），不要写127

 

配置哨兵

需要注意的是：所有哨兵的配置文件中一定要关闭保护模式

protected-mode no	#关闭保护模式，保护redis服务器

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20211020173929.png" alt="image-20211020173929242" style="zoom:50%;" />

在项目主配置文件中配置哨兵

```yaml
mybatis:
  config-location: classpath:mybatis/mybatis-config.xml
  type-aliases-package: com.woniuxy.main.pojo
  
spring:
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://localhost:3306/redis?serverTimezone=UTC&useUnicode=true&characterEncoding=utf-8&useSSL=true
    username: root
    password: root
  redis:
#    port: 8001
#    host: 192.168.74.145   # 虚拟机ip
    jedis:
      pool:
        max-idle: 8   # 最大发呆（空闲）的连接数
        max-wait: -1ms   # 最大等待时间  -1代表一直登陆
        max-active: 8 # 最大活跃的连接数  最大连接数
        min-idle: 2  # 最小发呆的连接数
    sentinel:
      master: mymaster
      nodes: 192.168.41.226:26379,192.168.41.226:26380,192.168.41.226:26381
server:
  port: 8081

```



### 哨兵操作流程

#### 停止服务

停止所有哨兵

停掉所有redis

删除所有从机中最后一行关于主机的配置信息

删除哨兵中所有多余的数据



#### 修改哨兵配置

哨兵配置文件中主机ip一定要用网络ip（虚拟机ip），不要使用127.0.0.1



#### 启动redis

分别启动三台Redis，然后形成主从结构

注意：在使用slaveof指令时，主机ip使用网络ip（虚拟机ip）



#### 启动哨兵

分别启动三台哨兵



#### 开启端口

开启所有redis、哨兵所使用到的端口

firewall-cmd --zone=public --add-port=6379/tcp --permanent

firewall-cmd --zone=public --add-port=6380/tcp --permanent

firewall-cmd --zone=public --add-port=6381/tcp --permanent

firewall-cmd --zone=public --add-port=16379/tcp --permanent

firewall-cmd --zone=public --add-port=16380/tcp --permanent

firewall-cmd --zone=public --add-port=16381/tcp --permanent

sudo service firewalld restart



#### 修改项目配置文件

注释掉redis的host、port配置

添加哨兵配置

```yaml
sentinel:
	master: mymaster
	nodes: 192.168.74.145:16379,192.168.74.145:16380,192.168.74.145:16381

```





### redis-cluster（redis集群）

从redis 3.0之后版本支持redis-cluster集群，Redis-Cluster采用无中心结构，每个节点保存数据和整个集群状态,每个节点都和其他所有节点连接。

sentinel模式基本可以满足一般生产的需求，具备高可用性。但是当数据量过大到一台服务器存放不下的情况时，主从模式或sentinel模式就不能满足需求了，这个时候需要对存储的数据进行分片，将数据存储到多个Redis实例中。cluster模式的出现就是为了解决单机Redis容量有限的问题，将Redis的数据根据一定的规则分配到多台机器。

 

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220523203916.jpg" alt="img" style="zoom:67%;" />

 

其结构特点：

- redis是一个开源的key value存储系统，受到了广大互联网公司的青睐。redis3.0版本之前只支持单例模式，在3.0版本及以后才支持集群，我这里用的是redis5.0.7版本；

- redis集群采用P2P模式，是完全去中心化的，不存在中心节点或者代理节点；

- redis集群是没有统一的入口的，客户端（client）连接集群的时候连接集群中的任意节点（node）即可，集群内部的节点是相互通信的（PING-PONG机制），每个节点都是一个redis实例；

- 为了实现集群的高可用，即判断节点是否健康（能否正常使用），redis-cluster有这么一个投票容错机制：如果集群中超过半数的节点投票认为某个节点挂了，那么这个节点就挂了（fail）。这是判断节点是否挂了的方法；

- 那么如何判断集群是否挂了呢? 如果集群中任意一个节点挂了，而且该节点没有从节点（备份节点），那么这个集群就挂了。这是判断集群是否挂了的方法；

- 那么为什么任意一个节点挂了（没有从节点）这个集群就挂了呢？因为集群内置了16384个slot（哈希槽），并且把所有的物理节点映射到了这16384[0-16383]个slot上，或者说把这些slot均等的分配给了各个节点。当需要在Redis集群存放一个数据（key-value）时，redis会先对这个key进行crc16算法，然后得到一个结果。再把这个结果对16384进行求余，这个余数会对应[0-16383]其中一个槽，进而决定key-value存储到哪个节点中。所以一旦某个节点挂了，该节点对应的slot就无法使用，那么就会导致集群无法正常工作。

- 综上所述，每个Redis集群理论上最多可以有16384个节点。。

 

### 集群实现

#### 集群搭建需要的环境

- Redis集群至少需要3个节点，因为投票容错机制要求超过半数节点认为某个节点挂了该节点才是挂了，所以2个节点无法构成集群。

- 要保证集群的高可用，需要每个节点都有从节点，也就是备份节点，所以Redis集群至少需要6台服务器。因为我没有那么多服务器，也启动不了那么多虚拟机，所在这里搭建的是伪分布式集群，即一台服务器虚拟运行6个redis实例，修改端口号为（8001-8006），当然实际生产环境的Redis集群搭建和这里是一样的。

 

#### 实现步骤

说明：针对5.0版本以后的版本，之前的版本需要先单独去安装ruby，但是很麻烦

- 在/usr/local/redis下创建redis-cluster目录

 

- 拷贝redis6379到redis-cluster中并命名为redis8001.conf

 

- 修改redis8001.conf中的端口号

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220523203924.jpg" alt="img" style="zoom:80%;" /> 

- 修改pidfile

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220523203927.jpg" alt="img" style="zoom:80%;" /> 

- 修改日志文件

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220523203930.jpg" alt="img" style="zoom:80%;" /> 

- 修改rdb文件

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220523203933.jpg" alt="img" style="zoom:80%;" /> 

- 开启aof

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220523203936.jpg" alt="img" style="zoom:80%;" /> 

- 指定aof文件名

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220523203938.jpg" alt="img" style="zoom:80%;" /> 

- 开启集群

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220523203941.jpg" alt="img" style="zoom:80%;" /> 

- 指定nodes配置文件

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220523203943.jpg" alt="img" style="zoom:80%;" /> 

- 将8001拷贝5份，分别为8002-8006,

- 依次修改8002-8006配置文件信息，修改的内容同8001，在命令模式下使用一下指令可以进行快速替换

  g/8001/s/8001/8002/g

  说明：

  g		/8001			/s/		8001					/8002		/g

  全局	包含的字符串	行		将行中的哪个进行替换	替换成		全局

 

- 分别启动8001-8006显得十分麻烦，因此编写启动文件，用于一次性启动所redis

  创建start_all.sh文件，在文件中添加入下内容

```sh
redis-server redis-cluster/redis8001.conf
redis-server redis-cluster/redis8002.conf
redis-server redis-cluster/redis8003.conf
redis-server redis-cluster/redis8004.conf
redis-server redis-cluster/redis8005.conf
redis-server redis-cluster/redis8006.conf
ps -ef|grep redis
```

保存退出，为start_all.sh文件添加执行权限

​	chmod +x start_all.sh

控制台输入./start_all

看到以下界面表示所有redis启动成功<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220523203946.jpg" alt="img" style="zoom: 80%;" /> 

·删除redis目录下的所有aof、rdb、log文件

编写删除rm_all.sh文件，并添加以下信息

```sh
rm -f append*
rm -f *.log
rm -f *.rdb
rm -f nodes*
```

添加执行权限

chmod +x rm_all.sh

 

·输入以下命令创建集群

```
redis-cli --cluster create 192.168.74.130:8001 192.168.74.130:8002 192.168.74.130:8003 192.168.74.130:8004 192.168.74.130:8005 192.168.74.130:8006 --cluster-replicas 1
```

注：ip地址为自己虚拟机的ip地址

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220523203950.jpg" alt="img" style="zoom:80%;" /> 

输入yes继续

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220523203952.jpg" alt="img" style="zoom:80%;" /> 

出现此界面表示集群创建成功

 

- 登录8001，设置key-value，需要注意的是：redis-cli连接redis时需要使用-c参数来启动集群模式

redis-cli -c -p 8001

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220523203956.jpg" alt="img" style="zoom:80%;" /> 

 

- 使用同样的方式登录8003，获取key对应的value

<img src="C:\Users\ADMINI~1\AppData\Local\Temp\ksohtml2632\wps14.jpg" alt="img" style="zoom:80%;" /> 

如果能获得值，表示集群已经开启，key正常使用了

 

- 如果想要一次性关闭所有redis，key在/usr/local/redis下创建stop_all.sh文件，并添加如下内容

```sh
#!/bin/bash
PORT=8001
ENDPORT=8006
while [ $((PORT <= ENDPORT)) != "0" ]; do
   echo "Stopping Redis $PORT"
   redis-cli -p $PORT shutdown
   PORT=$((PORT+1))
done
echo "done"
exit 0
```

添加执行权限

chmod +x stop_all.sh

 

### Spring Boot中使用Redis集群

- 虚拟机开放8001-8006端口

```
firewall-cmd --zone=public --add-port=8001/tcp --permanent
firewall-cmd --zone=public --add-port=8002/tcp --permanent
firewall-cmd --zone=public --add-port=8003/tcp --permanent
firewall-cmd --zone=public --add-port=8004/tcp --permanent
firewall-cmd --zone=public --add-port=8005/tcp --permanent
firewall-cmd --zone=public --add-port=8006/tcp --permanent
systemctl restart firewalld.service
```

- pom.xml中引入jedis连接池

```xml
<!-- jedis -->
<dependency>	
    <groupId>redis.clients</groupId>	
    <artifactId>jedis</artifactId>
</dependency>
```

- 修改application.yml文件

```yaml
spring:
  datasource:
    driver-class-name: com.mysql.jdbc.Driver
    url: jdbc:mysql://localhost:3306/java58?serverTimezone=UTC&useUnicode=true&characterEncoding=utf-8&useSSL=true
    username: root
password: root
  redis:
    cluster:
      nodes:
        - 192.168.74.130:8001
        - 192.168.74.130:8002
        - 192.168.74.130:8003
        - 192.168.74.130:8004
        - 192.168.74.130:8005
        - 192.168.74.130:8006
    jedis:
      pool:
        max-active: 1000  #最大连接数，负值表示没有限制
        max-wait: -1ms  #最大阻塞等待时间
        max-idle: 10  #最大空闲连接
        min-idle: 5   #最小空闲连接
```



- 编写测试用handler

```java
@RestController
@RequestMapping("/cluster")
public class ClusterHandler {
	@Autowired
	private RedisUtil redisUtil;
	
	@RequestMapping("/set")
	public String set() {
		redisUtil.set("cluster", "test");
		return "success";
	}
	
	@RequestMapping("/get")
	public Object get() {
		return redisUtil.get("cluster");
	}
}
```

- 运行程序分别调用set、get方法进行测试

 

### 哈希槽

Redis cluster采用数据分片的哈希槽来进行数据存储和数据的读取。

redis cluster一共有2^14（16384）个槽，所有的master节点都会有一个槽区比如0～1000，槽数是可以迁移的。master节点的slave节点不分配槽，只拥有读权限。但是注意在代码中redis cluster执行读写操作的都是master节点，并不是你想的读是从节点，写是主节点。第一次新建redis cluster时，16384个槽是被master节点均匀分布的，但是后期因为节点的加入、退出会导致不一定按照平均分布。

![1653310710025](C:\Users\Lijunbo\AppData\Roaming\Typora\typora-user-images\1653310710025.png)

 

- key的定位规则是根据CRC-16(key)%16384的值来判断属于哪个槽区，从而判断该key属于哪个节点，

- redis cluster是采用master节点有多个slave节点机制来保证数据的完整性的,master节点写入数据，slave节点同步数据。当master节点挂机后，slave节点会通过选举机制选举出一个节点变成master节点，实现高可用。但是这里有一点需要考虑，如果master节点存在热点缓存，某一个时刻某个key的访问急剧增高，这时该mater节点可能操劳过度而死，随后从节点选举为主节点后，同样宕机，依次类推，造成缓存雪崩。



# day06

### 分布式存储介绍（中 15）

分布式存储的特点及解决方案

分布式存储是一种数据存储技术，通过网络使用企业中的每台机器上的磁盘空间，并将这些分散的存储资源构成一个虚拟的存储设备，数据分散的存储在企业的各个角落。

分布式网络存储系统采用可扩展的系统结构，利用多台存储服务器分担存储负荷，利用位置服务器定位存储信息，它不但提高了系统的可靠性、可用性和存取效率，还易于扩展。



#### 专业术语

##### OSS

Object Storage Service俗称对象存储，主要提供图片、文档、音频、视频等二进制文件的海量存储功能。目前除了公有云提供对象存储服务外，一般私有云比较关心一些开源的分布式对象存储解决方案，本文列举了一些常见的技术方案供参考。



##### 块存储

通常SAN（Storage Area Network）结构的产品属于块存储，比如我们常见的硬盘、磁盘阵列等物理盘。



##### 文件存储

一般NAS（Network Attached Storage）产品都是文件级存储，如Ceph的CephFS，另外GFS、HDFS等也属于文件存储。



##### 对象存储

同时兼顾着SAN高速直接访问磁盘特点及NAS的分布式共享特点的一类存储，一般是通过RESTful接口访问。

 

#### 常见解决方案

##### Swift

Swift 是 OpenStack 社区核心子项目，是一个弹性可伸缩、高可用的分布式对象存储系统，使用Python语言实现，采用 Apache 2.0 许可协议。

Swift 提供一个基于RESTful HTTP接口的 Object Storage API，用于创建，修改和获取对象和元数据。用户可以使用 Swift 高效、安全且廉价地存储大量数据。Swift 整体架构：

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210718181204.png" alt="image-20210718181203768" style="zoom:50%;" />

总的来说，企业如果想要建立可扩展的分布式对象存储集群，可以考虑 Swift。



##### Ceph

Ceph是一种高性能、高可用、可扩展的分布式存储系统，统一的对外提供对象存储、块存储以及文件存储功能，底层使用C/C++语言。

其中对象存储功能支持 2 种接口：
1、兼容S3：提供了对象存储接口，兼容 S3 RESTful 接口的一个大子集。
2、兼容Swift：提供了对象存储接口，兼容 Openstack Swift 接口的一个大子集。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210718181305.png" alt="image-20210718181304987" style="zoom:50%;" />

Ceph是一个企业级分布式存储系统，功能强大，不仅可以为企业建立对象存储服务，还可以帮助企业建立自己的云平台，具有广泛的应用场景特别是在云环境下使用广泛。



##### Minio

Minio是一个企业级、兼容S3接口的对象存储系统。Minio基于 Apache 2.0 许可协议，采用Go语言实现，客户端支持Java、Python、Go等多种语言，是一种轻量级、高并发的开源解决方案，可以作为云存储方案用来保存海量的图片，视频，文档等。

大数据集成方面，Minio支持各种常见的查询计算引擎，比如Spark、Presto、Hive以及Flink等，可以使用这些处理框架查询分析对象数据，此外，Minio支持Parquet，Json、Csv格式等多种文件存储格式，包括压缩与编码。更多特性可以参考官网 地址https://min.io。Minio架构：

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210718181353.png" style="zoom:50%;" />

Minio主要为人工智能、机器学习而设计，并适用于其他大数据负载。从架构与功能方面考虑，Minio是一个比较好的开源对象存储解决方案。



##### HBase MOB

这是利用HBase的MOB特性支持对象存储功能。Apache HBase2.0 版本开始支持中等对象存储（Medium Object Storage，简称 MOB），这个特性使得HBase能够非常良好的存储大小在100KB-10M的图片、文档、音频、短视频等二进制数据。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210718181616.png" alt="image-20210718181615972" style="zoom:50%;" />

架构如上，HBase MOB的设计类似于HBase + HDFS的方式，中等对象在写入HDFS之前同样是先写入MemStore，但是刷写与其他写入数据不同，MOB数据被刷写到MOB File中，MOB File被存放在特殊的Region中。

MOB特性在Apache HBase 2.0、CDH 5.4.x 或 HDP 2.5.x 及以上版本支持，用户可以基于HBase MOB特性设计自己的对象存储服务。


### 对象存储实现（高 40）

#### 利用阿里云OSS实现文件存储

阿里云对象存储*OSS*（Object Storage Service）是阿里云提供的海量、安全、低成本、高持久的云存储服务。其数据设计持久性不低于99.9999999999%（12个9），服务可用性...有关*阿里云存储服务*的客户案例、解决方案等，请参见阿里云存储产品家族。



##### 开通阿里云OSS服务

点击“产品”->“存储”->“对象存储OSS”

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210718203230.png" alt="image-20210718203230530" style="zoom: 33%;" />

点击“立即开通”

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210718203600.png" alt="image-20210718203600333" style="zoom:33%;" />

勾选协议，点击立即开通

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210718203638.png" alt="image-20210718203638118" style="zoom:33%;" />

开通完毕

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210718203710.png" alt="image-20210718203709866" style="zoom:33%;" />

#### 创建桶

bucket列表->创建bucket

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210718203840.png" alt="image-20210718203840668" style="zoom:33%;" />

点击“开通”

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210718203922.png" alt="image-20210718203922369" style="zoom:33%;" />



指定桶名字以及存储区域

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220523101258.png" alt="image-20220523101258005" style="zoom: 50%;" />

#### 设置AccessKey

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210718210715.png" alt="image-20210718210715686" style="zoom: 25%;" />

点击“开始使用子用户AccessKey”

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210718210835.png" alt="image-20210718210835130" style="zoom: 25%;" />

点击“创建用户”

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210718210911.png" alt="image-20210718210910861" style="zoom: 25%;" />

指定登录名和显示名称，选择“Open API调用访问”，点击“确定创建”

![image-20220523101737762](https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220523164358.png)



**<font color='red'>创建完毕之后，在用户列表下有用户信息和accesskey id和accesskey secret，请立即将access key保存</font>**

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210718211413.png" alt="image-20210718211412744" style="zoom: 25%;" />



##### 指定用户权限

点击用户信息

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210718211821.png" alt="image-20210718211821017" style="zoom: 25%;" />

选择”权限管理“选项卡，点击”添加权限“

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210718211900.png" alt="image-20210718211859661" style="zoom: 25%;" />

授予全部权限

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210718212054.png" alt="image-20210718212054568" style="zoom: 25%;" />



#### 新建oss微服务

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210718213144.png" alt="image-20210718213144561" style="zoom:33%;" />

##### 导入阿里云sdk

```xml
<!--aliyun-->
<dependency>
    <groupId>com.alibaba.cloud</groupId>
    <artifactId>aliyun-oss-spring-boot-starter</artifactId>
    <version>1.0.0</version>
</dependency>
<dependency>
    <groupId>com.aliyun</groupId>
    <artifactId>aliyun-java-sdk-core</artifactId>
    <version>4.5.0</version>
</dependency>
```



##### 导入公共模块

```xml
<parent>
    <artifactId>springcloud-teach</artifactId>
    <groupId>com.woniuxy</groupId>
    <version>1.0</version>
</parent>
```



##### oss模块中创建实体类

```java
@Data
@AllArgsConstructor
@NoArgsConstructor
public class UploadResult implements Serializable {
    private String fileName;
    private String url;
}
```



##### oss模块中创建controller

```java
package com.woniuxy.oss.controller;

import com.aliyun.oss.OSSClient;
import com.commons.result.ResponseResult;
import com.woniuxy.oss.entity.UploadResult;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;
import org.springframework.web.multipart.MultipartFile;

import javax.annotation.Resource;
import java.io.IOException;
import java.io.InputStream;
import java.net.URL;
import java.util.Date;

@RestController
@RequestMapping("/file")
public class OssController {
    @Resource
    private OSSClient ossClient;

    private static final String BUCKETNAME = "woniuxy-79";
    private String baseUrl = "https://woniuxy-79.oss-cn-chengdu.aliyuncs.com/";

    @PostMapping("/upload")
    public ResponseResult<UploadResult> upload(MultipartFile file){
        //
        ResponseResult<UploadResult> responseResult = new ResponseResult<>(500,"fail",null);

        //1.获得文件名字
        String fileName = file.getOriginalFilename();

        //2.获取文件流
        InputStream inputStream = null;
        try {
            inputStream = file.getInputStream();
            //

            ossClient.putObject(BUCKETNAME,fileName,inputStream);

            //设置文件有效期  60天
            Date date = new Date(new Date().getTime()+ 1000*3600*24*60);
            //获取url
            URL url = ossClient.generatePresignedUrl(BUCKETNAME,fileName,date);

            //返回数据
            UploadResult fileResult = new UploadResult(fileName,baseUrl+fileName);
            //
            responseResult.setStatus(200);
            responseResult.setMessage("success");
            responseResult.setData(fileResult);
            //
            return responseResult;
        }catch (IOException e){
            e.printStackTrace();
        }
        return responseResult;
    }

    //删除文件
    @PostMapping("/del")
    public ResponseResult<String> del(String fileName){
        ossClient.deleteObject(BUCKETNAME,fileName);
        return new ResponseResult<>(200,"success",null);
    }
}
```



##### 在oss的application.yml配置文件中配置eureka、阿里云oss等信息

```yaml
alibaba:
  cloud:
    access-key: LTAI5tHmB7zi4kM8Azw5xqxU
    secret-key: TscBRtri6x1KUXGhdbPYOArFJVALDX
    oss:
      endpoint: oss-cn-chengdu.aliyuncs.com
spring:
  application:
    name: oss
server:
  port: 9999
eureka:
  client: #客户端注册到eureka列表中
    service-url:
      defaultZone: http://127.0.0.1:9001/eureka
  instance:
    instance-id: oss-9600  #注册中心status显示出来的微服务id
    prefer-ip-address: true #显示访问url
```



其中endpoint可以在控制台找到，如下图所示

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210718214120.png" alt="image-20210718214120421" style="zoom: 25%;" />



##### gateway模块中配置oss路由信息

```yaml
spring:
  application:
    name: gateway
  cloud:
    inetutils:
      default-ip-address: 127.0.0.1
    gateway:
      routes:
        - id: oss
          uri: lb://oss
          predicates:
            - Path=/file/**
```



##### 前端代码

```java
<template>
  <div>
   <input type="file" name="file" id="file"><br>
   <button @click="upload()">上传</button>
  </div>
</template>

<script>
export default {
  methods:{
    upload:function(){
      //获取文件
      let file = document.getElementById("file").files[0];
      console.log(file);
      //将file封装到formdata
      let formData = new FormData();
      formData.append("file",file);
      //上传
      this.axios.post("http://localhost:9600/file/upload",formData,{
        headers:{
          'Content-Type':'multipart/form-data'
        }
      }).then(res => {
        console.log(res.data);
      })
    }
  }
}
</script>

<style scoped>

</style>
```



##### 依次启动eureka、oss、gateway微服务，前端向gateway发送请求，浏览器控制台显示以下信息表示成功

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210719203919.png" alt="image-20210719203918891" style="zoom:33%;" />



### 分布式锁的基本概念（中 30）

#### 什么是分布式锁？

要介绍分布式锁，首先要提到与分布式锁相对应的是线程锁、进程锁。

 

线程锁：主要用来给方法、代码块加锁。当某个方法或代码使用锁，在同一时刻仅有一个线程执行该方法或该代码段。线程锁只在同一JVM中有效果，因为线程锁的实现在根本上是依靠线程之间共享内存实现的，比如synchronized是共享对象头，显示锁Lock是共享某个变量（state）。

 

进程锁：为了控制同一操作系统中多个进程访问某个共享资源，因为进程具有独立性，各个进程无法访问其他进程的资源，因此无法通过synchronized等线程锁实现进程锁。

 

分布式锁：当多个进程不在同一个系统中，用分布式锁控制多个进程对资源的访问。

分布式锁是控制分布式系统或不同系统之间共同访问共享资源的一种锁实现，如果不同的系统或同一个系统的不同主机之间共享了某个资源时，往往需要互斥来防止彼此干扰来保证一致性。

 

#### 分布式锁的使用场景

线程间并发问题和进程间并发问题都是可以通过分布式锁解决的，但是强烈不建议这样做！因为采用分布式锁解决这些小问题是非常消耗资源的！分布式锁应该用来解决分布式情况下的多进程并发问题才是最合适的。

 

有这样一个情境，线程A和线程B都共享某个变量X。

 

如果是单机情况下（单JVM），线程之间共享内存，只要使用线程锁就可以解决并发问题。

 

如果是分布式情况下（多JVM），线程A和线程B很可能不是在同一JVM中，这样线程锁就无法起到作用了，这时候就要用到分布式锁来解决。

 

### 分布式锁的解决方案（高 15）

#### 数据库乐观锁

就是在数据库中创建一张锁表，在表中对临界资源做唯一性约束。当系统中的某个节点要访问临界资源时，就向锁表插入一条记录，表示锁定资源。使用完成后删除这条记录，表示释放资源。数据库的唯一性约束保证了当有多个节点同时向锁表插入记录时，只能有一个成功，插入成功的那个节点就可以有权限访问临界资源。

乐观锁在大多数是基于数据版本（version）的记录机制实现的。

```sql
CREATE TABLE `optimistic_lock` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `resource` int(11) NOT NULL COMMENT '锁定的资源',
  `version` int(11) NOT NULL COMMENT '版本信息',
  `created_time` datetime DEFAULT NULL COMMENT '创建时间',
  `updated_time` datetime DEFAULT NULL COMMENT '更新时间',
  `deleted_time` datetime DEFAULT NULL COMMENT '删除时间',
  PRIMARY KEY (`id`),
  UNIQUE KEY `uiq_idx_resource` (`resource`)
) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4 COMMENT='数据库分布式锁表';
```

优点：实现简单

缺点：

- 依赖数据库，性能受限于数据库，在高并发的情况下，数据库可能由行锁变成表锁，性能急剧下降。
- 锁表的数据库容易产生单点故障，导致整体分布式系统不可用。
- 锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他节点无法再获得到锁。



#### 基于ZooKeeper的分布式锁

ZooKeeper数据存储是树形结构，树由节点(Znode)组成。ZooKeeper 的树形数据存储结构主要由 4 种节点构成：

- 持久节点，默认的节点类型。创建节点的客户端与zookeeper断开连接后，该节点依旧存在 。

- 持久顺序节点，客户端在创建节点时，ZooKeeper 根据节点创建的时间顺序对节点进行编号。

- 临时节点，持久节点相反，当创建节点的客户端与zookeeper断开连接后，临时节点会被删除。

- 临时顺序节点，就是按时间顺序编号的临时节点。

Zookeeper是基于临时顺序节点实现了分布式锁：

- 首先在Zookeeper上创建一个持久节点，当有客户端需要获取锁时，就在持久节点下创建一个临时顺序节点。

- 每个客户端进程获取持久节点目录下的所有临时节点列表，注册子节点变更的 Watcher，并监听节点。

- 每个节点确定自己的编号是否是持久节点目录下所有子节点中最小的，若最小，则获得锁。

- 若本客户端进程对应的临时节点编号不是最小的，则等待，直到其他节点编号大的客户端释放锁。

#### 基于redis的分布式锁

a）加锁
加锁实际上就是在redis中，给Key键设置一个值，为避免死锁，并给定一个过期时间。

SET lock_key random_value NX PX 5000

值得注意的是：
random_value 是客户端生成的唯一的字符串。
NX 代表只在键不存在时，才对键进行设置操作。
PX 5000 设置键的过期时间为5000毫秒。

这样，如果上面的命令执行成功，则证明客户端获取到了锁。



b）解锁
解锁的过程就是将Key键删除。但也不能乱删，不能说客户端1的请求将客户端2的锁给删除掉。这时候random_value的作用就体现出来。

为了保证解锁操作的原子性，我们用LUA脚本完成这一操作。先判断当前锁的字符串是否与传入的值相等，是的话就删除Key，解锁成功。



优点

- Redis有更高的性能；
- Redis命令对此支持较好，实现起来比较方便



### Redis实现分布式锁（高 45）

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720171219.png" alt="image-20210720171219098" style="zoom:50%;" />

#### 创建项目

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720172245.png" alt="image-20210720172245737" style="zoom: 33%;" />

##### pom.xml中导入jedis

```xml
<dependency>
    <groupId>redis.clients</groupId>
    <artifactId>jedis</artifactId>
</dependency>

```



##### application.yml添加redis配置

```yaml
server:
  port: 8081

spring:
  redis:
    database: 0
    host: 127.0.0.1
    port: 6379
    timeout: 3600
    jedis:
      pool:
        max-active: 10
        max-wait: -1
        max-idle: 5
        min-idle: 2

```



##### 创建redis配置文件

```java
package com.woniuxy.kill.configuration;

import java.lang.reflect.Method;

import org.springframework.cache.annotation.CachingConfigurerSupport;
import org.springframework.cache.annotation.EnableCaching;
import org.springframework.cache.interceptor.KeyGenerator;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.data.redis.connection.RedisConnectionFactory;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer;
import org.springframework.data.redis.serializer.StringRedisSerializer;

import com.fasterxml.jackson.annotation.JsonAutoDetect;
import com.fasterxml.jackson.annotation.PropertyAccessor;
import com.fasterxml.jackson.databind.ObjectMapper;
/*
 * 开启redis缓存，设置key的生产策略。主要用于注解情况下，默认使用方法的全限定名作为key    自动生成key
 */
@EnableCaching
@Configuration
public class RedisConfiguration extends CachingConfigurerSupport{
    /*
     * key的生成策略
     */
    @Override
    public KeyGenerator keyGenerator() {
        // TODO Auto-generated method stub
        return new KeyGenerator() {
            /*
             * 参数1：要操作的目标对象
             * 参数2：要操作的方法
             * 参数3：执行方法时的参数
             */
            @Override
            public Object generate(Object target, Method method, Object... params) {
                StringBuilder sBuilder = new StringBuilder();
                sBuilder.append(target.getClass().getName());
                sBuilder.append(".");
                sBuilder.append(method.getName());    //生成key
                for(Object object:params){
                    sBuilder.append(".");
                    sBuilder.append(object.toString());
                }
                return sBuilder.toString();
            }
        };
    }
    /**
     * redisTemplate相关配置
     * @param factory
     * @return
     */
    @Bean
    @SuppressWarnings("all")
    public RedisTemplate<String, Object> redisTemplate(RedisConnectionFactory factory) {
        RedisTemplate<String, Object> template  = new RedisTemplate<>();
        //设置工厂
        template.setConnectionFactory(factory);
        //使用Jackson2JsonRedisSerializer来序列化和反序列化redis的value值（默认使用JDK的序列化方式）
        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer =
                new Jackson2JsonRedisSerializer<>(Object.class);
        //创建对象映射
        ObjectMapper mapper = new ObjectMapper();
        //指定要序列化的域，field,get和set,以及修饰符范围，ANY是都有包括private和public
        mapper.setVisibility(PropertyAccessor.ALL,JsonAutoDetect.Visibility.ANY);
        //指定序列化输入的类型，类必须是非final修饰的，final修饰的类，比如String,Integer等会抛出异常
        mapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);
        //
        jackson2JsonRedisSerializer.setObjectMapper(mapper);
        //字符串序列化器
        StringRedisSerializer stringRedisSerializer = new StringRedisSerializer();
        //key采用String的序列化方式
        template.setKeySerializer(stringRedisSerializer);
        //hash的key也采用String的方式
        template.setHashKeySerializer(stringRedisSerializer);
        //value采用jackson的方式
        template.setValueSerializer(jackson2JsonRedisSerializer);
        //hash的value也采用Jackson
        template.setHashValueSerializer(jackson2JsonRedisSerializer);

        template.afterPropertiesSet();
        return template;
    }
}

```



##### 创建controller

```java
package com.woniuxy.kill.controller;

import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

@RestController
@RequestMapping("/sale")
public class KillController {
    @Resource
    private RedisTemplate<String,Object> redisTemplate;

    @GetMapping("/kill")
    public boolean kill(){
        boolean flag = false;
        int num = (Integer)redisTemplate.opsForValue().get("num");

        if (num >0 ){
            num--;
            System.out.println("删减库存成功,剩余库存:"+num);
            //设置回去
            redisTemplate.opsForValue().set("num",num);
            //
            flag = true;
        }

        return flag;
    }
}

```



##### 版本1

```java
@GetMapping("/kill")
public boolean kill() {
	boolean flag = false;	
	int num = (Integer)redisTemplate.opsForValue().get("num");
	if (num>0) {
		num--;
		System.out.println("删减库存成功,剩余库存:"+num);
		//修改库存
		redisTemplate.opsForValue().set("num", num+"");
		flag = true;
	}
	return flag;
}

```

缺点：在集群环境下无法保证redis数据安全

改进思路：通过redis的setnx实现一把简单的分布式锁



##### 版本2

```java
@GetMapping("/kill")
public boolean kill() {
	boolean flag = false;
	String lock = "key";  //通过setnx命令设置key
	boolean result = redisTemplate.opsForValue().setIfAbsent(lock, "woniuxy");	
    if (!result) {
		return flag;
	}
	......
	redisTemplate.delete(lock);
	return flag;
}

```

缺点：如果在释放锁之前代码出现异常，将导致锁无法被释放

改进思路：在finally中释放锁



##### 版本3

```java
@GetMapping("/kill")
public boolean kill() {
	boolean flag = false;
	String lock = "key";  //通过setnx命令设置key
     try{
	    boolean result = redisTemplate.opsForValue().setIfAbsent(lock, "woniuxy");	    
        if (!result) {
		    return flag;
	    }
	    ......
     }finally{
	    redisTemplate.delete(lock);
     }
	return flag;
}

```

缺点：当前服务器在释放锁之前宕机，导致锁无法被释放
改进思路：设置过期时间



##### 版本4

```java
@GetMapping("/kill")
public boolean kill() {
	boolean flag = false;
	String lock = "key";  //通过setnx命令设置key
     try{
	    boolean result = redisTemplate.opsForValue().setIfAbsent(lock, "woniuxy");
         redisTemplate.expire(lock, 10, TimeUnit.SECONDS);
	    if (!result) {
		    return flag;
	    }
	    ......
     }finally{
	    redisTemplate.delete(lock);
     }
	return flag;
}

```

缺点：在设计过期时间之前宕机，锁依然无法释放
改进思路：在获取锁的同时指定过期时间



##### 版本5

```java
@GetMapping("/kill")
public boolean kill() {
	boolean flag = false;
	String lock = "key";  //通过setnx命令设置key
     try{
	    boolean result = redisTemplate.opsForValue()
                .setIfAbsent(lock, "woniuxy", 10, TimeUnit.SECONDS);
	    if (!result) {
		    return flag;
	    }
	    ......
     }finally{
	    redisTemplate.delete(lock);
     }
	return flag;
}

```



缺点：如果完成业务时间的大于或者小于过期时间，都有可能出现前一个进程删除后一个进程的锁

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720171607.png" alt="image-20210720171607660" style="zoom: 50%;" />

改进思路：在获取锁时指定唯一id



##### 版本6

```java
@GetMapping("/kill")
public boolean kill() {
    String id = UUID.randomUUID().toString();	
    boolean flag = false;	String lock = "key";
    try {
	   boolean result = redisTemplate.opsForValue().setIfAbsent(lock, id, 10, TimeUnit.SECONDS);
	   ......
    } finally{
	   //先获取进行判断
	   if (id.equals(redisTemplate.opsForValue().get(lock))) {
		  //删除key
		  redisTemplate.delete(lock);
	   }
    }
    return flag;
}

```

缺点：
      过期时间固定，不太合适，因为可能存在业务超过过期时间的情况（不够时需要续命）
      加锁的机器宕机，其他机器只能等待key过期才能执行（降低效率）



### Redisson的使用（高 30）

#### pom.xml导入redisson依赖

```xml
<!--redisson-->
<dependency>
    <groupId>org.redisson</groupId>
    <artifactId>redisson</artifactId>
    <version>3.12.5</version>
</dependency>

```


#### 创建redisson配置类

```java
package com.woniuxy.kill.configuration;

import org.redisson.Redisson;
import org.redisson.config.Config;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class RedissonConfiguration {
    @Bean
    public Redisson redisson() {
        //单机模式
        Config config = new Config();
        config.useSingleServer().setAddress("redis://127.0.0.1:6379").setDatabase(0);
        return (Redisson)Redisson.create(config);
    }
}

```



#### 修改controller

```java
package com.woniuxy.kill.controller;

import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

import org.redisson.Redisson;
import org.redisson.api.RLock;

import javax.annotation.Resource;

@RestController
@RequestMapping("/sale")
public class KillController {
    @Autowired
    private RedisTemplate<String,Object> redisTemplate;

    @Resource
    private Redisson redisson;


    @GetMapping("/kill")
    public boolean kill(){
        boolean flag = false;
        String lock = "key";
        RLock rLock = redisson.getLock(lock);
        try {

            rLock.lock();
            int num = (Integer) redisTemplate.opsForValue().get("num");
            if (num>0) {
                num--;
                System.out.println("删减库存成功,剩余库存:"+num);
                //设置回去
                redisTemplate.opsForValue().set("num", num+"");
                //
                flag = true;
            }
        } finally{
            rLock.unlock();
        }
        return flag;
    }
}

```

# day07

### 链路追踪简介（中 15）

Sleuth是Spring Cloud的组件之一，它为Spring Cloud实现了一种分布式追踪解决方案，兼容Zipkin，HTrace和其他基于日志的追踪系统，例如 ELK（Elasticsearch 、Logstash、 Kibana）。

 

Seuth主要功能是在分布式系统中提供追踪解决方案，并且兼容支持了Zipkin(提供了链路追踪的可视化功能)利用这些信息，可以可视化地分析服务调用链路和服务间的依赖关系。


#### 相关术语

Sleuth引入了许多 Dapper中的术语：

 

- Span

基本的工作单元。无论是发送一个请求或响应都是一个Span。每一个Span通过一个64位ID来进行唯一标识，并通过另一个64位ID对Span所在的Trace进行唯一标识。

Span能够启动和停止，他们不断地追踪自身的时间信息，当你创建了一个Span，你必须在未来的某个时刻停止它。

提示：启动一个Trace的初始化Span被叫作 Root Span ，它的 Span ID 和 Trace Id 相同。

 

- Trace

由一系列Span 组成的一个树状结构。例如，如果你要执行一个分布式大数据的存储操作，这个Trace也许会由你的PUT请求来形成。

 

- Annotation：用来及时记录一个事件的存在。通过引入Brave库，我们不用再去设置一系列的特别事件，从而让 Zipkin 能够知道客户端和服务器是谁、请求是从哪里开始的、又到哪里结束。出于学习的目的，还是把这些事件在这里列举一下：

  a）CS （Client start） - 客户端发起一个请求，这个注释指示了一个Span的开始。

  b）SS （Server Start） - 服务端接收请求并开始处理它，如果用 SS 时间戳减去CS时间戳便能看出有多少网络延迟。

  c）SF（Server Finish）- 注释请求处理完成(响应已发送给客户端)，如果用 SF 时间戳减去SS 时间戳便可得出服务端处理请求耗费的时间。

  d）CF（Client Finish）- 预示了一个Span的结束，客户端成功地接 收到了服务端的响应，如果用CF时间戳减去CS时间戳便可得出客户端从服务端获得响应所需耗费的整个时间。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720212314.png" alt="image-20210720212313914" style="zoom: 50%;" />

Sleuth是对Zipkin的封装，对应Span,Trace等信息的生成、接入HttpRequest,以及向Zipkin Server发送采集信息等全部自动化完成。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720212620.png" alt="image-20210720212619907" style="zoom: 50%;" />

一次单独的调用链也可以称为一个Span，Dapper记录的是Span的名称，以及每个Span的ID和父ID，以重建在一次追踪过程中不同Span之间的关系，上图中一个矩形框就是一个Span，前端从发出请求到收到回复就是一个Span。

再细化到一个Span的内部，如下图：

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720212402.png" alt="image-20210720212401964" style="zoom:50%;" />



对于一个特定的Span，记录从Start到End，首先经历了客户端发送数据，然后Server接收数据，然后Server执行内部逻辑，这中间可能去访问另一个应用。执行完了Server将数据返回，然后客户端接收到数据。

 

一个Span的内容就能构成Trace上面的一个基本元素，可以在这个Span中埋点打上各种各样的Trace类型，比如，一般将客户端发送记录成依赖（Dependency），服务端接收客户端以及回复给客户端这两个时间统一记录成请求（Request），如果打上这两种，那么在运行完这个Span之后，日志库中就会多出两条日志，一条是Dependency的日志，一条是Request的日志。

 

现在的Trace SDK，都可以进行配置去自动记录一些事件，比如数据库调用依赖，Http调用依赖，记录上游的请求等等，也可以自己手动埋点，在需要打上记录点的地方写上记录的代码即可。

 

Dapper中给出的是一张这样的图

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720212430.png" alt="image-20210720212430783" style="zoom: 50%;" />

首先各个日志收集点按照一定的采样率将日志写进数据文件，然后通过管道将这些日志文件按照一定的TraceId排定输出到BigTable中去。

如果一个系统完成了上面阐述的架构，基本可以构成一个简单的Trace系统。



#### TraceId和ParentId的生成

在整个过程中，TraceId和ParentId的生成至关重要。首先解释下TraceId和ParentId。TraceId是标识这个调用链的Id，整个调用链，从浏览器开始放完，到A到B到C，一直到调用结束，所有应用在这次调用中拥有同一个TraceId，所以才能把这次调用链在一起。

 

既然知道了这次调用链的整个Id，那么每次查找问题的时候，只要知道某一个调用的TraceId，就能把所有这个Id的调用全部查找出来，能够清楚的知道本地调用链经过了哪些应用，产生了哪些调用。但是还缺一点，那就是链。

 

在Java中的LinkedList、Tree等数据结构，可以通过父节点就能够知道子节点，或者通过子节点能够知道父节点是谁（双向链表），那么我们想知道应用A调用了哪些应用，而又有哪些应用调用了应用A，单纯从TraceId里面根本看不出来，必须要指定自己的父节点才行，这就是ParentId的作用。



### 微服务与Zipkin的整合（中 20）

#### 下载安装Zipkin

​		https://dl.bintray.com/openzipkin/maven/io/zipkin/java/zipkin-server/

选择2.12.9版本

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720212714.png" alt="image-20210720212714225" style="zoom: 50%;" />

下载jar包

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720212733.png" alt="image-20210720212733264" style="zoom: 50%;" />

##### 将下载下来的jar包放到任意目录下

打开命令行工具，切换工作路径到jar包所在的位置，输入以下命令运行Zipkin

​	java -jar zipkin-server-2.12.9-exec.jar

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720212751.png" alt="image-20210720212750929" style="zoom: 50%;" />

##### 打开浏览器输入：localhost:9411/zipkin打开Zipkin管理页面

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720212805.png" alt="image-20210720212805200" style="zoom: 50%;" />

##### 在provider中加入依赖

```xml
<!--zipkin-->
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-zipkin</artifactId>
</dependency>
```

##### 在provider的application.yml文件中添加配置

```yaml
spring:
  application:
    name: provider
  zipkin:
    base-url: http://localhost:9411
  sleuth:
    sampler:
      probability: 1
```



##### 在consumer模块的pom.xml中加入依赖

```xml
<!--zipkin-->
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-zipkin</artifactId>
</dependency>
```

##### 在consumer的application.yml文件中添加配置

```yaml
spring:
  application:
    name: consumer
  zipkin:
    base-url: http://localhost:9411
  sleuth:
    sampler:
      probability: 1
```

依次启动redis、zipkin、eureka、provider、consumer



##### 访问consumer的all方法

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720214855.png" alt="image-20210720214855214" style="zoom: 50%;" />

**<font color='red'>刷新Zipkin管理页面</font>**

点击all旁边的下拉按钮，可以看到刚才请求过程中涉及到的微服务，选择comsumer

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720215031.png" alt="image-20210720215030856" style="zoom: 33%;" />

点击”查找”

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720215108.png" alt="image-20210720215108302" style="zoom:33%;" />

可以看到页面下方有一个时间提示，点击

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720215154.png" alt="image-20210720215154709" style="zoom:33%;" />

在新的页面中可以看到刚才请求中的微服务和各微服务消耗的时间

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720215255.png" alt="image-20210720215255622" style="zoom:33%;" />

 

### RabbitMQ概述（中 20）

常用消息队列介绍概述及应用场景，RabbitMQ简介

 <img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720215457.png" alt="image-20210720215456906" style="zoom:33%;" />

#### 什么是MQ

消息队列（Message Queue，简称MQ），从字面意思上看，本质是个队列，FIFO先入先出，只不过队列中存放的内容是message而已。

其主要用途：不同进程Process/线程Thread之间通信。

 

为什么会产生消息队列？有几个原因：

- 不同进程（process）之间传递消息时，两个进程之间耦合程度过高，改动一个进程，引发必须修改另一个进程，为了隔离这两个进程，在两进程间抽离出一层（一个模块），所有两进程之间传递的消息，都必须通过消息队列来传递，单独修改某一个进程，不会影响另一个；

 

- 不同进程（process）之间传递消息时，为了实现标准化，将消息的格式规范化了，并且，某一个进程接受的消息太多，一下子无法处理完，并且也有先后顺序，必须对收到的消息进行排队，因此诞生了事实上的消息队列；

 

#### RabbitMQ介绍

RabbitMQ是由Erlang语言开发的AMQP的开源实现。

 

AMQP：Advanced Message Queue，高级消息队列协议。它是应用层协议的一个开放标准，为面向消息的中间件设计，基于此协议的客户端与消息中间件可传递消息，并不受产品、开发语言等条件的限制。

 

#### RabbitMQ特点

- 可靠性(Reliablity)

  使用了一些机制来保证可靠性，比如持久化、传输确认、发布确认。

- 灵活的路由(Flexible Routing)

  在消息进入队列之前，通过Exchange来路由消息。对于典型的路由功能，Rabbit已经提供了一些内置的Exchange来实现。针对更复杂的路由功能，可以将多个Exchange绑定在一起，也通过插件机制实现自己的Exchange。

- 消息集群(Clustering)

  多个RabbitMQ服务器可以组成一个集群，形成一个逻辑Broker。

- 高可用(Highly Avaliable Queues)

  队列可以在集群中的机器上进行镜像，使得在部分节点出问题的情况下队列仍然可用。

- 多种协议(Multi-protocol)

  支持多种消息队列协议，如STOMP、MQTT等。

- 多种语言客户端(Many Clients)

  几乎支持所有常用语言，比如Java、.NET、Ruby等。

- 管理界面(Management UI)

  提供了易用的用户界面，使得用户可以监控和管理消息Broker的许多方面。

- 跟踪机制(Tracing)

  如果消息异常，RabbitMQ提供了消息的跟踪机制，使用者可以找出发生了什么。

- 插件机制(Plugin System)

  提供了许多插件，来从多方面进行扩展，也可以编辑自己的插件。

#### 应用场景

##### 1、异步处理

场景说明：用户注册后，需要发注册邮件和注册短信,传统的做法有两种：串行方式、并行方式

- 串行方式:将注册信息写入数据库后,发送注册邮件,再发送注册短信,以上三个任务全部完成后才返回给客户端。 这有一个问题是,邮件,短信并不是必须的,它只是一个通知,而这种做法让客户端等待没有必要等待的东西.

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720215709.png" alt="image-20210720215709121" style="zoom:50%;" />

- 并行方式:将注册信息写入数据库后,发送邮件的同时,发送短信,以上三个任务完成后,返回给客户端,并行的方式能提高处理的时间。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720215737.png" alt="image-20210720215737666" style="zoom:50%;" />

假设三个业务节点分别使用50ms,串行方式使用时间150ms,并行使用时间100ms。虽然并性已经提高的处理时间,但是,前面说过,邮件和短信对我正常的使用网站没有任何影响，客户端没有必要等着其发送完成才显示注册成功,英爱是写入数据库后就返回。



- 消息队列 

  引入消息队列后，把发送邮件,短信不是必须的业务逻辑异步处理

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720215814.png" alt="image-20210720215814677" style="zoom:50%;" />

由此可以看出,引入消息队列后，用户的响应时间就等于写入数据库的时间+写入消息队列的时间(可以忽略不计),引入消息队列后处理后,响应时间是串行的3倍,是并行的2倍。



##### 2、应用解耦

场景：双11是购物狂节,用户下单后,订单系统需要通知库存系统,

传统的做法就是订单系统调用库存系统的接口

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720215900.png" alt="image-20210720215900697" style="zoom:50%;" />

这种做法有一个缺点:

当库存系统出现故障时,订单就会失败。

订单系统和库存系统高耦合。

 

引入消息队列 

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720215915.png" alt="image-20210720215915705" style="zoom:50%;" />

订单系统:用户下单后,订单系统完成持久化处理,将消息写入消息队列,返回用户订单下单成功。

库存系统:订阅下单的消息,获取下单消息,进行库操作。 

就算库存系统出现故障,消息队列也能保证消息的可靠投递,不会导致消息丢失



##### 3、流量削峰

流量削峰一般在秒杀活动中应用广泛 

场景:秒杀活动，一般会因为流量过大，导致应用挂掉,为了解决这个问题，一般在应用前端加入消息队列。 

作用: 

- 可以控制活动人数，超过此一定阀值的订单直接丢弃 

- 可以缓解短时间的高流量压垮应用(应用程序按自己的最大处理能力获取订单)

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720215941.png" alt="image-20210720215941237" style="zoom:50%;" />

处理过程

- 用户的请求,服务器收到之后,首先写入消息队列,加入消息队列长度超过最大值,则直接抛弃用户请求或跳转到错误页面. 

- 秒杀业务根据消息队列中的请求信息，再做后续处理.



##### 4、消息驱动的系统



#### Rabbit体系架构

系统分为消息队列、消息生产者、消息消费者，生产者负责产生消息，消费者负责对消息进行处理

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720220041.png" alt="image-20210720220041493" style="zoom:67%;" />



### 安装配置（低 20）



输入**<font color='red'>yum install *.rpm</font>**命令进行安装

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720220129.png" alt="image-20210720220129541" style="zoom:67%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720220139.png" alt="image-20210720220139303" style="zoom:67%;" />

启动rabbit mq

执行**<font color='red'>sudo service rabbitmq-server start</font>**

提示如图所示则表示启动成功

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720220154.png" alt="image-20210720220154184" style="zoom:67%;" />

配置rabbitmq管理账户。

执行命令 **<font color='red'>rabbitmqctl add_user admin admin</font>**，设置账户密码为admin admin

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720220211.png" alt="image-20210720220211182" style="zoom:67%;" />

执行命令 **<font color='red'>rabbitmqctl set_user_tags admin administrator</font>**，设置admin为管理员权限

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720220224.png" alt="image-20210720220224179" style="zoom:67%;" />

执行命令**<font color='red'> rabbitmq-plugins enable rabbitmq_management</font>**，打开rabbitmq web管理

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720220240.png" alt="image-20210720220240197" style="zoom:67%;" />

开放端口

firewall-cmd --zone=public --add-port=5672/tcp --permanent
firewall-cmd --zone=public --add-port=15672/tcp --permanent
sudo service firewalld restart



测试rabbit mq是否可以，打开浏览器在地址栏中输入：http://虚拟机ip:15672,出现登录页面，登陆账户密码为设置的admin admin

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720220254.png" alt="image-20210720220254230" style="zoom:67%;" />

查看用户权限,默认状态下权限是不允许访问(此时程序访问5672端口是连接被拒绝)

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720220306.png" alt="image-20210720220306204" style="zoom:67%;" />

点击用户名，进入用户页面，直接点击设置权限。此时刷新页面回到Users页面，权限变成可访问

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720220324.png" alt="image-20210720220324701" style="zoom:67%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720220333.png" alt="image-20210720220333577" style="zoom:67%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720220339.png" alt="image-20210720220339572" style="zoom: 67%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720220333.png" alt="image-20210720220333577" style="zoom:67%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210720220339.png" alt="image-20210720220339572" style="zoom:67%;" />



#### 常见问题

 http://ip:15672不能访问，确认两点：

1、 添加用户、给用户设置管理员权限、rabbitmq-plugins这三步是否执行成功。

2、使用firewall打开5672/15672端口。具体步骤如下：

```
firewall-cmd --zone=public --add-port=5672/tcp --permanent
firewall-cmd --zone=public --add-port=15672/tcp --permanent
sudo service firewalld restart（如果系统不要求开启防火墙，可以在设置完以后再关闭它）
备注：即使防火墙处于关闭状态，也应该先打开端口再关闭，否则在有些机器上会仍然端口不通。
```



### 相关概念及常用命令（低 20）

#### 常见概念

##### 生产者

​	创建消息，发布到代理服务器（Message Broker）。

##### 消费者

​	连接到代理服务器，并订阅到队列（queue）上，代理服务器将发送消息给一个订阅的/监听的消费者

##### 队列

​	队列结构，先进先出（FIFO）

##### 虚拟主机

​	虚拟机概念是RabbitMQ的核心,在用户未自定义虚拟机前已经内置有虚拟机,在使用RabbitMQ中,可以进行自定义配置虚拟机。一个虚拟机中可以含有多个队列信息

​	虚拟机最大的好处在于可以根据不同的用户分配不同的操作空间

**创建虚拟主机**

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210810201848.png" alt="image-20210810201847824" style="zoom: 33%;" />

指定主机名，点击添加

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210810202050.png" alt="image-20210810202050237" style="zoom:33%;" />

指定能够访问虚拟主机的用户（默认guest）

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210810202337.png" alt="image-20210810202337442" style="zoom:33%;" />

删除不需要的用户

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210810202538.png" alt="image-20210810202537944" style="zoom:33%;" />

指定新用户

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210810202607.png" alt="image-20210810202607698" style="zoom:33%;" />

得到如下结果表明成功

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210810202633.png" alt="image-20210810202632788" style="zoom:33%;" />


### Java客户端访问RabbitMQ（低 30）

#### 创建springboot项目

<img src="C:\Users\Administrator\Desktop\20210721153235.png" alt="image-20210721153235607" style="zoom: 33%;" />

导入依赖

```xml
<!--rabbit mq-->
<dependency>
    <groupId>com.rabbitmq</groupId>
    <artifactId>amqp-client</artifactId>
    <version>5.1.1</version>
</dependency>
```

### Simple简单模式（中 20）

#### RabbitMQ工作模式的介绍

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210721154205.png" alt="image-20210721154205876" style="zoom: 67%;" />

- 消息产生者将消息放入队列

- 消息的消费者(consumer) 监听(while) 消息队列,如果队列中有消息,就消费掉,消息被拿走后,自动从队列中删除(隐患 消息可能没有被消费者正确处理,已经从队列中消失了,造成消息的丢失)应用场景:聊天(中间有一个过度的服务器;p端,c端)

#### 编写生产者代码

```java
package com.woniuxy.rabbitteach.simple;

import com.rabbitmq.client.Channel;
import com.rabbitmq.client.Connection;
import com.rabbitmq.client.ConnectionFactory;

import java.io.IOException;
import java.util.concurrent.TimeoutException;

public class Productor {
    public static void main(String[] args) throws IOException, TimeoutException {
        //1.创建连接工厂
        ConnectionFactory factory = new ConnectionFactory();
        //2.设置参数
        factory.setHost("192.168.74.146");
        factory.setPort(5672);
        factory.setUsername("admin");
        factory.setPassword("admin");
        factory.setVirtualHost("/test");  //设置虚拟主机   默认/
        //3.创建连接
        Connection connection = factory.newConnection();
        //4.创建通道
        Channel channel = connection.createChannel();
        //5.创建消息队列
        //参数1：队列名
        //参数2：是否持久化
        //参数3：是否排外，一个队列只允许一个消费者连接
        //参数4：是否自动删除
        //参数5：初始化参数

        channel.queueDeclare("test",false,false,false,null);
        //6.发送消息
        channel.basicPublish("","test",null,"hello world".getBytes());
        //7.关闭资源
        channel.close();
        connection.close();
    }
}
```

#### 消费者代码

```java
package com.woniuxy.rabbitteach.simple;

import com.rabbitmq.client.*;

import java.io.IOException;
import java.util.concurrent.TimeoutException;

public class Received {
    public static void main(String[] args) throws IOException, TimeoutException {
        //1.创建连接工厂
        ConnectionFactory factory = new ConnectionFactory();
        //2.设置参数
        factory.setHost("192.168.74.146");
        factory.setPort(5672);
        factory.setUsername("admin");
        factory.setPassword("admin");
        factory.setVirtualHost("/test");  //设置虚拟主机   默认/
        //3.创建连接
        Connection connection = factory.newConnection();
        //4.创建通道
        Channel channel = connection.createChannel();
        //5.创建消息队列
        channel.queueDeclare("test",false,false,false,null);
        //6.创建消费者
        Consumer consumer = new DefaultConsumer(channel){
            @Override
            public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException {
                String message = new String(body,"UTF-8");
                System.out.println(message);
            }
        };
        //7.消费者确认消息并进行处理
        //参数1：队列名
        //参数2：true 接收到传递过来的消息后acknowledged（应答服务器），false 接收到消息后不应答服务器
        //参数3：消费者对象的回调接口
        channel.basicConsume("test",true,consumer);
    }
}
```

依次运行rabbitmq、Received、Productor

**<font color='red'>注意：每次测试时，最好将之前的消息队列删除</font>**



### Work模式（中 25）

#### 介绍

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210721154902.png" alt="image-20210721154902797" style="zoom:67%;" />

- 消息产生者将消息放入队列消费者可以有多个,消费者1,消费者2,同时监听同一个队列,消息被消费者C1 C2共同争抢当前的消息队列内容,谁先拿到谁负责消费消息(隐患,高并发情况下,默认会产生某一个消息被多个消费者共同使用,可以设置一个开关(syncronize,与同步锁的性能不一样) 保证一条消息只能被一个消费者使用)

- 应用场景:红包;大项目中的资源调度(任务分配系统不需知道哪一个任务执行系统在空闲,直接将任务扔到消息队列中,空闲的系统自动争抢)

#### 生产者，在simple模式代码基础上循环发送消息

```java
package com.woniuxy.rabbitteach.work;

import com.rabbitmq.client.Channel;
import com.rabbitmq.client.Connection;
import com.rabbitmq.client.ConnectionFactory;

import java.io.IOException;
import java.util.concurrent.TimeoutException;

public class Productor {
    public static void main(String[] args) throws IOException, TimeoutException {
        //1.创建连接工厂
        ConnectionFactory factory = new ConnectionFactory();
        //2.设置参数
        factory.setHost("192.168.74.146");
        factory.setPort(5672);
        factory.setUsername("admin");
        factory.setPassword("admin");
        //3.创建连接
        Connection connection = factory.newConnection();
        //4.创建通道
        Channel channel = connection.createChannel();
        //5.创建消息队列
        //参数1：队列名
        //参数2：是否持久化
        //参数3：是否排外，一个队列只允许一个消费者连接
        //参数4：是否自动删除
        //参数5：初始化参数

        channel.queueDeclare("test",false,false,false,null);
        //6.发送消息
        for(int i=0;i<10;i++){
            channel.basicPublish("","test",null,("hello world"+i).getBytes());
        }
        //7.关闭资源
        channel.close();
        connection.close();
    }
}

```



#### 创建两个消费者

#### 消费者同simple模式



利用Productor发送消息，可以看到两个消费者的控制台打印信息如下

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210721155421.png" alt="image-20210721155421839" style="zoom:67%;" />

### 订阅模式（中 25）

#### 介绍

publish/subscribe发布订阅(共享资源)

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210721155503.png" alt="image-20210721155503436" style="zoom:67%;" />

- X代表交换机rabbitMQ内部组件,erlang 消息产生者是代码完成,代码的执行效率不高,消息产生者将消息放入交换机,交换机发布订阅把消息发送到所有消息队列中,对应消息队列的消费者拿到消息进行消费

- 相关场景:邮件群发,群聊天,广播(广告)

#### 生产者

```java
public class Productor {
    public static String EXCHANGE_NAME = "exchange-1";

    public static void main(String[] args) throws IOException, TimeoutException {
        ConnectionFactory factory = new ConnectionFactory();
        factory.setHost("192.168.74.146");
        factory.setPort(5672);
        factory.setUsername("admin");
        factory.setPassword("admin");
        Connection connection = factory.newConnection();
        Channel channel = connection.createChannel();

        //创建交换机fanout
        channel.exchangeDeclare(EXCHANGE_NAME,"fanout");
        //发送消息
        for(int i=0;i<10;i++){
            channel.basicPublish(EXCHANGE_NAME,"", null, ("hello"+i).getBytes());
        }
        channel.close();
        connection.close();
    }
}

```

#### 消费者

```java
public class Consumer1 {
    public static String EXCHANGE_NAME = "exchange-1";

    public static void main(String[] args) throws IOException, TimeoutException {
        ConnectionFactory factory = new ConnectionFactory();
        factory.setHost("192.168.74.146");
        factory.setPort(5672);
        factory.setUsername("admin");
        factory.setPassword("admin");
        Connection connection = factory.newConnection();
        Channel channel = connection.createChannel();
        //声明交换机
        channel.exchangeDeclare(EXCHANGE_NAME,"fanout");
        //获取随机队列名
        String queueName = channel.queueDeclare().getQueue();
        //绑定交换机和队列
        channel.queueBind(queueName,EXCHANGE_NAME,"");
        Consumer consumer = new DefaultConsumer(channel){
            @Override
            public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException {
                String message = new String(body,"UTF-8");
                System.out.println(message);
            }
        };
        channel.basicConsume(queueName,true,consumer);
    }
}


```



### 路由模式（中 25）

#### 介绍

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210721155604.png" alt="image-20210721155604376" style="zoom:67%;" />

- 消息生产者将消息发送给交换机按照路由判断,路由是字符串(info) 当前产生的消息携带路由字符(对象的方法),交换机根据路由的key,只能匹配上路由key对应的消息队列,对应的消费者才能消费消息;

- 根据业务功能定义路由字符串

- 从系统的代码逻辑中获取对应的功能字符串,将消息任务扔到对应的队列中业务场景:error 通知;EXCEPTION;错误通知的功能;传统意义的错误通知;客户通知;利用key路由,可以将程序中的错误封装成消息传入到消息队列中,开发者可以自定义消费者,实时接收错误;

#### 生产者

```java
public class Productor {
    public static String EXCHANGE_NAME = "rout-1";
    public static List<String> routs = new ArrayList<>();
    static {
        routs.add("news");
        routs.add("weather");
    }

    public static void main(String[] args) throws IOException, TimeoutException {
        ConnectionFactory factory = new ConnectionFactory();
        factory.setHost("192.168.74.146");
        factory.setPort(5672);
        factory.setUsername("admin");
        factory.setPassword("admin");
        Connection connection = factory.newConnection();
        Channel channel = connection.createChannel();
        //声明交换机
        channel.exchangeDeclare(EXCHANGE_NAME,"direct");
        //发送消息
        Random random = new Random();
        for(int i = 0;i < 10; i++){
            String rout = routs.get(random.nextInt(2));
            channel.basicPublish(EXCHANGE_NAME, rout,null,("hello"+i).getBytes());
        }

        channel.close();
        connection.close();
    }
}

```

#### 消费者

```java
public class Consumer {

    public static String EXCHANGE_NAME = "rout-1";

    public static void main(String[] args) throws IOException, TimeoutException {
        ConnectionFactory factory = new ConnectionFactory();
        factory.setHost("192.168.74.146");
        factory.setPort(5672);
        factory.setUsername("admin");
        factory.setPassword("admin");
        Connection connection = factory.newConnection();
        Channel channel = connection.createChannel();
        //声明交换机
        channel.exchangeDeclare(EXCHANGE_NAME,"direct");
        //获取随机队列名
        String queueName = channel.queueDeclare().getQueue();
        //绑定交换机和队列
        channel.queueBind(queueName,EXCHANGE_NAME,"news");
        Consumer consumer = new DefaultConsumer(channel){
            @Override
            public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException {
                String message = new String(body,"UTF-8");
                System.out.println(message);
            }
        };
        channel.basicConsume(queueName,true,consumer);
    }
}

```



### 主题模式（中 25）

#### 介绍

topic主题模式(路由模式的一种)

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210721155705.png" alt="image-20210721155705717" style="zoom:67%;" />

- 星号井号代表通配符

- 星号代表一个单词,井号代表零个或多个单词

- 路由功能添加模糊匹配

- 消息产生者产生消息,把消息交给交换机

- 交换机根据key的规则模糊匹配到对应的队列,由队列的监听消费者接收消息消费

#### 生产者

```java
public class Productor {
    public static String EXCHANGE_NAME = "topic-1";

    public static void main(String[] args) throws IOException, TimeoutException {
        ConnectionFactory factory = new ConnectionFactory();
        factory.setHost("192.168.74.146");
        factory.setPort(5672);
        factory.setUsername("admin");
        factory.setPassword("admin");
        Connection connection = factory.newConnection();
        Channel channel = connection.createChannel();
        //声明交换机
        channel.exchangeDeclare(EXCHANGE_NAME,"topic");
        //发送消息
        Random random = new Random();
        for(int i = 0;i < 10; i++){
            channel.basicPublish(EXCHANGE_NAME, "chengdu.news",null,("hello"+i).getBytes());
        }

        channel.close();
        connection.close();
    }
}

```

#### 消费者1

```java
public class Consumer1 {

    public static String EXCHANGE_NAME = "topic-1";

    public static void main(String[] args) throws IOException, TimeoutException {
        ConnectionFactory factory = new ConnectionFactory();
        factory.setHost("192.168.74.146");
        factory.setPort(5672);
        factory.setUsername("admin");
        factory.setPassword("admin");
        Connection connection = factory.newConnection();
        Channel channel = connection.createChannel();
        //声明交换机
        channel.exchangeDeclare(EXCHANGE_NAME,"topic");
        //获取随机队列名
        String queueName = channel.queueDeclare().getQueue();
        //绑定交换机和队列
        channel.queueBind(queueName,EXCHANGE_NAME,"*.news");
        Consumer consumer = new DefaultConsumer(channel){
            @Override
            public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException {
                String message = new String(body,"UTF-8");
                System.out.println("news:"+message);
            }
        };
        channel.basicConsume(queueName,true,consumer);
    }
}

```

#### 消费者2

```java
public class Consumer1 {

    public static String EXCHANGE_NAME = "topic-1";

    public static void main(String[] args) throws IOException, TimeoutException {
        ConnectionFactory factory = new ConnectionFactory();
        factory.setHost("192.168.74.146");
        factory.setPort(5672);
        factory.setUsername("admin");
        factory.setPassword("admin");
        Connection connection = factory.newConnection();
        Channel channel = connection.createChannel();
        //声明交换机
        channel.exchangeDeclare(EXCHANGE_NAME,"topic");
        //获取随机队列名
        String queueName = channel.queueDeclare().getQueue();
        //绑定交换机和队列
        channel.queueBind(queueName,EXCHANGE_NAME,"chengdu.*");
        Consumer consumer = new DefaultConsumer(channel){
            @Override
            public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException {
                String message = new String(body,"UTF-8");
                System.out.println("chengdu:"+message);
            }
        };
        channel.basicConsume(queueName,true,consumer);
    }
}


```



### 消息消费确认（中 25）

#### 介绍

消费者确认分两种:自动确认和手动确认.

 

在自动确认模式中,消息在发送到消费者后即被认为"成功消费".这种模式可以降低吞吐量（只要消费者可以跟上）,以降低交付和消费者处理的安全性.这种模式通常被称为“即发即忘”.与手动确认模型不同,如果消费者的TCP连接或通道在真正的"成功消费"之前关闭,则服务器发送的消息将丢失.因此,自动消息确认应被视为不安全,并不适用于所有工作负载.

 

使用自动确认模式时需要考虑的另一件事是消费者过载.手动确认模式通常与有界信道预取(BasicQos方法)一起使用,该预取限制了信道上未完成（“进行中”）的消息的数量.但是,自动确认没有这种限制.因此,消费者可能会被消息的发送速度所淹没,可能会导致消息积压并耗尽堆或使操作系统终止其进程.某些客户端库将应用TCP反压(停止从套接字读取,直到未处理的交付积压超过某个限制).因此,仅建议能够以稳定的速度有效处理消息的消费者使用自动确认模式.

 

- 自动确认模式：消费者挂掉，待ack的消息回归到队列中。消费者抛出异常，消息会不断的被重发，直到处理成功。不会丢失消息，即便服务挂掉，没有处理完成的消息会重回队列，但是异常会让消息不断重试。

 

- 手动确认模式：如果消费者来不及处理就死掉时，没有响应ack时会重复发送一条信息给其他消费者；如果监听程序处理异常了，且未对异常进行捕获，会一直重复接收消息，然后一直抛异常；如果对异常进行了捕获，但是没有在finally里ack，也会一直重复发送消息(重试机制)。



#### 1、自动确认

##### 消费者

```java
public class Received {
    public static void main(String[] args) throws IOException, TimeoutException {
        //1.创建连接工厂
        ConnectionFactory factory = new ConnectionFactory();
        //2.设置参数
        factory.setHost("127.0.0.1");
        factory.setPort(5672);
        factory.setUsername("admin");
        factory.setPassword("admin");
        //3.创建连接
        Connection connection = factory.newConnection();
        //4.创建通道
        Channel channel = connection.createChannel();
        //5.创建消息队列
        channel.queueDeclare("test",true,false,false,null);
        //6.该消费者在接收到队列里的消息但没有返回确认结果之前,队列不会将新的消息分发给该消费者
        //队列中没有被消费的消息不会被删除，还是存在于队列中。
        channel.basicQos(1);
        //7.接收处理消息
        Consumer consumer = new DefaultConsumer(channel){
            @Override
            public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException {
                String message = new String(body,"UTF-8");
                System.out.println(message);
                try {
                    Thread.sleep(1000);
                }catch (Exception e){
                    e.printStackTrace();
                }
            }
        };
        //8.消费者确认收到消息
        channel.basicConsume("test",true,consumer);
    }
}

```

##### 生产者

```java
public class Productor {
    public static void main(String[] args) throws IOException, TimeoutException {
        //1.创建连接工厂
        ConnectionFactory factory = new ConnectionFactory();
        //2.设置参数
        factory.setHost("127.0.0.1");
        factory.setPort(5672);
        factory.setUsername("admin");
        factory.setPassword("admin");
        //3.创建连接
        Connection connection = factory.newConnection();
        //4.创建通道
        Channel channel = connection.createChannel();
        //5.创建消息队列
        channel.queueDeclare("test",true,false,false,null);
        //6.发送消息
        for (int i=0;i<10;i++){
            //发送10次
            channel.basicPublish("","test", MessageProperties.PERSISTENT_TEXT_PLAIN,("helloworld"+i).getBytes());
        }
        //7.关闭资源
        channel.close();
        connection.close();
    }
}

```

##### 运行观察rabbitmq控制台

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210721155957.png" alt="image-20210721155957366" style="zoom: 50%;" />

可以看到消费者还没有打印消息，该队列中已经没有任何消息了



#### 2、手动确认

##### 消费者

```java
public class Received {
    public static void main(String[] args) throws IOException, TimeoutException {
        //1.创建连接工厂
        ConnectionFactory factory = new ConnectionFactory();
        //2.设置参数
        factory.setHost("127.0.0.1");
        factory.setPort(5672);
        factory.setUsername("admin");
        factory.setPassword("admin");
        //3.创建连接
        Connection connection = factory.newConnection();
        //4.创建通道
        Channel channel = connection.createChannel();
        //5.创建消息队列
        channel.queueDeclare("test",true,false,false,null);
        //6.该消费者在接收到队列里的消息但没有返回确认结果之前,队列不会将新的消息分发给该消费者
        //队列中没有被消费的消息不会被删除，还是存在于队列中。
        channel.basicQos(1);
        //7.接收处理消息
        Consumer consumer = new DefaultConsumer(channel){
            @Override
            public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException {
                String message = new String(body,"UTF-8");
                System.out.println(message);
                try {
                    Thread.sleep(1000);
                }catch (Exception e){
                    e.printStackTrace();
                }
                finally {
                    //此处增加消息确认确认机制，envelope.getDeliveryTag()获取消息的唯一标识，false表示仅ack当前消息
                    channel.basicAck(envelope.getDeliveryTag(),false);
                }

            }
        };
        //8.消费者确认收到消息
        channel.basicConsume("test",false,consumer);
    }
}

```



##### 生产者同上



运行观察rabbitmq控制台

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210721160040.png" alt="image-20210721160039938" style="zoom: 50%;" />



当消费者收到一条消息,但是还没有肯定确认时,从管理后台可以清晰的看到,队列中一共有6条消息,其中5条尚未推送,1条已经推送但尚未确认.



#### 成功确认

成功确认（2个参数）

void basicAck(long deliveryTag, boolean multiple) throws IOException;

参数：

​	deliveryTag		该消息的index

​	multiple		是否批量		true：将一次性ack所有小于deliveryTag的消息。



#### 否定确认

失败确认（三个参数）

- void basicNack(long deliveryTag, boolean multiple, boolean requeue)throws IOException;

  参数：

  deliveryTag		该消息的index。

  multiple		是否批量		true：将一次性拒绝所有小于deliveryTag的消息。

  requeue			被拒绝的是否重新入队列。

 

- void basicReject(long deliveryTag, boolean requeue) throws IOException;

  参数

  deliveryTag		该消息的index。

  requeue			被拒绝的是否重新入队列。

 

否定确认的场景不多,但有时候某个消费者因为某种原因无法立即处理某条消息时,就需要否定确认了.

否定确认时,需要指定是丢弃掉这条消息,还是让这条消息重新排队,过一会再来,又或者是让这条消息重新排队,并尽快让另一个消费者接收并处理它.



修改上面消费者的代码如下

```java
finally {
    channel.basicNack(envelope.getDeliveryTag(),false,false);
}

```

运行如下：

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210721160502.png" alt="image-20210721160501975" style="zoom:50%;" />

重新排队

```java
finally {
    channel.basicNack(envelope.getDeliveryTag(),false,true);
}

```

运行如下：

 <img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210721160538.png" alt="image-20210721160538797" style="zoom:50%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210721160549.png" alt="image-20210721160549296" style="zoom:50%;" />

可以看到,消费者收到的一直是"helloworld0"这条消息,而管理后台一直显示 9,1,10.这是为什么呢?

 

首先,我们设置的是每次只推送一条消息给消费者,否定确认中我们选择的是重新排队,所以"helloworld0"这条消息被否定确认后,被安排去重新排队了.当消息被重新排队时,如果可能的话,它将被放置在其队列中的原始位置.也就是说"helloworld0"这条消息又被放到了队列头,因为它的原始位置就是队列头.所以结果就变成了消费之一直在消费"helloworld0",并且一直在否定确认.

 

#### 消费者确认模式,预取和吞吐量

确认模式和QoS预取值对消费者吞吐量具有显着影响。通常，增加预取将提高向消费者传递消息的速率。自动确认模式可以产生最佳的交付率。但是，在这两种情况下，已传送但尚未处理的消息的数量也将增加，从而增加了消费者的RAM消耗。

 

应谨慎使用具有无限预取功能的自动确认模式或手动确认模式。在没有确认的情况下消耗大量消息的消费者将导致他们所连接的节点上的内存消耗增长。找到合适的预取值需要不断试验，并且会因工作负载而异。100到300范围内的值通常可提供最佳吞吐量，并且不会面临压倒性消费者的重大风险。

 

预取值1是最保守的。它将显着降低吞吐量，特别是在消费者连接延迟较高的环境中。对于许多应用来说，更高的值是合适的和最佳的。

 

#### 当消费者失败或失去连接时：自动重新排队

使用手动确认时，除了我们主动让消息重新排队外,任何未确认的消息都将在关闭发生传递的信道（或连接）时自动重新排队。这包括客户端的TCP连接丢失，消费者应用程序（进程）故障和通道级协议异常.

 

由于这种行为，消费者必须准备好处理重新发送，否则就要考虑到幂等性。BasicDeliverEventArgs 有一个特殊的布尔属性 : Redelivered，如果该消息是第一次交付，它将被设置为false.否则为 true.

 

修改代码：

```java
System.out.println(message+"-"+envelope.isRedeliver());

```

测试结果：

 <img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210721160640.png" alt="image-20210721160639984" style="zoom:50%;" />

# 定时任务



### 方式一：定时线程池

```java
public class Pool {
	public static void main(String[] args) {
		//创建线程池
		ScheduledExecutorService pool = Executors.newScheduledThreadPool(1);
		//添加任务
		pool.scheduleAtFixedRate(new Runnable() {
			@Override
			public void run() {
				System.out.println("hello - "+new Date());
				
			}
		}, 0, 1, TimeUnit.SECONDS);
	}
}
```



### 方式二：Timer

创建任务类

```java
public class HelloTask extends TimerTask{
	@Override
	public void run() {
		System.out.println("hello - "+ new Date());
	}
}
```

测试类

```java
public class TimerTest {
	public static void main(String[] args) {
		//创建timer
		Timer timer = new Timer();
		//设置任务
		//参数1：任务  
		//参数2：延迟
		//参数3：间隔时间  毫秒
		timer.schedule(new HelloTask(), 0, 1000);
	}
}
```



### 方式三：SpringBoot定时任务

任务类

```java
@Configuration
@EnableScheduling	//开启定时任务
public class TaskTest {
    //指定策略
	@Scheduled(cron="0/5 * * * * ?")
	public void task() {
		System.out.println("定时任务:"+new Date());
	}
}
```

此处为每5秒执行一次



### 方式四：Quartz

Quartz是OpenSymphony开源组织在Job scheduling领域又一个开源项目，完全由Java开发，可以用来执行定时任务，类似于java.util.Timer。但是相较于Timer， Quartz增加了很多功能：

- 持久性作业 - 就是保持调度定时的状态;

- 作业管理 - 对调度作业进行有效的管理;

 

三个基本组成部分：

- 任务：Job

- 触发器：Trigger，包括SimpleTrigger和CronTrigger

- 调度器：Scheduler

 

Job

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210827144651.png" alt="image-20210827144651317" style="zoom:50%;" />

Trigger

实现触发任务去执行的触发器，触发器Trigger最基本的功能是指定Job的执行时间，执行间隔，运行次数等。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210827144703.png" alt="image-20210827144703423" style="zoom:50%;" />



Scheduler

有了Job和Trigger后，怎么样将两者结合起来呢？即怎样指定Trigger去执行指定的Job呢？这时需要一个Schedule，来负责这个功能的实现。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210827144715.png" alt="image-20210827144715207" style="zoom:50%;" />

代码演示：

导入依赖

```xml
<!-- Quartz -->
<dependency>
	<groupId>org.quartz-scheduler</groupId>
	<artifactId>quartz</artifactId>
	<version>2.3.0</version>
</dependency>
```

创建Job

```java
public class HelloJob implements Job{
	@Override
	public void execute(JobExecutionContext arg0) throws JobExecutionException {
		System.out.println("hello - "+new Date());
	}
}
```

测试类

```java
public class HelloScheduler {
	public static void main(String[] args) throws SchedulerException, InterruptedException {
		//1.创建调度器工厂
		SchedulerFactory factory = new StdSchedulerFactory();
		//2.调度器
		Scheduler scheduler = factory.getScheduler();
		//3.创建detail实例，绑定job
		JobDetail detail = JobBuilder.newJob(HelloJob.class).withIdentity("job", "j_group").build();
		//4.创建触发器
		Trigger trigger = TriggerBuilder.newTrigger().withIdentity("t1", "t_group")
				.startNow()//立即开始
				.withSchedule(
						SimpleScheduleBuilder.simpleSchedule()
						.withIntervalInSeconds(1)//每秒
						.repeatForever())//重复
				.build();
		//5.执行任务
		scheduler.scheduleJob(detail, trigger);
		System.out.println("start------------");
		scheduler.start();
		
		TimeUnit.MINUTES.sleep(1);//主线程睡眠一分钟之后执行
		scheduler.shutdown();
		System.out.println("end------------");
	}
}
```

也可以设置开始结束时间

```java
public class HelloScheduler {
	public static void main(String[] args) throws SchedulerException, InterruptedException {
		
		Date startDate = new Date();	//开始时间
		Date endDate = new Date();		//结束时间
		endDate.setTime(startDate.getTime()+5000);//相差5秒  执行5秒
		
		//1.创建调度器工厂
		SchedulerFactory factory = new StdSchedulerFactory();
		//2.调度器
		Scheduler scheduler = factory.getScheduler();
		//3.创建detail实例，绑定job
		JobDetail detail = JobBuilder.newJob(HelloJob.class).withIdentity("job", "j_group").build();
		//4.创建触发器
		Trigger trigger = TriggerBuilder.newTrigger().withIdentity("t1", "t_group")
				.startNow()
				.startAt(startDate)
				.endAt(endDate)
				.withSchedule(
						SimpleScheduleBuilder.simpleSchedule()
						.withIntervalInSeconds(1)//每秒
						.repeatForever())//重复
				.build();
		//5.执行任务
		scheduler.scheduleJob(detail, trigger);
		scheduler.start();
	}
}
```

利用Corntrigger实现复杂定时任务

```java
//2.创建调度器
public class HelloScheduler2 {
	public static void main(String[] args) throws SchedulerException, InterruptedException {
		
		Date startDate = new Date();	//开始时间
		Date endDate = new Date();		//结束时间
		endDate.setTime(startDate.getTime()+5000);//相差5秒  执行5秒
		
		//1.创建调度器工厂
		SchedulerFactory factory = new StdSchedulerFactory();
		//2.调度器
		Scheduler scheduler = factory.getScheduler();
		//3.创建detail实例，绑定job
		JobDetail detail = JobBuilder.newJob(HelloJob.class).withIdentity("job2", "j_group2").build();
		//4.创建触发器
		CronTrigger cronTrigger = TriggerBuilder.newTrigger()
									.withIdentity("t2", "g2")
									.startNow()
									.startAt(startDate)
									.endAt(endDate)
									.withSchedule(CronScheduleBuilder.cronSchedule("* * * * * ?"))
									.build();
		//5.执行
		scheduler.scheduleJob(detail, cronTrigger);
		scheduler.start();
	}
}

```



### CORN在线生成器

https://cron.qqe2.com/



# day08

### 消息发送确认（中 25）

生产者消息确认：confirm、return

消息的确认，是指生产者投递消息后，如果 Broker 收到消息，则会给我们生产者一个应答。生产者进行接收应答，用来确定这条消息是否正常的发送到 Broker ，这种方式也是消息的可靠性投递的核心保障!

#### 流程图

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210729102601.png" alt="image-20210729102601417" style="zoom:50%;" />

为了使用Confirm模式，client会发送confirm.select方法帧。通过是否设置了no-wait属性，来决定Broker端是否会以confirm.select-ok来进行应答。一旦在channel上使用confirm.select方法，channel就将处于Confirm模式。

 

在生产者将信道设置成Confirm模式，一旦信道进入Confirm模式，所有在该信道上面发布的消息都会被指派一个唯一的ID(以confirm.select为基础从1开始计数)，一旦消息被投递到所有匹配的队列之后，Broker就会发送一个确认给生产者（包含消息的唯一ID）,这就使得生产者知道消息已经正确到达目的队列了，如果消息和队列是可持久化的，那么确认消息会将消息写入磁盘之后发出，Broker回传给生产者的确认消息中deliver-tag域包含了确认消息的序列号，此外Broker也可以设置basic.ack的multiple域，表示到这个序列号之前的所有消息都已经得到了处理。

 

Confirm模式最大的好处在于它是异步的，一旦发布一条消息，生产者应用程序就可以在等信道返回确认的同时继续发送下一条消息，当消息最终得到确认之后，生产者应用便可以通过回调方法来处理该确认消息，如果RabbitMQ因为自身内部错误导致消息丢失，就会发送一条basic.nack来代替basic.ack的消息，在这个情形下，basic.nack中各域值的含义与basic.ack中相应各域含义是相同的，同时requeue域的值应该被忽略。通过nack一条或多条消息， Broker表明自身无法对相应消息完成处理，并拒绝为这些消息的处理负责。在这种情况下，client可以选择将消息re-publish。

 

在channel 被设置成Confirm模式之后，所有被publish的后续消息都将被Confirm（即 ack）或者被nack一次。但是没有对消息被Confirm的快慢做任何保证，并且同一条消息不会既被Confirm又被nack。



#### 如何实现Confirm确认消息?

第一步:在 channel 上开启确认模式: channel.confirmSelect()

第二步:在 channel 上添加监听: channel.addConfirmListener(ConfirmListener listener);, 监听成功和失败的返回结果，根据具体的结果对消息进行重新发送、或记录日志等后续处理!



##### 生产者

```java
public class Productor {
    private static final String EXCHANGE_NAME = "confirm_exchange";
    private static final String ROUTING_KEY = "confirm";
    public static void main(String[] args) throws IOException, TimeoutException {
        //1.创建连接工厂
        ConnectionFactory factory = new ConnectionFactory();
        //2.设置参数
        factory.setHost("127.0.0.1");
        factory.setPort(5672);
        factory.setUsername("admin");
        factory.setPassword("admin");
        //3.创建连接
        Connection connection = factory.newConnection();
        //4.创建通道
        Channel channel = connection.createChannel();

        //5.指定消息投递方式为：confirm模式
        channel.confirmSelect();

        //6.添加监听器
        channel.addConfirmListener(new ConfirmListener() {
            //成功回调函数
            //参数1：消息tag
            //参数2：
            @Override
            public void handleAck(long deliveryTag, boolean multiple) throws IOException {
                System.out.println("-----success-----");
                System.out.println(multiple);
            }
            //失败回调函数
            @Override
            public void handleNack(long deliveryTag, boolean multiple) throws IOException {
                System.out.println("======fail======");
                System.out.println(multiple);
            }
        });
        //7.发送消息
        for (int i=0;i<10;i++){
            //发送10次
            channel.basicPublish(EXCHANGE_NAME,ROUTING_KEY, null, ("hello world"+i).getBytes());
        }
        //8.关闭资源
//        channel.close();
//        connection.close();
    }
}
```

<font color='red'>注意：此处不要关闭通道、连接，不然出不来效果</font>



##### 消费者

```java
public class Received {
    private static final String EXCHANGE_NAME = "confirm_exchange";
    private static final String ROUTING_KEY = "confirm";
    private static final String QUEUE_NAME = "confirm_queue";
    public static void main(String[] args) throws IOException, TimeoutException {
        //1.创建连接工厂
        ConnectionFactory factory = new ConnectionFactory();
        //2.设置参数
        factory.setHost("127.0.0.1");
        factory.setPort(5672);
        factory.setUsername("admin");
        factory.setPassword("admin");
        //3.创建连接
        Connection connection = factory.newConnection();
        //4.创建通道
        Channel channel = connection.createChannel();
        //5.创建交换机、消息队列
        channel.exchangeDeclare(EXCHANGE_NAME,"topic");
        //消息队列
        channel.queueDeclare(QUEUE_NAME,true,false,false,null);
        //绑定
        channel.queueBind(QUEUE_NAME,EXCHANGE_NAME,ROUTING_KEY);

        //6.该消费者在接收到队列里的消息但没有返回确认结果之前,队列不会将新的消息分发给该消费者
        //队列中没有被消费的消息不会被删除，还是存在于队列中。
        channel.basicQos(1);
        //7.接收处理消息
        Consumer consumer = new DefaultConsumer(channel){
            @Override
            public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException {
                String message = new String(body,"UTF-8");
                System.out.println(message+"-"+envelope.isRedeliver());
                try {
                    Thread.sleep(1000);
                }catch (Exception e){
                    e.printStackTrace();
                }
            }
        };
        //8.消费者确认收到消息
        channel.basicConsume(QUEUE_NAME,true,consumer);
    }
}

```

运行测试

<font color='red'>注意：如果出不了预期效果，多运行几次生产者试试</font>

<font color='red'>此处采用的是异步 confirm 模式：提供一个回调方法，服务端 confirm 了一条或者多条消息后 Client 端会回调这个方法。除此之外还有单条同步 confirm 模式、批量同步 confirm 模式，由于现实场景中很少使用我们在此不做介绍，如有兴趣直接参考官方文档。</font>

<font color='red'>我们运行生产端会发现每次运行结果都不一样,会有多种情况出现，因为 Broker 会进行优化，有时会批量一次性 confirm ，有时会分开几条 confirm。</font>



#### return确认机制

- Return Listener 用于处理一些不可路由的消息!

- 消息生产者，通过指定一个 Exchange 和 Routingkey，把消息送达到某一个队列中去，然后我们的消费者监听队列，进行消费处理操作!

- 但是在某些情况下，如果我们在发送消息的时候，当前的 exchange 不存在或者指定的路由 key 路由不到，这个时候如果我们需要监听这种不可达的消息，就要使用 Return Listener !

- 在基础API中有一个关键的配置项:Mandatory：如果为 true，则监听器会接收到路由不可达的消息，然后进行后续处理，如果为 false，那么 broker 端自动删除该消息!

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210729103000.png" alt="image-20210729103000052" style="zoom:50%;" />

#### 案例：

- 首先我们需要发送多条消息，并且故意将第 0 条消息的 routing Key设置为错误的，让他无法正常路由到消费端。
- 添加监听即可监听到不可路由到消费端的消息channel.addReturnListener(ReturnListener r))
- mandatory 设置为 true，表示交换器无法根据交换机的类型或路由键找到一个符合条件的队列，那么RabbitMq会调用Basic.Ruturn命令将消息返回给生产者，为false时，出现上述情况消息被直接丢弃。即channel.basicPublish(exchangeName, errRoutingKey, <font color='red'>**true**</font>,null, msg.getBytes());

##### 生产者

```java
public class Productor {
    private static final String EXCHANGE_NAME = "return_confirm_exchange";
    private static final String ROUTING_KEY = "return_confirm";
    private static final String ERROR_ROUTING_KEY = "error_return_confirm";

    public static void main(String[] args) throws IOException, TimeoutException {
        //1.创建连接工厂
        ConnectionFactory factory = new ConnectionFactory();
        //2.设置参数
        factory.setHost("127.0.0.1");
        factory.setPort(5672);
        factory.setUsername("admin");
        factory.setPassword("admin");
        //3.创建连接
        Connection connection = factory.newConnection();
        //4.创建通道
        Channel channel = connection.createChannel();

        //5.添加return监听
        channel.addReturnListener(new ReturnListener() {
            @Override
            public void handleReturn(int replyCode, String replyText, String exchange, String routingKey, AMQP.BasicProperties properties, byte[] body) throws IOException {
                System.out.println(replyCode);
                System.out.println(replyText);
                System.out.println(exchange);
                System.out.println(routingKey);
                System.out.println(properties);
                System.out.println(new String(body));
            }
        });

        //6.发送消息
        for (int i=0;i<10;i++){
            //发送10次
            if (i==0){
                //第一条错误
                channel.basicPublish(EXCHANGE_NAME,ERROR_ROUTING_KEY, true, null,
 ("helloworld"+i).getBytes());
            }else {
                //正确
                channel.basicPublish(EXCHANGE_NAME,ROUTING_KEY, true, null, 
("helloworld"+i).getBytes());
            }
        }
        //7.关闭资源
//        channel.close();
//        connection.close();
    }
}
```

##### 消费者

同confirm机制的代码



### SpringBoot整合RabbitMQ开发（高 45）

#### 导入依赖

```xml
<!-- rabbid mq -->
<dependency>
	<groupId>org.springframework.boot</groupId>
	<artifactId>spring-boot-starter-amqp</artifactId>
</dependency>
<!-- rabbit test -->
<dependency>
	<groupId>org.springframework.amqp</groupId> 
	<artifactId>spring-rabbit-test</artifactId>
	<scope>test</scope>
</dependency>
<!-- lombok -->
<dependency>
	<groupId>org.projectlombok</groupId>
	<artifactId>lombok</artifactId>
	<optional>true</optional>
</dependency>
<!-- 热部署 -->
<dependency>
	<groupId>org.springframework.boot</groupId>
	<artifactId>spring-boot-devtools</artifactId>
	<optional>true</optional>
	<scope>true</scope>
</dependency>
```

#### 编辑application.yml文件

```yaml
spring:
  rabbitmq:
    host: 192.168.41.226
    port: 5672    # java程序访问时用到的端口
    username: admin   #账号
    password: admin   #密码
    virtual-host: /test    #虚拟主机
    publisher-confirm-type: correlated   #开启RabbitMQ的生产者确认模式
    publisher-returns: true    #返回确认消息
    template:
      mandatory: true  #启用强制信息，必须确认，消息无法达到队列时将消息返回给生产者，否则丢弃消息
```

#### 编写配置类

```java
package com.woniuxy.main.configuration;

import org.springframework.amqp.core.Queue;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class RabbitConfiguration {
	@Bean
	public Queue helloQueue() {
		return new Queue("hello");  //队列名
	}
}
```



#### 直接模式

直接向消息队列发送消息，包括simple、work模式

#### 生产者

在direct包中创建SingletonHello类发送消息，在SpringBoot中直接使用AmqpTemplate去发送消息，代码如下:

```java
package com.woniuxy.main.direct;

import org.springframework.amqp.core.AmqpTemplate;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

@Component
public class SingletonHello {
    
    @Autowired
    private AmqpTemplate amqpTemplate;
    
    public void send() {
        String sendMsg = "hello rabbit";
        System.out.println("sender :" + sendMsg);
        amqpTemplate.convertAndSend("hello", sendMsg);
    }
}
```

##### 消费者

在direct文件夹中创建SingletonHelloReceiver类来接受消息，代码如下所示：

```java
package com.woniuxy.main.direct;

import org.springframework.amqp.rabbit.annotation.RabbitHandler;
import org.springframework.amqp.rabbit.annotation.RabbitListener;
import org.springframework.stereotype.Component;

@Component
@RabbitListener(queues =  "hello")
public class SingletonHelloReceiver {
    
    @RabbitHandler
    public void receiver(String hello) {
        System.out.println("SingletonHelloReceiver" + hello);
    }
}
```

##### 测试类

验证测试代码，在controller文件夹中创建RabbitTestController类来测试

```java
package com.woniuxy.main.handler;

import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Controller;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestMapping;

import com.woniuxy.main.direct.SingletonHello;

@Controller
@RequestMapping("/rabbit")
public class RabbitTestHandler {
	@Autowired
    private SingletonHello singletonHello;
     
    @GetMapping("/hello")
    public void hello () {
        singletonHello.send();
    }
}

```

##### 测试

运行程序在浏览器地址栏中输入：http://localhost:8080/rabbit/hello 验证，如果在控制台上输出以下信息表示成功

```
sender :hello rabbit
SingletonHelloReceiver:hello rabbit

```

#### 分类

- 一对一：一个生产者一个消费者

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210729103559.png" alt="image-20210729103559413" style="zoom:50%;" />

- 一对多：一个生产者多个消费者

  再新建一个消费者，同样监听

  注意：当其中一个消费获取到数据之后，消息队列会将对应的消息删除，其他消费者就无法获取到该消息

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210729103658.png" alt="image-20210729103658713" style="zoom:50%;" />

- 多对多：多个生产者多个消费者

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210729103647.png" alt="image-20210729103647507" style="zoom:50%;" />

#### Fanout模式（分发模式）

- 任何发送到Fanout Exchange上的消息都会转发到与Exchange绑定（binding）的queue上。

- 可以理解为路由表的模式

- 这种模式需要提前将Exchange与Queue进行绑定，一个Exchange可以绑定多个Queue，一个Queue可以同多个Exchange进行绑定。

- 如果接受到消息的Exchange没有与任何Queue绑定，则消息会被抛弃。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210729103739.png" alt="image-20210729103739683" style="zoom:50%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210729103750.png" alt="image-20210729103749931" style="zoom:50%;" />

##### 配置类

在RabbitConfiguration配置类中添加如下配置

```java
/*
 * fanout 模式
 */
@Bean
public Queue fanoutMessageA() {
    return new Queue("fanout.A");
}

@Bean
public Queue fanoutMessageB() {
    return new Queue("fanout.B");
}

@Bean
public Queue fanoutMessageC() {
    return new Queue("fanout.C");
}

@Bean
public FanoutExchange fanoutExchange() {
    return new FanoutExchange("fanoutExchange");
}
@Bean
public Binding bindingExchangeA(Queue fanoutMessageA,FanoutExchange fanoutExchange) {
    return BindingBuilder.bind(fanoutMessageA).to(fanoutExchange);
}

@Bean
public Binding bindingExchangeB(Queue fanoutMessageB,FanoutExchange fanoutExchange) {
    return BindingBuilder.bind(fanoutMessageB).to(fanoutExchange);
}

@Bean
public Binding bindingExchangeC(Queue fanoutMessageC,FanoutExchange fanoutExchange) {
    return BindingBuilder.bind(fanoutMessageC).to(fanoutExchange);
}

```

##### 生产者

创建一个fanout的包，在包下创建一个生产者和三个消费者

生产者负责向fanout的交换机发送消息，消费者分别负责监听对应的队列，从队列中取出数据编写FanoutSender类，负责发送消息

```java
package com.woniuxy.main.fanout;

import org.springframework.amqp.core.AmqpTemplate;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

import lombok.Data;

@Data
@Component
public class FanoutSender {
	@Autowired
	private AmqpTemplate amqpTemplate;
	
	//发送消息的方法
	public void send() {
		String message = "fanout message";
		amqpTemplate.convertAndSend("fanoutExchange","",message);//发送消息
	}
}

```

##### 消费者

编写FanoutReceiveA、B、C三个消费者类，代码基本一致

```java
package com.woniuxy.main.fanout;

import org.springframework.amqp.rabbit.annotation.RabbitHandler;
import org.springframework.amqp.rabbit.annotation.RabbitListener;
import org.springframework.stereotype.Component;

@Component
@RabbitListener(queues = "fanout.A")
public class FanoutReceiveA {
	@RabbitHandler
	public void receive(String message) {
		System.out.println("A:"+message);
	}
}

```

##### 测试类

修改RabbitTestController

```java
@Data
@Controller
@RequestMapping("/rabbit")
public class RabbitTestHandler {
	@Autowired
    private SingletonHello singletonHello;        
	@Autowired
	private FanoutSender fanoutSender;
	
	
    @GetMapping("/hello")
    public void hello () {
        singletonHello.send();
    }
    //fanout模式    
    @GetMapping("/fanout")
    public void fanout() {
		fanoutSender.send();
	}  
}

```

##### 测试

发送请求测试，控制台输入以下结果表示成功!

```
A:fanout message
B:fanout message
C:fanout message

```



#### Direct（路由模式）

直接交换机	默认

任何发送到Direct Exchange 上的消息都会转发到RouteKey指定的queue中。

- 一般使用RabbitMp自带的Exchange。

- 这种模式不需要对Exhange进行任何绑定（binding）操作。

- 消息传递时只需要一个简单的RouteKey，可理解为接收消息队列的名字，如RabbitApplication启动类中的“direct”，代码如下所示。

- 如果vhost中不存在RouteKey中指定的队列名，则该消息会被抛弃。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210729104111.png" alt="image-20210729104111293" style="zoom:50%;" />

#### 配置类

创建消息队列、交换机并绑定

```java
@Configuration
public class RabbitConfiguration {
    @Bean
    public Queue newsQueue() {
        return new Queue("news_queue");  //队列名
    }

    @Bean
    public Queue weatherQueue(){
        return new Queue("weather_queue");
    }

    @Bean
    public DirectExchange directExchange(){
        return new DirectExchange("direct_exchange");
    }

    @Bean
    public Binding bindingNewsQueueAndExchange(DirectExchange directExchange,Queue newsQueue){
        return BindingBuilder.bind(newsQueue).to(directExchange).with("news");
    }

    @Bean
    public Binding bindingWeatherQueueAndExchange(DirectExchange directExchange,Queue weatherQueue){
        return BindingBuilder.bind(weatherQueue).to(directExchange).with("weather");
    }
}

```

##### 生产者

创建消息发送者

```java
@Component
public class DirectSender {
    @Autowired
    private RabbitTemplate rabbitTemplate;

    public void send(){
        rabbitTemplate.convertAndSend("direct_exchange","news","新闻");
        rabbitTemplate.convertAndSend("direct_exchange","weather","天气");
    }
}

```

##### 消费者

创建两个消费者，分别监听不同的队列

```java
@Component
public class NewsComsumer {
    @RabbitListener(queues = "news_queue")
    public void received(String msg){
        System.out.println("news："+msg);
    }
}

```

```java
@Component
public class WeatherComsumer {
    @RabbitListener(queues = "weather_queue")
    public void received(String msg){
        System.out.println("weather："+msg);
    }
}

```

##### 测试类

```java
@RestController
@RequestMapping("/direct")
public class DirectController {
    @Autowired
    private DirectSender directSender;

    @RequestMapping("/send")
    public String send(){
        directSender.send();
        return "success";
    }
}

```

##### 测试

启动程序，发送请求



#### Topic（主题模式）

- 任何发送到Topic Exchange的消息都会被转发到RouteKey中匹配到的Queue上。

- 所有的队列（queue）都有一个标签，所有的消息也都带有一个标签（RouteKey），Exchange会将消息转发到与它相匹配的队列（queue）中，这里的匹配是模糊匹配。

- 这种模式需要RouteKey，且需要提前绑定Exchange和Queue。

- 如果Exchange没有发现能够与RouteKey匹配的Queue，则会抛弃此消息。

- “#”表示0个或若干个关键字，“*”表示一个关键字。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210729104324.png" alt="image-20210729104324459" style="zoom:50%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210729104332.png" alt="image-20210729104332332" style="zoom:50%;" />

##### 配置类

在RabbitConfiguration.java  配置topic的队列和交换机

```java
package com.woniuxy.main.configuration;

import org.springframework.amqp.core.Queue;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class RabbitConfiguration {
	@Bean
	public Queue helloQueue() {
		return new Queue("hello");		//队列名
	}
	@Bean
	public Queue userQueue() {
		return new Queue("entity");
	}
	/*
	 * 以下是验证topic Exchange的队列
	 */
	//@Bean(name="queue.A")
    @Bean
    public Queue topicMessageA() {
        return new Queue("topic.A");
    }
    
    //@Bean(name="queue.B")
    @Bean
    public Queue topicMessageB() {
        return new Queue("topic.B");
    }
    
	//@Bean(name="queue.C")
    @Bean
    public Queue topicMessageC() {
        return new Queue("topic.C");
    }
    
    //topic的交换机
    @Bean
    TopicExchange exchange() {
        return new TopicExchange("topic:exchange");
    }
    
    //绑定队列和交换机，建立交换机与队列的联系
    @Bean
    Binding bindingMessageA(Queue topicMessage,TopicExchange exchange) {	//@Qualifier("queue.A") 
        return BindingBuilder.bind(topicMessage).
to(exchange).with("message-key.mark");//with绑定规则，消息的key，主题
    }
    @Bean
    Binding bindingMessageB(Queue topicMessage,TopicExchange exchange) {	//@Qualifier("queue.B") 
    	return BindingBuilder.bind(topicMessage).
to(exchange).with("message-key.#");	//*表示一个词,#表示零个或多个词
    }
    @Bean
    Binding bindingMessageC(Queue topicMessage,TopicExchange exchange) {	//@Qualifier("queue.C") 
    	return BindingBuilder.bind(topicMessage).
to(exchange).with("message-key.#");
    }
}

```

##### 生产者

创建一个topic的包，在包下创建一个生产者和三个消费者

生产者负责向topic的交换机发送消息，消费者分别负责监听对应的队列，从队列中取出数据

```java
package com.woniuxy.main.topic;

import org.springframework.amqp.core.AmqpTemplate;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

import lombok.Data;

@Data
@Component
public class Producer {
	@Autowired
	private AmqpTemplate amqpTemplate;
	
	public void send(){
		String message = "来自生产者的消息";
		//参数1：交换机的名字
		//参数2：消息的key
		//参数3：消息
		amqpTemplate.convertAndSend("topic:exchange","message-key.mark", message);
	}
}

```

##### 消费者

ConsumerA、B、C的代码基本一致，就只用更换一下queues的值

```java
package com.woniuxy.main.topic;

import org.springframework.amqp.rabbit.annotation.RabbitHandler;
import org.springframework.amqp.rabbit.annotation.RabbitListener;
import org.springframework.stereotype.Component;

@Component
@RabbitListener(queues = "topic.A")
public class ConsumerA {
	@RabbitHandler
	public void receive(String message){
		System.out.println("topic.A接收到:"+message);
	}
}

```

##### 测试类

```java
package com.woniuxy.main.handler;

import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Controller;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestMapping;

import com.woniuxy.main.direct.SingletonHello;
import com.woniuxy.main.topic.Producer;

import lombok.Data;

@Data
@Controller
@RequestMapping("/rabbit")
public class RabbitTestHandler {
	@Autowired
	private Producer producer;	//topic的生产者
    @GetMapping("/topic")
    public void topic() {
		producer.send();    //调用消费者方法，发送数据
	}
}

```



### 延迟队列简介及使用（高 30）

#### 什么是延迟队列

延迟队列，首先，它是一种队列，队列意味着内部的元素是有序的，元素出队和入队是有方向性的，元素从一端进入，从另一端取出。

其次，延迟队列，最重要的特性就体现在它的延迟属性上，跟普通的队列不一样的是，普通队列中的元素总是等着希望被早点取出处理，而延迟队列中的元素则是希望被在指定时间得到取出和处理，所以延迟队列中的元素是都是带时间属性的，通常来说是需要被处理的消息或者任务。

简单来说，延迟队列就是用来存放需要在指定时间被处理的元素的队列。



#### 使用场景：

- 订单在十分钟之内未支付则自动取消。

- 新创建的店铺，如果在十天内都没有上传过商品，则自动发送消息提醒。

- 账单在一周内未支付，则自动结算。

- 用户注册成功后，如果三天内没有登陆则进行短信提醒。

- 用户发起退款，如果三天内没有得到处理则通知相关运营人员。

- 预定会议后，需要在预定的时间点前十分钟通知各个与会人员参加会议。

 

这些场景都有一个特点，需要在某个事件发生之后或者之前的指定时间点完成某一项任务，如：发生订单生成事件，在十分钟之后检查该订单支付状态，然后将未支付的订单进行关闭；发生店铺创建事件，十天后检查该店铺上新商品数，然后通知上新数为0的商户；发生账单生成事件，检查账单支付状态，然后自动结算未支付的账单；发生新用户注册事件，三天后检查新注册用户的活动数据，然后通知没有任何活动记录的用户；发生退款事件，在三天之后检查该订单是否已被处理，如仍未被处理，则发送消息给相关运营人员；发生预定会议事件，判断离会议开始是否只有十分钟了，如果是，则通知各个与会人员。

 

看起来似乎使用定时任务，一直轮询数据，每秒查一次，取出需要被处理的数据，然后处理不就完事了吗？如果数据量比较少，确实可以这样做，比如：对于“如果账单一周内未支付则进行自动结算”这样的需求，如果对于时间不是严格限制，而是宽松意义上的一周，那么每天晚上跑个定时任务检查一下所有未支付的账单，确实也是一个可行的方案。但对于数据量比较大，并且时效性较强的场景，如：“订单十分钟内未支付则关闭“，短期内未支付的订单数据可能会有很多，活动期间甚至会达到百万甚至千万级别，对这么庞大的数据量仍旧使用轮询的方式显然是不可取的，很可能在一秒内无法完成所有订单的检查，同时会给数据库带来很大压力，无法满足业务要求而且性能低下。

 

#### TTL

在介绍延迟队列之前，还需要先介绍一下RabbitMQ中的一个高级特性——TTL（Time To Live）。

TTL是什么呢？TTL是RabbitMQ中一个消息或者队列的属性，表明一条消息或者该队列中的所有消息的最大存活时间，单位是毫秒。换句话说，如果一条消息设置了TTL属性或者进入了设置TTL属性的队列，那么这条消息如果在TTL设置的时间内没有被消费，则会成为“死信”。如果同时配置了队列的TTL和消息的TTL，那么较小的那个值将会被使用。

从下图可以大致看出消息的流向：

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210729104615.png" alt="image-20210729104615080" style="zoom:50%;" />

生产者生产一条延迟消息，根据需要延迟时间的不同，利用不同的routingkey将消息路由到不同的延迟队列，每个队列都设置了不同的TTL属性，并绑定在同一个死信交换机中，消息过期后，根据routingkey的不同，又会被路由到不同的死信队列中，消费者只需要监听对应的死信队列进行处理即可。



#### 死信

死信，在官网中对应的单词为“Dead Letter”，可以看出翻译确实非常的简单粗暴。那么死信是个什么东西呢？

“死信”是RabbitMQ中的一种消息机制，当你在消费消息时，如果队列里的消息出现以下情况：

- 消息被否定确认，使用 channel.basicNack 或 channel.basicReject ，并且此时requeue 属性被设置为false。

- 消息在队列的存活时间超过设置的TTL(消息过期)时间。

- 消息队列的消息数量已经超过最大队列长度。

 那么该消息将成为“死信”。

 

"死信”消息会被RabbitMQ进行特殊处理，如果配置了死信队列信息，那么该消息将会被丢进死信队列中，如果没有配置，则该消息将会被丢弃。



#### 代码实现

##### 配置类

创建queue、exchange并进行绑定

```java
@Configuration
public class RabbitConfiguration3 {
	//延迟交换机
	@Bean
	public DirectExchange delayExchange() {
		return new DirectExchange("delay_exchange");
	}
	
	//死信交换机
	@Bean
	public DirectExchange deadExchange() {
		return new DirectExchange("dead_exchange");
	}
	
	//延迟队列，指定TTL时间，并绑定到死信交换机
	@Bean
	public Queue delayQueue() {
		Map<String, Object> map = new HashMap<>();
        // x-dead-letter-exchange    这里声明当前队列绑定的死信交换机
		map.put("x-dead-letter-exchange", "dead_exchange");
        // x-dead-letter-routing-key  这里声明当前队列的死信路由key
		map.put("x-dead-letter-routing-key", "dead_key");
        // x-message-ttl  声明队列的TTL	3秒
		map.put("x-message-ttl", 3000);
		
		return new Queue("delay_queue",true,false,false,map);
	}
	
	//死信队列A，处理延迟队列A的消息
	@Bean
	public Queue deadQueue() {
		return new Queue("dead_queue");
	}

	//绑定
	//延迟队列A绑定延迟交换机
	@Bean
	public Binding bindingDelayQueueAndDelayExchange(DirectExchange delayExchange,Queue delayQueue) {
		return BindingBuilder.bind(delayQueue).to(delayExchange).with("delay_key");
	}
	
	//绑定死信队列和死信交换机
	@Bean
	public Binding bindingDeadQueueAndDeadExchange(DirectExchange deadExchange,Queue deadQueue) {
		return BindingBuilder.bind(deadQueue).to(deadExchange).with("dead_key");
	}
}

```

##### 生产者

```java
@Component
public class BusinessSender {
	@Autowired
	private RabbitTemplate rabbitTemplate;
	
	public void send(String msg) {
		System.out.println("发送者发送消息："+ new Date());
		rabbitTemplate.convertAndSend("delay_exchange","delay_key",msg);
	}
}

```

##### 业务消费者

```java
@Component
public class BusinessComsumer {

	@RabbitListener(queues="delay_queue")
	public void received(Message message,Channel channel) {
		System.out.println("消费者接收数据时间:"+new Date());
		System.out.println("接收到:"+new String(message.getBody()));
	}
}

```

##### 创建死信消费者

```java
@Component
public class DeadComsumer {

	@RabbitListener(queues="dead_queue")
	public void received(String msg) {
		System.out.println("死信队列接收消息："+new Date());
		System.out.println("接收到："+msg);
	}
}

```

##### 创建业务controller

```java
@RestController
public class BusinessController {
	@Autowired
	private BusinessSender sender;
	
	@RequestMapping("/dead")
	public String dead() {
		sender.send("hello");
		return "success";
	}
}

```

##### 测试

启动项目测试

```
发送者发送消息：Tue Jun 23 10:11:55 CST 2020
消费者接收数据时间:Tue Jun 23 10:11:55 CST 2020
接收到:hello

```

可以看到业务消费者可以正常消费消息，所以死信消费者不会接收到任何消息，只有当TTL到了并且消息无法被业务消费者消费时，死信消费者才会接收到消息

 

将业务消费者中监听队列的注解注释掉，启动程序再次进行测试

```java
@Component
public class BusinessComsumer {
	//@RabbitListener(queues="delay_queue")
	public void received(Message message,Channel channel) {
		System.out.println("消费者接收数据时间:"+new Date());
		System.out.println("接收到:"+new String(message.getBody()));
	}
}

```

运行结果

```
发送者发送消息：Tue Jun 23 10:14:26 CST 2020
死信队列接收消息：Tue Jun 23 10:14:29 CST 2020
接收到：hello

```

死信消费者受到消息，表明延迟队列功能实现

 

但是此种方式存在很大的弊端：

- 死信队列TTL固定，如果项目中存在多个过期时间，那么就需要创建多个队列，扩展性低，很不灵活

- 无法给每一条消息指定不同的过期时间



### 延迟插件（高 30）

#### 下载

下载地址：https://www.rabbitmq.com/community-plugins.html

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210729105815.png" alt="image-20210729105815027" style="zoom:50%;" />

下载rabbitmq_delayed_message_exchange插件

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210729105832.png" alt="image-20210729105832475" style="zoom:50%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210729105840.png" alt="image-20210729105839928" style="zoom:50%;" />

#### 安装

1、然后解压放置到RabbitMQ的插件目录。/usr/lib/rabbitmq/lib/rabbitmq_server-3.7.0/plugins

 

2、接下来，进入RabbitMQ的安装目录下的sbin目录，/usr/lib/rabbitmq/lib/rabbitmq_server-3.7.0/sbin

执行下面命令让该插件生效

​	rabbitmq-plugins enable rabbitmq_delayed_message_exchange

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210729105937.png" alt="image-20210729105937762" style="zoom:50%;" />

3、然后重启RabbitMQ

​	sudo service rabbitmq-server restart



#### 代码实现

##### 配置类

创建延迟queue、exchange并进行绑定

```java
package com.woniuxy.configuration;

import java.util.HashMap;
import java.util.Map;

import org.springframework.amqp.core.Binding;
import org.springframework.amqp.core.BindingBuilder;
import org.springframework.amqp.core.CustomExchange;
import org.springframework.amqp.core.Queue;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;


@Configuration
public class RabbitConfiguration2 {
	
	@Bean
	public Queue delayQueue() {
		return new Queue("delay_queue");
	}
	
	@Bean
	public CustomExchange customExchange() {
		Map<String, Object> args = new HashMap<>();
        args.put("x-delayed-type", "direct");
        return new CustomExchange("delay_exchange", "x-delayed-message", true, false, args);
	}
	
	@Bean
	public Binding bindingDelayQueueAndExchange(CustomExchange customExchange,Queue delayQueue) {
		return 
BindingBuilder.bind(delayQueue).to(customExchange).with("delay_key").noargs();
	}
}

```

##### 生产者

```java
package com.woniuxy.delay;

import java.util.Date;

import org.springframework.amqp.AmqpException;
import org.springframework.amqp.core.Message;
import org.springframework.amqp.core.MessagePostProcessor;
import org.springframework.amqp.rabbit.core.RabbitTemplate;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;


@Component
public class DelaySender {
	@Autowired
	private RabbitTemplate rabbitTemplate;
	
	public void send(String msg,int delayTime) {
		System.out.println("生产者发送消息时间："+new Date());
		rabbitTemplate.convertAndSend("delay_exchange","delay_key",new Date().toString(),new MessagePostProcessor() {//消息后置处理
			@Override
			public Message postProcessMessage(Message message) throws AmqpException {
				//设置TTL
				message.getMessageProperties().setDelay(delayTime);
				return message;
			}
		});
	}
}

```

##### 消费者

```java
package com.woniuxy.comsumer;

import java.util.Date;

import org.springframework.amqp.core.Message;
import org.springframework.amqp.rabbit.annotation.RabbitListener;
import org.springframework.stereotype.Component;

import com.rabbitmq.client.Channel;

@Component
public class DelayComsumer {

	@RabbitListener(queues="delay_queue")
	public void received(Message message,Channel channel) {
		System.out.println("消费者接收数据时间:"+new Date());
		System.out.println("接收到:"+new String(message.getBody()));
	}
}

```

##### 测试

运行程序，发送请求测试

​	localhost:8080/delay?msg=hello&delayTime=2000

 观察控制台数据，如果显示的数据如下所示，表示成功

```
生产者发送消息时间：Mon Jun 22 21:31:10 CST 2020
消费者接收数据时间：Mon Jun 22 21:31:12 CST 2020

```









 rpm -e --nodeps  java-1.8.0-openjdk-headless-1.8.0.262.b10-1.el7.x86_64

rpm -e --nodeps  java-1.8.0-openjdk-1.8.0.262.b10-1.el7.x86_64



# day09

### RabbitMQ实现削峰限流（高 30）

#### 案例

##### 秒杀业务

上游发起下单操作

下游完成秒杀业务逻辑（库存检查，库存冻结，余额检查，余额冻结，订单生成，余额扣减，库存扣减，生成流水，余额解冻，库存解冻）

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210729110257.png" alt="image-20210729110257537" style="zoom:50%;" />

上游下单业务简单，每秒发起了10000个请求，下游秒杀业务复杂，每秒只能处理2000个请求，很有可能上游不限速的下单，导致下游系统被压垮，引发雪崩。

为了避免雪崩，常见的优化方案有两种：

- 业务上游队列缓冲，限速发送

- 业务下游队列缓冲，限速执行

 通过设置队列长度实现消峰限流：在创建队列时指定队列长度，并指定队列消息溢出后处理方式

 

#### 常见概念

高并发		在短时间内接收到大量请求，可能对数据库进行大量的读写操作，这样就可能会对服务器造成巨大的压力，甚至导致雪崩。

响应时间	服务器从接到请求到完成处理请求的时间

吞吐量		单位时间内接收处理请求的数量

QPS			每秒查询率，每秒响应请求的数量

并发数		同时能够承载正常使用当前系统的用户数量

 

#### 秒杀系统中存在的问题：

库存：大量请求进来时怎么解决库存不能出现负数的问题

订单：不是所有人点击购买都能创建订单

消峰：不能因为并发过大导致系统雪崩

 

#### 实现思路

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210729110459.png" alt="image-20210729110459550" style="zoom:50%;" />

 #### 代码实现

##### application.yml配置

```yaml
spring:
  rabbitmq:
    host: 192.168.74.146
    port: 5672    # java程序访问时用到的端口
    username: admin
    password: admin
    virtual-host: /test    #虚拟机
    publisher-confirm-type: correlated   #开启RabbitMQ的生产者确认模式
    publisher-returns: true    #返回确认消息
    template:
      mandatory: true  #启用强制信息，必须确认，消息无法达到队列时将消息返回给生产者，否则丢弃消息
    listener:
      simple:
        acknowledge-mode: manual  #手动确认
        prefetch: 1 #预取值为1
```

##### rabbitmq配置类

```java
package com.woniuxy.rabbitteach.configuration;

import org.springframework.amqp.core.Binding;
import org.springframework.amqp.core.BindingBuilder;
import org.springframework.amqp.core.Queue;
import org.springframework.amqp.core.TopicExchange;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

import java.util.HashMap;
import java.util.Map;

@Configuration
public class RabbitConfiguration {
    @Bean
    public Queue killQueue() {
        Map<String, Object> map = new HashMap<>();
        //指定队列长度
        map.put("x-max-length", 10);
        //设置队列中的消息溢出后,该队列的行为:"拒绝接收"(所有消息),则最近发布的消息将被丢弃
        //可选值：drop-head  删除队列头，变成死信;reject-publish，拒绝接收
        map.put("x-overflow", "drop-head");

        //绑定死信交换机
        map.put("x-dead-letter-exchange","dead_exchange");
        //绑定死信路由
        map.put("x-dead-letter-routing-key","dead");

        //参数1：队列名
        //参数2：是否为持久队列，服务器重启之后依旧存在
        //参数3：是否为排他队列  只有自己可见的队列，即不允许其它用户访问
        //参数4：是否在不使用时删除
        //参数5：设置队列的初始化参数
        return new Queue("killQueue", false, false, false, map);
    }
    //业务交换机
    @Bean
    public TopicExchange killExchange(){
        return new TopicExchange("kill_exchange");
    }

    //业务路由
    @Bean
    public Binding bindingPeackQueueAndExchange(Queue killQueue, TopicExchange killExchange){
        return BindingBuilder.bind(killQueue).to(killExchange).with("kill");
    }

    //死信队列
    @Bean
    public Queue deadQueue(){
        return new Queue("dead_queue");
    }
    //死信交换机
    @Bean
    public TopicExchange deadExchange(){
        return new TopicExchange("dead_exchange");
    }
    //死信路由
    @Bean
    public Binding bindingDeadExchangeAndQueue(Queue deadQueue,TopicExchange deadExchange){
        return BindingBuilder.bind(deadQueue).to(deadExchange).with("dead");
    }
}
```

##### 生产者

```java
package com.woniuxy.rabbitteach.limit;

import org.springframework.amqp.rabbit.core.RabbitTemplate;
import org.springframework.stereotype.Component;

import javax.annotation.Resource;

@Component
public class KillSender {
    @Resource
    private RabbitTemplate rabbitTemplate;

    public void send(String message) {
        //发送请求
        rabbitTemplate.convertAndSend("kill_exchange", "kill", message);
    }
}
```

#### 消费者

```java
package com.woniuxy.rabbitteach.limit;

import com.rabbitmq.client.Channel;
import org.springframework.amqp.core.Message;
import org.springframework.amqp.rabbit.annotation.RabbitListener;
import org.springframework.stereotype.Component;

@Component
public class KillRecevier {
    @RabbitListener(queues="killQueue")
    public void recevie(Message message, Channel channel) throws Exception {
        //得到消息
        System.out.println("接收到:" + message.getMessageProperties().getDeliveryTag());

        //模拟后台处理业务消耗时间
        Thread.sleep(1000);

        //业务完成手动确认
        channel.basicAck(message.getMessageProperties().getDeliveryTag(),false);
    }
}
```

##### 死信消费者

```java
package com.woniuxy.rabbitteach.limit;

import com.rabbitmq.client.Channel;
import org.springframework.amqp.core.Message;
import org.springframework.amqp.rabbit.annotation.RabbitListener;
import org.springframework.stereotype.Component;

@Component
public class DeadRecevier {
    @RabbitListener(queues = "dead_queue")
    public void received(Message message, Channel channel)throws Exception{
        //获取失败的消息
        System.out.println("秒杀失败:"+message.getMessageProperties().getDeliveryTag());
        //手动确认
        channel.basicAck(message.getMessageProperties().getDeliveryTag(),false);
        //将结果告诉浏览器 websocket
    }
}
```

##### controller

```java
package com.woniuxy.rabbitteach.controller;

import com.woniuxy.rabbitteach.limit.KillSender;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;
import javax.annotation.Resource;

@RestController
public class KillController {
    @Resource
    private KillSender peakSender;

    @RequestMapping("/kill")
    public void kill(){
        peakSender.send("用户账号");
    }
}
```

##### 测试

使用jemiter向controller发送请求

### WebSocket

WebSocket 是 HTML5 开始提供的一种在单个 TCP 连接上进行全双工通讯的协议，可以在html页面直接使用。

WebSocket 使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。在 WebSocket API 中，浏览器和服务器只需要完成一次握手，两者之间就直接可以创建持久性的连接，并进行双向数据传输。

在 WebSocket API 中，浏览器和服务器只需要做一个握手的动作，然后，浏览器和服务器之间就形成了一条快速通道。两者之间就直接可以数据互相传送。

过去，很多网站为了实现推送技术，所用的技术都是 Ajax 轮询。轮询是在特定的的时间间隔（如每1秒），由浏览器对服务器发出HTTP请求，然后由服务器返回最新的数据给客户端的浏览器。这种传统的模式带来很明显的缺点，即浏览器需要不断的向服务器发出请求，然而HTTP请求可能包含较长的头部，其中真正有效的数据可能只是很小的一部分，显然这样会浪费很多的带宽等资源。

HTML5 定义的 WebSocket 协议，能更好的节省服务器资源和带宽，并且能够更实时地进行通讯。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220409085906.png" alt="image-20220409085906297" style="zoom:67%;" />

浏览器通过 JavaScript 向服务器发出建立 WebSocket 连接的请求，连接建立以后，客户端和服务器端就可以通过TCP连接直接交换数据。

当获取WebSocket连接后，可以通过 send() 方法来向服务器发送数据，并通过 onmessage 事件来接收服务器返回的数据。

 

WebSocket在传输的过程中不再使用http协议，而是Stomp协议

 

#### STOMP

STOMP即Simple (or Streaming) Text Orientated Messaging Protocol，简单(流)文本定向消息协议，它提供了一个可互操作的连接格式，允许STOMP客户端与任意STOMP消息代理（Broker）进行交互。STOMP协议由于设计简单，易于开发客户端，因此在多种语言和多种平台上得到广泛地应用。

 

STOMP协议的前身是TTMP协议（一个简单的基于文本的协议），专为消息中间件设计。

 

STOMP是一个非常简单和容易实现的协议，其设计灵感源自于HTTP的简单性。尽管STOMP协议在服务器端的实现可能有一定的难度，但客户端的实现却很容易。例如，可以使用Telnet登录到任何的STOMP代理，并与STOMP代理进行交互。

 

#### WebSocket 事件

以下是 WebSocket 对象的相关事件。

| 事件    | 事件处理程序     | 描述                       |
| ------- | ---------------- | -------------------------- |
| open    | Socket.onopen    | 连接建立时触发             |
| message | Socket.onmessage | 客户端接收服务端数据时触发 |
| error   | Socket.onerror   | 通信发生错误时触发         |
| close   | Socket.onclose   | 连接关闭时触发             |

#### WebSocket 方法

以下是 WebSocket 对象的相关方法。

| 方法           | 描述             |
| -------------- | ---------------- |
| Socket.send()  | 使用连接发送数据 |
| Socket.close() | 关闭连接         |

 

#### websocket聊天室

##### 引入websocket模块

```xml
<dependency>
	<groupId>org.springframework.boot</groupId>
	<artifactId>spring-boot-starter-websocket</artifactId>
</dependency>
```



##### 在resource/static下创建前端index.html页面

```java
<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Insert title here</title>
<link rel="stylesheet" type="text/css" href="css/index.css">
<script type="text/javascript" src="js/jquery.min.js"></script>
<script type="text/javascript">
	$(document).ready(function(){
		var url = "ws://localhost:8080/WebSocketHandler/";
		var ws = null;
		//连接服务器
		$("#join").click(function(){
			var userName = $("#userName").val();
			url = url + userName;	//传递用户名
			console.info(url);
			//创建对象，连接服务器
			ws = new WebSocket(url); 	//html5中提供了	
			
			//给open事件绑定方法
			ws.onopen = function(){
				console.info("连接成功");
			}
			//接收到数据
			ws.onmessage = function(result){
				var textarea = document.getElementById('textarea');
				textarea.append(result.data+"\n");
                 //将文本域的滚动条滚动到最后
				textarea.scrollTop = textarea.scrollHeight;
			}
			//关闭连接
			ws.onclose = function(){
				$("#textarea").append("用户:"+userName+"离开聊天室"+"\n");
				console.info("关闭连接");
			}
		});
		//发送消息
		$("#send").click(function(){
			//将输入框中的消息发送给服务器，并且显示到消息框中
			var messageInput = $("#message");
			var message = messageInput.val();
			if(ws!=null){
				ws.send(message);	//发送消息
				messageInput.val("");
			}
		});
		//断开连接
		$("#out").click(function(){
			if(ws!=null){
				ws.close();	
			}
		});	
	})
</script>
</head>
<body>
	<div id="box">
		<p>蜗牛聊天室</p>
		<textarea rows="10" cols="50" disabled="disabled" id="textarea"></textarea><br>
		<div class="infoBox">
			用户名:<input type="text" id="userName"><br><br>
			<button style="color: green;" id="join">加入聊天室</button>
			&nbsp;&nbsp;&nbsp;&nbsp;
			<button style="color: red;" id="out">离开聊天室</button>
		</div>
		<br><br>
		<div class="infoBox">
			消&nbsp;&nbsp;&nbsp;息:<input type="text" id="message"><br><br>
			<button id="send">发送消息</button>
		</div>
		<br>
		
	</div>
</body>
</html>
```



##### 创建css文件

```css
#box{
	width: 500px;
	background: pink;
	text-align: center;
}
.infoBox{
	text-align:left;
	position: relative;
	left: 62px;
}
#message{
	width: 322px;
}
#send{
	position:relative;
	left:50px;
	height:30px;
	width: 326px;
}

```



##### 创建后台向前端发送消息的工具类

```java
package com.my.utils;

import java.io.IOException;
import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;

import javax.websocket.Session;
import javax.websocket.RemoteEndpoint;
public class WebSocketUtil {
	//HashMap：不支持多线程，并发情况下线程不安全
	public static final Map<String, Session> MESSAGEMAP = new ConcurrentHashMap<>();
	
	//发送消息给客户端
	public static void sendMessage(Session session,String message) {
		if (session!=null) {
			final RemoteEndpoint.Basic basic = session.getBasicRemote();
			if (basic!=null) {
				try {
					basic.sendText(message);//发送消息回客户端
				} catch (IOException e) {
					e.printStackTrace();
				}
			}
		}
	}
	
	//将消息给所有聊天室的人
	//循环发送
	public static void sendMessageToAll(String message) {
		MESSAGEMAP.forEach((sessionId,session)->sendMessage(session, message));
	}
}


```



##### 创建用于接受前台消息的handler

```java
package com.my.handler;
import java.io.IOException;
import javax.websocket.OnClose;
import javax.websocket.OnError;
import javax.websocket.OnMessage;
import javax.websocket.OnOpen;
import javax.websocket.Session;
import javax.websocket.server.PathParam;
import javax.websocket.server.ServerEndpoint;
import org.springframework.web.bind.annotation.RestController;
import com.my.utils.WebSocketUtil;

@RestController
@ServerEndpoint("/WebSocketHandler/{userName}")		//表示接受的是STOMP协议提交的数据
public class WebSocketHandler {
	
	//建立连接
	@OnOpen
	public void openSession(@PathParam("userName")String userName,Session session) {
		//消息
		String message = "欢迎:"+userName+"加入群聊";
		//加入聊天室
		WebSocketUtil.MESSAGEMAP.put(userName, session);
		//发送消息
		WebSocketUtil.sendMessageToAll(message);
	}
	
	@OnMessage
	public void onMessage(@PathParam("userName")String userName,String message) {
		message = userName+":"+message;
		WebSocketUtil.sendMessageToAll(message);
	}
	
	//离开聊天室
	@OnClose
	public void onClose(@PathParam("userName")String userName,Session session) {
		//将当前用户从map中移除 注销
		WebSocketUtil.MESSAGEMAP.remove(userName);
		//群发消息
		WebSocketUtil.sendMessageToAll("用户:"+userName+"离开聊天室");
		//关闭session
		try {
			session.close();
		} catch (IOException e) {
			e.printStackTrace();
		}
	}
	
	//连接异常
	@OnError
	public void onError(Session session,Throwable throwable) {
		try {
			session.close();
		} catch (IOException e) {
			e.printStackTrace();
		}
	}
}

```



##### 在SpringBootTestApplication.java中引入WebSocket

```java
@SpringBootApplication
@EnableWebSocket	//启用websocket
@ComponentScan("com.my.handler")
public class SpringBootTest2Application {

	public static void main(String[] args) {
		SpringApplication.run(SpringBootTest2Application.class, args);
	}
	
	@Bean    //在容器中创建bean对象，在WebSocketUtil中需要用到的RemoteEndpoint对象
	public ServerEndpointExporter serverEndpointExporter() {
		return new ServerEndpointExporter();
	}
}

```



##### 利用不同的浏览器进入主界面进行测试。

# day10

### ElasticSearch介绍（中 15）

#### 思考：大规模数据如何检索？

当系统数据量上了10亿、100亿条的时候，我们在做系统架构的时候通常会从以下角度去考虑问题：

- 用什么数据库好？(mysql、oracle、mongodb、hbase…)

- 如何解决单点故障；(Zookeeper、MQ...)

- 如何保证数据安全性；(热备、冷备、异地多活)

- 如何解决检索难题；(数据库代理中间件：mysql-proxy、Cobar、MaxScale等;)

- 如何解决统计分析问题；(离线、近实时)

 

#### 传统数据库的应对解决方案

- 通过主从备份解决数据安全性问题；

- 通过数据库代理中间件心跳监测，解决单点故障问题； 

- 通过代理中间件将查询语句分发到各个slave节点进行查询，并汇总结果

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210722160608.png" alt="image-20210722160608748" style="zoom: 50%;" />



#### 常见搜索引擎

##### 1、Lucene

Lucene是目前最受欢迎的Java全文搜索框架，它是一个全文检索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎。

Lucene为开发人员提供了相当完整的工具包，可以非常方便地实现强大的全文检索功能。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210722160652.png" alt="image-20210722160652562" style="zoom:50%;" />

a）Apache Lucene优点

- 稳定，索引性能高。

  现代磁盘上每小时能够索引150GB以上的数据

  对内存的要求小：只需要1MB的堆内存

- 高效、准确、高性能的搜索算法

  搜索排名：最好的结果显示在最前面

  许多强大的查询类型：短语查询、通配符查询、近似查询、范围查询等

  可以对任意字段排序

- 跨平台解决方案

  作为 Apache 开源许可，在商业软件和开放程序中都可以使用 Lucene

  100%纯Java编写

  对多种语言提供接口

 

b）Apache Lucene缺点

- 不支持集群，只能通过solr或者nutch+hadoop间接实现。

  当代文件数量大，不可能只存在一个服务器上，实际请看看是存储在多个服务器上

- 几乎没有接口，功能扩展麻烦，主要是一些抽象类

  很多类是包级别的，自己要扩展功能只能在该包下基层该类，导致污染客户代码



##### 2、Apache Solr

Solr也基于Java实现，并且是基于Lucene实现的，Solr的主要特性包括：高效、灵活的缓存功能，垂直搜索功能，高亮显示搜索结果。

Solr还提供一款Web界面来管理索引的数据。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210722160808.png" alt="image-20210722160808618" style="zoom:50%;" />



Apache Solr优缺点

- Solr有一个更大、更成熟的用户、开发和贡献者社区。

- 支持添加多种格式的索引，如：HTML、PDF、微软 Office 系列软件格式以及 JSON、XML、CSV 等纯文本格式。

- Solr比较成熟、稳定。

- 建立索引时，搜索效率下降，实时索引搜索效率不高。



##### 3、ElasticSearch

Elasticsearch 是一个分布式可扩展的实时搜索和分析引擎,一个建立在全文搜索引擎 Apache Lucene(TM) 基础上的搜索引擎，但不仅仅是 Lucene 那么简单，它不仅包括了全文搜索功能，还可以进行以下工作:

- 分布式实时文件存储，并将每一个字段都编入索引，使其可以被搜索。

- 实时分析的分布式搜索引擎。

- 可以扩展到上百台服务器，处理PB级别的结构化或非结构化数据。

 

由于Elasticsearch的功能强大和使用简单，维基百科、卫报、Stack Overflow、GitHub等都纷纷采用它来做全文搜索。

 

Elasticsearch是目前最受欢迎的企业搜索引擎，其次是Apache Solr。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210722160905.png" alt="image-20210722160905402" style="zoom:50%;" />

a）ElasticSearch优点

- Elasticsearch是分布式的，不需要其他组件，分发是实时的。

- Elasticsearch 完全支持 Apache Lucene 的接近实时的搜索。

- 处理多租户不需要特殊配置，而Solr则需要更多的高级设置。

- 各节点组成对等的网络结构，某些节点出现故障时会自动分配其他节点代替其进行工作。

 

b）ElasticSearch缺点

- 系统维护者相对较少。

- Elasticsearch 完全支持 Apache Lucene 的接近实时的搜索。

- 还不够自动，不适合当前新的Index Warmup API（索引预热）



##### ElasticSearch与Solr比较

1、当只对已有数据进行搜索时Solr更快

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210722161019.png" alt="image-20210722161019177" style="zoom:50%;" />

2、当实时建立索引时, Solr会产生io阻塞，查询性能较差

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210722161030.png" alt="image-20210722161030912" style="zoom:50%;" />

 3、随着数据量的增加，Solr的搜索效率会变得更低，而Elasticsearch却没有明显的变化

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210722161044.png" alt="image-20210722161044286" style="zoom:50%;" />



### 核心概念（中 15）

介绍ElasticSearch中的基本概念：集群、节点、分片、副本、全文检索；与数据库相关概念对比

#### Cluster：集群

ES可以作为一个独立的单个搜索服务器。不过，为了处理大型数据集，实现容错和高可用性，ES可以运行在许多互相合作的服务器上。这些服务器的集合称为集群

#### Node：节点

形成集群的每个服务器称为节点。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210722161125.png" alt="image-20210722161125845" style="zoom:50%;" />

#### Shard：分片

分片是一个底层的工作单元 ，它仅保存了全部数据中的一部分，一个分片是一个 Lucene 的实例，它本身就是一个完整的搜索引擎，我们的文档被存储和索引到分片内。

 

每个分片又有一个副本分片，副本分片就是主分片的copy，对于分布式搜索引擎来说, 分片及副本的分配将是高可用及快速搜索响应的设计核心.主分片与副本都能处理查询请求，它们的唯一区别在于只有主分片才能处理更新请求，这就有点像我们常见的“主从”的概念了。

 

Elasticsearch 是利用分片将数据分发到集群内各处的。分片是数据的容器，文档保存在分片内，分片又被分配到集群内的各个节点里。当你的集群规模扩大或者缩小时， Elasticsearch 会自动的在各节点中迁移分片，使得数据仍然均匀分布在集群里。所以集群和分片关系非常密切，学习集群之前，需要了解分片的概念和作用。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210722161200.png" alt="image-20210722161200081" style="zoom:50%;" />

#### Replia：副本

为提高查询吞吐量或实现高可用性，可以使用分片副本。

副本是一个分片的精确复制，每个分片可以有零个或多个副本。ES中可以有许多相同的分片，其中之一被选择更改索引操作，这种特殊的分片称为主分片。

当主分片丢失时，如：该分片所在的数据不可用时，集群将副本提升为新的主分片

 

#### 全文检索

全文检索就是对一篇文章进行索引，可以根据关键字搜索，类似于mysql里的like语句。

全文索引就是把内容根据词的意义进行分词，然后分别创建索引，例如”接下来听我给大家讲解ES的基本使用与深层原理” 可能会被分词成：“接下来“，“大家”,”学会“，“基本“，”原理“ 等token，这样当你搜索“你们” 或者 “原理” 都会把这句搜出来。

```
curl -XGET http://192.168.74.128:9200/_analyze?pretty -H 'Content-Type:application/json' -d'               
{
  "analyzer": "ik_smart",
  "text": "听说看我上课的兄弟最帅、姑娘最美"
}'
```



#### ES的主要概念（与Mysql对比）

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210722161320.png" alt="image-20210722161320732" style="zoom:50%;" />

- 关系型数据库中的数据库（DataBase），等价于ES中的索引（Index）

- 一个数据库下面有N张表（Table），等价于1个索引Index下面有N多类型（Type），

- 一个数据库表（Table）下的数据由多行（ROW）多列（column，属性）组成，等价于1个Type由多个文档（Document）和多Field组成。



### ElasticSearch安装步骤（低  30）

讲解ElasticSearch的安装步骤、基本配置及配置信息含义，JVM配置

 #### 安装说明

- 本教程基于ElasticSearch7.4.2

- 操作系统Centos7

- JDK11

- 虚拟机内存：8G

- CPU：8核

- 硬盘：80GB

#### 安装JDK11

1、写在系统自带的JDK

​	查看当前安装的JDK相关组件

​	source /etc/profile

​	

​	将所有openjdk相关的都卸载 

​	rpm -e --nodeps java-1.7.0-openjdk-1.7.0.191-2.6.15.5.el7.x86_64



2、切换到java安装目录

​    如果没有该目录自己创建一个

​	cd /usr/java

3、删除里面的所有内容

​	rm -rf *

4、将JDK11上传到该目录下并解压

​	tar -zxvf jdk-11.0.1_linux-x64_bin.tar.gz

5、输入  vi /etc/profile打开文件配置环境变量，在文件最后添加以下代码

```
#java environment
export JAVA_HOME=/usr/java/jdk-11.0.1
export CLASSPATH=.:${JAVA_HOME}/jre/lib/rt.jar:${JAVA_HOME}/lib/dt.jar:${JAVA_HOME}/lib/tools.jar
export PATH=$PATH:${JAVA_HOME}/bin
```

保存退出

6、输入命令让刚才的配置生效

​	source /etc/profile

​    java -version

#### 安装elasticsearch

1、切换到root用户：su root

2、创建文件夹：<font color='red'>mkdir /usr/local/elasticsearch</font>

3、将elasticsearch-7.4.2-linux-x86_64.tar.gz安装包拷贝到该文件夹中

4、解压压缩包：tar -zxvf 包名

5、删除压缩包：rm -f 包名（可选）

6、修改elasticsearch.yml：<font color='red'>vi elasticsearch-7.4.2/config/elasticsearch.yml</font>

```yml
#集群名称
17  cluster.name: my-application
#节点名称
23  node.name: node-1
#将来访问elastic的话，都是通过API访问，在这我们要提供一个http主机地址，这里就是本机IP
55  network.host: 192.168.40.233  
#默认端口
59  http.port: 9200
#指定集群节点列表
72 cluster.initial_master_nodes: ["node-1"]

末尾增加
#开启跨域访问
http.cors.enabled: true
http.cors.allow-origin: "*"
#是否能成为master节点
node.master: true
#该节点能存储数据
node.data: true 
```

7、创建用户

​	<font color='red'>groupadd es</font>

​	<font color='red'>useradd esuser -g es -p es</font>

​	<font color='red'>chown -R esuser:es /usr/local/elasticsearch/</font>



8、切换到esuser用户启动es

​	<font color='red'>su esuser</font>

​	<font color='red'>cd /usr/local/elasticsearch/elasticsearch-7.4.2</font>

​	<font color='red'>./bin/elasticsearch</font>

报错：

- ERROR: [2] bootstrap checks failed

  [1]: max number of threads [3756] for user [esuser] is too low, increase to at least [4096]

- Likely root cause: java.nio.file.AccessDeniedException...错误，表示授权未成功，再次授权即可,需要先切换成root用户再执行授权的指令

- max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]

  将当前用户的软硬限制调大。

![image-20210816112945000](https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210816112945.png)

9、JVM内存太小：修改大小

配置大小：切换成root用户

​    <font color='red'>su root</font>

​	<font color='red'>vi /etc/security/limits.conf</font>

在文件末尾添加以下内容

```
#任何用户可以打开的最大的文件描述符数量，默认1024，这里的数值会限制tcp连接
* soft nofile 65536
* hard nofile 65536
esuser soft nofile 65536
esuser hard nofile 65536

#任何用户可以打开的最大进程数
* soft    nproc   4096
* hard    nproc   4096

#解除对memlock（内存锁定）的限制
esuser soft memlock unlimited
esuser hard memlock unlimited
```

修改90-nproc.conf，提高普通用户默认进程数(1024)，指定root用户不受限制

​	<font color='red'>vi /etc/security/limits.d/90-nproc.conf</font>

```
*          soft    nproc     8192
root       soft    nproc     unlimited
```

修改sysctl.conf，设置虚拟内存大小

​	<font color='red'>vi /etc/sysctl.conf</font>

```
#追加以下内容：
#设置虚拟内存大小，默认是65536
vm.max_map_count=655360
```

保存后，执行：

​	<font color='red'>sysctl -p</font>

让内核参数立即生效



**<font color='red'>关闭xshell或者新开一个xshell连接，然后重新启动es，成功。</font>**

​	su esuser

​	cd /usr/local/elasticsearch/elasticsearch-7.4.2

​	./bin/elasticsearch

10、开起9200端口，便于外部计算机通过浏览器访问es

```
firewall-cmd --zone=public --add-port=9300/tcp --permanent
firewall-cmd --zone=public --add-port=9200/tcp --permanent

systemctl restart firewalld.service
```

11、打开浏览器，在地址栏中输入虚拟机ip:9200回车，显示以下内容表示运行成功

 <img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210722162014.png" alt="image-20210722162014146" style="zoom: 67%;" />



指定elasticsearch使用内存大小

 	vi /usr/local/elasticsearch/elasticsearch-7.4.2/config/jvm.options

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210811175612.png" alt="image-20210811175612438" style="zoom:50%;" />



### ElasticSearchHead安装（低 30）

#### 安装nodejs

1、创建nodejs文件夹

​	<font color='red'>mkdir /usr/local/elasticsearch/nodejs</font>

2、进入文件夹

​	<font color='red'>cd /usr/local/elasticsearch/nodejs</font>

3、将nodejs的压缩包复制到nodejs文件夹并解压

​	<font color='red'>tar -xvf node-v14.15.5-linux-x64.tar.xz</font>

4、重命名文件夹为node-14

​	<font color='red'>mv node-v14.15.5-linux-x64 node-14</font>

5、配置全局使用

​	<font color='red'>ln -s /usr/local/elasticsearch/nodejs/node-14/bin/node /usr/local/bin/node</font>

​	<font color='red'>ln -s /usr/local/elasticsearch/nodejs/node-14/bin/npm /usr/local/bin/npm</font>

6、输入：node -v 查看版本

 

7、设置淘宝的 pacakge mirror 镜像加速

​	<font color='red'>npm config set registry https://registry.npm.taobao.org</font>

 

8、安装grunt项目构建工具

​	<font color='red'>npm install -g grunt-cli </font>



#### 安装Head

1、将elasticsearch-head安装包上传到/usr/local/elasticsearch文件夹下并解压

​	<font color='red'>unzip elasticsearch-head.zip</font>

2、修改配置文件

​	<font color='red'>vi /usr/local/elasticsearch/elasticsearch-head/_site/app.js</font>

修改登录访问head的IP地址

![image-20210724213543410](https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210724213543.png)

3、安装

```
npm config set registry=http://registry.npm.taobao.org/       //修改源地址为淘宝NPM镜像
cd elasticsearch-head
npm install
```



npm install 安装时，可能会报 phantomjs-prebuilt@2.1.16安装失败。解决方法

```
npm install phantomjs-prebuilt@2.1.16 --ignore-scripts
然后
npm install

```



4、重新开一个终端，开起9100端口，便于外部计算机访问

```
firewall-cmd --zone=public --add-port=9100/tcp --permanent

systemctl restart firewalld.service

```



5、启动插件   在head的主目录下

npm run start

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210724214040.png" alt="image-20210724214040658" style="zoom: 50%;" />

6、在浏览器地址栏上输入：ip:9100访问head管理页面

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210723102521.png" alt="image-20210723102521210" style="zoom: 33%;" />





### Kibana的安装与使用（低 30）

Kibana是一个开源的分析与可视化平台，设计出来用于和Elasticsearch一起使用的。你可以用kibana搜索、查看存放在Elasticsearch中的数据。Kibana与Elasticsearch的交互方式是各种不同的图表、表格、地图等，直观的展示数据，从而达到高级的数据分析与可视化的目的。



#### 安装

1、创建/usr/local/elasticsearch/kibana目录

 	<font color='red'>mkdir /usr/local/elasticsearch/kibana</font>

2、将kibana安装包移动到该目录下并解压

​	<font color='red'>cd /usr/local/elasticsearch/kibana</font>

​	<font color='red'>tar -zxvf kibana-7.4.2-linux-x86_64.tar.gz</font>

 

3、编辑kibana主目录/config/kibana.yml，添加以下内容

​	server.port: 5601

​	server.host: "192.168.74.146"

​	elasticsearch.url: "http://192.168.74.146:9200"

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210723103245.png" alt="image-20210723103245657" style="zoom:50%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210724215816.png" alt="image-20210724215816756" style="zoom:50%;" />



4、开起5601端口，便于外部计算机访问

​	firewall-cmd --zone=public --add-port=5601/tcp --permanent

​	systemctl restart firewalld.service



5、kibana不能以root用户启动，所以给esuser进行授权，用esuser进行启动

​	<font color='red'>chown -R esuser:es /usr/local/elasticsearch/kibana/kibana-7.4.2-linux-x86_64</font>

6、启动kibana

​	kibana主目录<font color='red'>/bin/kibana</font>

 

7、浏览器输入：<font color='red'>192.168.74.146:5601</font>打开kibana管理页面

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210724221120.png" alt="image-20210724221120181" style="zoom:33%;" />

#### 基本使用

1、导入数据

将woniumall.json文件上传到Linux任意目录，然后在该目录下执行以下指令将数据导入到es中

```sh
curl -XPOST '192.168.74.145:9200/woniumall/_bulk?pretty' -H "Content-Type: application/json" --data-binary @woniumall.json

```

备注：curl是一个利用URL语法在命令行下工作的文件传输工具，全名CommandLine Uniform Resource Locator（命令行统一资源定位符）



刷新head管理页面，看到数据表明OK

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210723150551.png" alt="image-20210723150551225" style="zoom:33%;" />

选择kibana的开发工具

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210724221441.png" alt="image-20210724221441772" style="zoom: 33%;" />

2、查询指定索引

GET <font color='red'>索引名</font>/_search

```
GET woniumall/_search
{
  "query": {
    "match_all": {}
  }
}

```

- match_all 查询所有

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210724221441.png" alt="image-20210724221441772" style="zoom: 33%;" />

结果解释：

```json
{
  "took": 2,						#查询花费时间  毫秒
  "timed_out": false,				#是否超时
  "_shards": {						#分片信息
    "total": 5,						#分片数
    "successful": 5,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": 733,
    "max_score": 1,
    "hits": [
      {
        "_index": "woniumall",		#索引
        "_type": "line",			#文档类型
        "_id": "0",					#文档id
        "_score": 1,				#文档得分
        "_source": {				#文档数据
          "id": 2,
          "name": "企业IT架构转型之道 阿里巴巴中台战略思想与架构实战",
          "goodsno": "6523715169109",
          "publisher": "机械工业出版社",
          "pubtime": "2017-09-01 ",
          "description": "",
          "salesprice": 1,
          "salenums": 81
        }
      }
    ]
  }
}

```



- 以id排序降序查询

```
GET woniumall/_search
{
  "query": {
    "match_all": {}
  },
  "sort": [
    {
      "id": "desc"
    }
  ]
}

```

- 通过"_source"指定需要查询哪些字段，多个字段用[]括起来

  <font color='red'>"_source": ["id","name"]</font>

```
GET woniumall/_search
{
  "query": {
    "match_all": {}
  },
  "_source": ["id","name"],
  "sort": [
    {
      "_id": "desc"
    }
  ]
}

```

- match条件查询

以图书名作为查询条件进行查询（模糊）

```
GET woniumall/_search
{
  "query": {
    "match": {
      "name":"软件开发"
    }
  },
  "_source": ["name","description"],
  "sort": [
    {
      "_id": "desc"
    }
  ]
}

```

会把查询条件进行分词，然后进行查询,多个词条之间是or的关系



- 某些情况下，我们需要更精确查找，我们希望这个关系变成and，可以这样做    包含全部单词

  "name":{
          "query": "软件开发",
          "operator": "and"
   }

```
GET woniumall/_search
{
  "query": {
    "match": {
      "name":{
        "query": "软件开发",
        "operator": "and"
      }
    }
  },
  "_source": ["name"],
  "sort": [
    {
      "_id": "desc"
    }
  ]
}

```



- 精确匹配

<font color='red'>term 查询被用于精确值 匹配，这些精确值可能是数字、时间、布尔或者那些未分词的字符串</font>

```
GET woniumall/_search
{
  "query": {
    "term": {
      "salenums": {
        "value": "230"
      }
    }
  },
  "sort": [
    {
      "_id": "desc"
    }
  ]
}

```



- 布尔组合（bool)

bool把各种其它查询通过must（与）、must_not（非）、should（或）的方式进行组合

```
GET woniumall/_search
{
  "query": {
    "bool": {
      "must": [{
        "match": {
          "name": "IT"
        }
      }],
      "must_not": [{
        "match": {
          "name": "java"
        }
      }],
      "should": [{
        "match": {
          "name": "编程"
        }
      }]
    }
  },
  "sort": [
    {
      "_id": "desc"
    }
  ]
}

```

- 范围查询(range)

range 查询找出那些落在指定区间内的数字或者时间

```
GET woniumall/_search
{
  "query": {
    "range": {
      "salesprice": {
        "gte": 10,
        "lte": 60
      }
    }
  },
  "sort": [
    {
      "_id": "desc"
    }
  ]
}

```

| 操作符 | 说明     |
| ------ | -------- |
| gt     | 大于     |
| gte    | 大于等于 |
| lt     | 小于     |
| lte    | 小于等于 |

 

- 过滤(filter)

条件查询中进行过滤

所有的查询都会影响到文档的评分及排名。如果我们需要在查询结果中进行过滤，并且不希望过滤条件影响评分，那么就不要把过滤条件作为查询条件来用。而是使用filter方式：

```
GET woniumall/_search
{
  "query": {
    "bool": {
      "must": [{
        "match": {
          "name": "IT"
        }
      }],
      "filter": {
        "range": {
          "salesprice": {
            "gte": 10,
            "lte": 30
          }
        }
      }
    }
  },
  "sort": [
    {
      "_id": "desc"
    }
  ]
}

```



- 高亮

高亮原理：

​	服务端搜索数据，得到搜索结果

​	把搜索结果中，搜索关键字都加上约定好的标签

​	前端页面提前写好标签的CSS样式，即可高亮

elasticsearch中实现高亮的语法比较简单：

```
GET woniumall/_search
{
  "query": {
    "match": {
      "name": "IT"
    }
  },
  "highlight": {
    "pre_tags": "<font color='red'>",
    "post_tags": "</font>",
    "fields": {
      "name": {}
    }
  }, 
  "sort": [
    {
      "_id": "desc"
    }
  ]
}

```

在使用match查询的同时，加上一个highlight属性：

​	pre_tags：前置标签

​	post_tags：后置标签

​	fields：需要高亮的字段

​		name：这里声明name字段需要高亮，后面可以为这个字段设置特有配置，也可以空

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210723152842.png" alt="image-20210723152842764" style="zoom: 50%;" />



- 分页查询

**<font color='red'>"from": 0, </font>**
 **<font color='red'>"size": 3,</font>**

```
GET woniumall/_search
{
  "query": {
    "match": {
      "name": "IT"
    }
  },
  "from": 0, 
  "size": 3,
  "sort": [
    {
      "_id": "desc"
    }
  ]
}

```



### IK分词器（中 15）

IK分词器在是一款 基于词典和规则 的中文分词器。

之前我们创建索引，查询数据，都是使用的默认的分词器，分词效果不太理想，会把text的字段分成一个一个汉字，即把一段中文或者别的划分成一个个的关键字,我们在搜索时候会把自己的信息进行分词,会把数据库中或者索引库中的数据进行分词,然后进行一个匹配操作,默认的中文分词器是将每个字看成一个词,比如"我爱技术"会被分为"我","爱","技","术",这显然不符合要求,所以我们需要安装中文分词器IK来解决这个问题，所以这里就需要更加智能的分词器IK分词器了。

#### 安装

1、在elasticsearch的plugins目录下创建名为ik的目录



2、将ik压缩包拷贝到ik目录下并解压，同时删除压缩包

​	unzip elasticsearch-analysis-ik-7.4.2.zip



3、重启elasticsearch



4、新开一个终端，输入以下内容

```
curl -XGET http://192.168.74.145:9200/_analyze?pretty -H 'Content-Type:application/json' -d'               
{
"analyzer": "ik_smart",
"text": "蜗牛学苑专注于IT与互联网人才孵化培养，开设有：Java开发、测试开发、Web前端开发、网络安全、UI设计、Python全栈、数据分析、物联网开发、人工智能等培训学科。我们一直坚持创新人才的培养模式，以“尊重人才，崇尚技术，诚实守信，坚持原则"
}'

```

出现以下结果表示安装成功

```
{
  "tokens" : [
    {
      "token" : "蜗牛",
      "start_offset" : 0,
      "end_offset" : 2,
      "type" : "CN_WORD",
      "position" : 0
},
…

```

#### analyzer分词策略

分词策略主要有两种：ik_smart和ik_max_word

- ik_smart：粒度较粗比较智能

- ik_max_word：最大限度分词。粒度较细

一般的策略是建立索引使用ik_max_word，查询时使用ik_smart，这样就能尽可能多的查到结果



### SpringBoot整合ElasticSearch开发（高  60）

整合的基本步骤、利用Spring data ElasticSearch实现基本CRUD

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726105431.png" alt="image-20210726105430906" style="zoom: 33%;" />

application.yml中添加elasticsearch相关配置

```yaml
spring:
  elasticsearch:
    rest:
      uris: 192.168.74.146:9200

```



创建Goods实体类

```java
package com.woniuxy.elasticsearchteach.entity;

import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;
import org.springframework.data.annotation.Id;
import org.springframework.data.elasticsearch.annotations.Document;
import org.springframework.data.elasticsearch.annotations.Field;
import org.springframework.data.elasticsearch.annotations.FieldType;

import java.math.BigDecimal;

@Data
@NoArgsConstructor
@AllArgsConstructor
@Document(indexName = "woniumall")
public class Goods {
    @Id
    @Field(name="id", type = FieldType.Keyword)
    private int id;

    @Field(type = FieldType.Text,analyzer = "ik_max_word",searchAnalyzer = "ik_smart")
    private String name;

    @Field(type = FieldType.Text)
    private String goodsno;

    @Field(type = FieldType.Text,analyzer = "ik_max_word",searchAnalyzer = "ik_smart")
    private String publisher;

    @Field
    private String pubtime;

    @Field(type = FieldType.Text,analyzer = "ik_max_word",searchAnalyzer = "ik_smart")
    private String description;

    @Field
    private BigDecimal salesprice;

    @Field
    private int salenums;
}


```

#### FieldType类型

| 类型              | 解释                                                         |
| ----------------- | ------------------------------------------------------------ |
| FieldType.Text    | 当一个字段是要被全文搜索的，比如Email内容、产品描述，应该使用text类型。设置text类型以后，字段内容会被分析，在生成倒排索引以前，字符串会被分析器分成一个一个词项。text类型的字段不用于排序，很少用于聚合（termsAggregation除外）。 |
| FieldType.Keyword | keyword类型适用于索引结构化的字段，比如email地址、主机名、状态码和标签。如果字段需要进行过滤(比如查找已发布博客中status属性为published的文章)、排序、聚合。keyword类型的字段只能通过精确值搜索到。 |
| FieldType.Integer | 整数类型                                                     |



#### SpringData操作elasticsearch

创建mapper接口继承ElasticsearchRepository接口

```java
package com.woniuxy.elasticsearchteach.mapper;

import com.woniuxy.elasticsearchteach.entity.Goods;
import org.springframework.data.elasticsearch.repository.ElasticsearchRepository;
import org.springframework.stereotype.Repository;

@Repository
public interface GoodsMapper extends ElasticsearchRepository<Goods,Integer> {
 
}

```



在测试类中编写测试代码：基础CRUD

| API               | 解释                                                         |
| ----------------- | ------------------------------------------------------------ |
| findAll()         | 查询所有                                                     |
| findAll(pageable) | 分页查询                                                     |
| findById          | 以id查询，<font color='red'>此id指的是elasticsearch数据库中的id，也就是数据的序号，不是数据的id</font> |
| save(obj)         | 插入数据                                                     |
| deleteById(id)    | 以id删除，<font color='red'>此id为实体类对象中的id</font>    |

```java
package com.woniuxy.elasticsearchteach;

import com.woniuxy.elasticsearchteach.entity.Goods;
import com.woniuxy.elasticsearchteach.mapper.GoodsMapper;
import org.junit.jupiter.api.Test;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.PageRequest;
import org.springframework.data.domain.Pageable;

import javax.annotation.Resource;
import java.math.BigDecimal;
import java.util.ArrayList;
import java.util.List;
import java.util.Optional;

@SpringBootTest
public class CRUD {
    @Resource
    private GoodsMapper goodsMapper;

    //查询所有
    @Test
    public void all(){
        //查询数据
        Iterable<Goods> iterable = goodsMapper.findAll();
        List<Goods> goods = new ArrayList<>();
        //遍历数据
        iterable.forEach(goods::add);   //lambda表达式
        System.out.println(goods.size());
    }
    
    //分页查询
    @Test
    public void page(){
        //分页对象
        Pageable pageable = PageRequest.of(10, 5);
        //查询
        Page<Goods> page = goodsMapper.findAll(pageable);
        //内容
        List<Goods> goods = page.getContent();
        //总页数
        int totalPages = page.getTotalPages();
        //总数
        long totalElements = page.getTotalElements();
        //页码
        int number = page.getNumber();
        //
        System.out.println(totalPages+","+totalElements+","+number);
    }

    //以id查询：此id指的是elasticsearch数据库中的id，也就是数据的序号，不是数据的id
    @Test
    public void findById(){
        //获得容器
        Optional<Goods> optional = goodsMapper.findById(0);
        //获取数据
        Goods goods = optional.get();
        System.out.println(goods);
    }

    //添加数据
    @Test
    public void add(){
        Goods goods = new Goods();
        goods.setId(1001);
        goods.setName("think in java");
        goods.setDescription("think in java is a very good book");
        goods.setGoodsno("wn202107260001");
        goods.setPublisher("蜗牛出版社");
        goods.setPubtime("2021-07-26");
        goods.setSalenums(0);
        goods.setSalesprice(new BigDecimal(1));
        //
        Goods save = goodsMapper.save(goods);
        //
        System.out.println(save);
    }

    //以id删除：此id为goods中的id
    @Test
    public void del(){
        goodsMapper.deleteById(1001);
    }
}

```

# day11



### SpringBoot整合ElasticSearch开发（高  60）

整合的基本步骤、利用Spring data ElasticSearch实现基本CRUD

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726105431.png" alt="image-20210726105430906" style="zoom: 33%;" />

application.yml中添加elasticsearch相关配置

```yaml
spring:
  elasticsearch:
    rest:
      uris: 192.168.74.146:9200
```



创建Goods实体类

```java
package com.woniuxy.elasticsearchteach.entity;

import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;
import org.springframework.data.annotation.Id;
import org.springframework.data.elasticsearch.annotations.Document;
import org.springframework.data.elasticsearch.annotations.Field;
import org.springframework.data.elasticsearch.annotations.FieldType;

import java.math.BigDecimal;

@Data
@NoArgsConstructor
@AllArgsConstructor
@Document(indexName = "woniumall")
public class Goods {
    @Id
    @Field(name="id", type = FieldType.Keyword)
    private int id;

    @Field(type = FieldType.Text,analyzer = "ik_max_word",searchAnalyzer = "ik_smart")
    private String name;

    @Field(type = FieldType.Text)
    private String goodsno;

    @Field(type = FieldType.Text,analyzer = "ik_max_word",searchAnalyzer = "ik_smart")
    private String publisher;

    @Field
    private String pubtime;

    @Field(type = FieldType.Text,analyzer = "ik_max_word",searchAnalyzer = "ik_smart")
    private String description;

    @Field
    private BigDecimal salesprice;

    @Field
    private int salenums;
}

```

#### FieldType类型

| 类型              | 解释                                                         |
| ----------------- | ------------------------------------------------------------ |
| FieldType.Text    | 当一个字段是要被全文搜索的，比如Email内容、产品描述，应该使用text类型。设置text类型以后，字段内容会被分析，在生成倒排索引以前，字符串会被分析器分成一个一个词项。text类型的字段不用于排序，很少用于聚合（termsAggregation除外）。 |
| FieldType.Keyword | keyword类型适用于索引结构化的字段，比如email地址、主机名、状态码和标签。如果字段需要进行过滤(比如查找已发布博客中status属性为published的文章)、排序、聚合。keyword类型的字段只能通过精确值搜索到。 |
| FieldType.Integer | 整数类型                                                     |



#### SpringData操作elasticsearch

创建mapper接口继承ElasticsearchRepository接口

```java
package com.woniuxy.elasticsearchteach.mapper;

import com.woniuxy.elasticsearchteach.entity.Goods;
import org.springframework.data.elasticsearch.repository.ElasticsearchRepository;
import org.springframework.stereotype.Repository;

@Repository
public interface GoodsMapper extends ElasticsearchRepository<Goods,Integer> {
 
}
```



在测试类中编写测试代码：基础CRUD

| API               | 解释                                                         |
| ----------------- | ------------------------------------------------------------ |
| findAll()         | 查询所有                                                     |
| findAll(pageable) | 分页查询                                                     |
| findById          | 以id查询，<font color='red'>此id指的是elasticsearch数据库中的id，也就是数据的序号，不是数据的id</font> |
| save(obj)         | 插入数据                                                     |
| deleteById(id)    | 以id删除，<font color='red'>此id为实体类对象中的id</font>    |

```java
package com.woniuxy.elasticsearchteach;

import com.woniuxy.elasticsearchteach.entity.Goods;
import com.woniuxy.elasticsearchteach.mapper.GoodsMapper;
import org.junit.jupiter.api.Test;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.PageRequest;
import org.springframework.data.domain.Pageable;

import javax.annotation.Resource;
import java.math.BigDecimal;
import java.util.ArrayList;
import java.util.List;
import java.util.Optional;

@SpringBootTest
public class CRUD {
    @Resource
    private GoodsMapper goodsMapper;

    //查询所有
    @Test
    public void all(){
        //查询数据
        Iterable<Goods> iterable = goodsMapper.findAll();
        List<Goods> goods = new ArrayList<>();
        //遍历数据
        iterable.forEach(goods::add);   //lambda表达式
        System.out.println(goods.size());
    }
    
    //分页查询
    @Test
    public void page(){
        //分页对象
        Pageable pageable = PageRequest.of(10, 5);
        //查询
        Page<Goods> page = goodsMapper.findAll(pageable);
        //内容
        List<Goods> goods = page.getContent();
        //总页数
        int totalPages = page.getTotalPages();
        //总数
        long totalElements = page.getTotalElements();
        //页码
        int number = page.getNumber();
        //
        System.out.println(totalPages+","+totalElements+","+number);
    }

    //以id查询：此id指的是elasticsearch数据库中的id，也就是数据的序号，不是数据的id
    @Test
    public void findById(){
        //获得容器
        Optional<Goods> optional = goodsMapper.findById(0);
        //获取数据
        Goods goods = optional.get();
        System.out.println(goods);
    }

    //添加数据
    @Test
    public void add(){
        Goods goods = new Goods();
        goods.setId(1001);
        goods.setName("think in java");
        goods.setDescription("think in java is a very good book");
        goods.setGoodsno("wn202107260001");
        goods.setPublisher("蜗牛出版社");
        goods.setPubtime("2021-07-26");
        goods.setSalenums(0);
        goods.setSalesprice(new BigDecimal(1));
        //
        Goods save = goodsMapper.save(goods);
        //
        System.out.println(save);
    }

    //以id删除：此id为goods中的id
    @Test
    public void del(){
        goodsMapper.deleteById(1001);
    }

}
```



#### 自定义查询

ElasticsearchRepository接口提供给我们的方法比较少，一般情况下很难满足我们的需求，但同时ElasticsearchRepository也为我们提供了自定义接口的方法，但是自定义的方法必须满足elasticsearch相关规范，如下表所示：

| 关键字              | 使用示例                           | 等同于的ES查询                                               |
| :------------------ | :--------------------------------- | :----------------------------------------------------------- |
| And                 | findByNameAndPrice                 | {“bool” : {“must” : [ {“field” : {“name” : “?”}}, {“field” : {“price” : “?”}} ]}} |
| Or                  | findByNameOrPrice                  | {“bool” : {“should” : [ {“field” : {“name” : “?”}}, {“field” : {“price” : “?”}} ]}} |
| Is                  | findByName                         | {“bool” : {“must” : {“field” : {“name” : “?”}}}}             |
| Not                 | findByNameNot                      | {“bool” : {“must_not” : {“field” : {“name” : “?”}}}}         |
| Between             | findByPriceBetween                 | {“bool” : {“must” : {“range” : {“price” : {“from” : ?,”to” : ?,”include_lower” : true,”include_upper” : true}}}}} |
| LessThanEqual       | findByPriceLessThan                | {“bool” : {“must” : {“range” : {“price” : {“from” : null,”to” : ?,”include_lower” : true,”include_upper” : true}}}}} |
| GreaterThanEqual    | findByPriceGreaterThan             | {“bool” : {“must” : {“range” : {“price” : {“from” : ?,”to” : null,”include_lower” : true,”include_upper” : true}}}}} |
| Before              | findByPriceBefore                  | {“bool” : {“must” : {“range” : {“price” : {“from” : null,”to” : ?,”include_lower” : true,”include_upper” : true}}}}} |
| After               | findByPriceAfter                   | {“bool” : {“must” : {“range” : {“price” : {“from” : ?,”to” : null,”include_lower” : true,”include_upper” : true}}}}} |
| Like                | findByNameLike                     | {“bool” : {“must” : {“field” : {“name” : {“query” : “? *”,”analyze_wildcard” : true}}}}} |
| StartingWith        | findByNameStartingWith             | {“bool” : {“must” : {“field” : {“name” : {“query” : “? *”,”analyze_wildcard” : true}}}}} |
| EndingWith          | findByNameEndingWith               | {“bool” : {“must” : {“field” : {“name” : {“query” : “*?”,”analyze_wildcard” : true}}}}} |
| Contains/Containing | findByNameContaining               | {“bool” : {“must” : {“field” : {“name” : {“query” : “?”,”analyze_wildcard” : true}}}}} |
| In                  | findByNameIn(Collectionnames)      | {“bool” : {“must” : {“bool” : {“should” : [ {“field” : {“name” : “?”}}, {“field” : {“name” : “?”}} ]}}}} |
| NotIn               | findByNameNotIn(Collectionnames)   | {“bool” : {“must_not” : {“bool” : {“should” : {“field” : {“name” : “?”}}}}}} |
| True                | findByAvailableTrue                | {“bool” : {“must” : {“field” : {“available” : true}}}}       |
| False               | findByAvailableFalse               | {“bool” : {“must” : {“field” : {“available” : false}}}}      |
| OrderBy             | findByAvailableTrueOrderByNameDesc | {“sort” : [{ “name” : {“order” : “desc”} }],”bool” : {“must” : {“field” : {“available” : true}}}} |

例如：在mapper中添加以下方法

```java
package com.woniuxy.elasticsearchteach.mapper;

import com.woniuxy.elasticsearchteach.entity.Goods;
import org.springframework.data.domain.Pageable;
import org.springframework.data.elasticsearch.repository.ElasticsearchRepository;
import org.springframework.stereotype.Repository;

import java.util.List;

@Repository
public interface GoodsMapper extends ElasticsearchRepository<Goods,Integer> {
    //模糊+分页
    public List<Goods> findByNameLike(String name, Pageable pageable);
    //多条件
    public List<Goods> findByNameAndSalesprice(String name,double salesprice);
    //范围查询
    public List<Goods> findBySalespriceBetween(double min,double max, Pageable pageable);
}
```



测试类

```java
package com.woniuxy.elasticsearchteach;

import com.woniuxy.elasticsearchteach.entity.Goods;
import com.woniuxy.elasticsearchteach.mapper.GoodsMapper;
import org.junit.jupiter.api.Test;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.PageRequest;
import org.springframework.data.domain.Pageable;

import javax.annotation.Resource;
import java.util.ArrayList;
import java.util.Iterator;
import java.util.List;
import java.util.Optional;

@SpringBootTest
public class MapperTest {
    @Resource
    private GoodsMapper goodsMapper;

    //模糊查询 + 分页
    @Test
    public void test(){
        Pageable pageable = PageRequest.of(0,5);
        List<Goods> goods = goodsMapper.findByNameLike("IT", pageable);
        System.out.println(goods);
    }

    //多条件查询
    @Test
    public void and(){
        List<Goods> goods = goodsMapper.findByNameAndSalesprice("IT", 1.0);
        System.out.println(goods);
    }

    //范围查询+分页
    @Test
    public void between(){
        Pageable pageable = PageRequest.of(0,5);
        List<Goods> goods = goodsMapper.findBySalespriceBetween(10, 20, pageable);
        System.out.println(goods.size());
    }
}

```



#### ElasticsearchRestTemplate查询

导入插件

```xml
<plugin>
    <groupId>org.apache.maven.plugins</groupId>
    <artifactId>maven-surefire-plugin</artifactId>
    <configuration>
        <testFailureIgnore>true</testFailureIgnore>
    </configuration>
</plugin>
```



### 聚合搜索（高  15）



聚合分析是数据库中重要的功能特性，完成对一个查询的数据集中数据的聚合计算，如：找出某字段（或计算表达式的结果）的最大值、最小值，计算和、平均值等。

测试代码

```java
package com.woniuxy.elasticsearchteach;

import com.woniuxy.elasticsearchteach.entity.Goods;
import org.elasticsearch.search.aggregations.AggregationBuilders;
import org.elasticsearch.search.aggregations.metrics.*;
import org.junit.jupiter.api.Test;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.data.elasticsearch.core.ElasticsearchRestTemplate;
import org.springframework.data.elasticsearch.core.SearchHits;
import org.springframework.data.elasticsearch.core.query.NativeSearchQuery;
import org.springframework.data.elasticsearch.core.query.NativeSearchQueryBuilder;

import javax.annotation.Resource;

@SpringBootTest
public class TemplateTest {
    @Resource
    private ElasticsearchRestTemplate restTemplate;

    //统计某个字段数量
    @Test
    public void count(){
        //指定查询的字段
        //类似于：select count(id) as goods_count from xxx 
        ValueCountAggregationBuilder builder = AggregationBuilders.count("goods_count").field("id");

        //设置查询对象
        NativeSearchQuery searchQuery = new NativeSearchQueryBuilder()
                .addAggregation(builder)
                .build();

        //执行查询
        long count = restTemplate.count(searchQuery, Goods.class);
        System.out.println(count);
    }
    //求平均值
    @Test
    public void avg(){
        //类似于:select avg(salesprice) as avg_salesprice from xxx group by id
        AvgAggregationBuilder builder = AggregationBuilders.avg("avg_salesprice").field("salesprice");
        NativeSearchQuery searchQuery = new NativeSearchQueryBuilder()
                .addAggregation(builder)
                .build();
        SearchHits<Goods> search = restTemplate.search(searchQuery, Goods.class);
        //获取到avg对象
        ParsedAvg parsedAvg = (ParsedAvg) search.getAggregations().asMap().get("avg_salesprice");
        //获取值
        double value = parsedAvg.getValue();
    }

    //求和
    @Test
    public void sum(){
        //类似于:select sum(salesprice) as sum_salesprice from xxx group by id
        SumAggregationBuilder builder = AggregationBuilders.sum("sum_salesprice").field("salesprice");
        NativeSearchQuery searchQuery = new NativeSearchQueryBuilder()
                .addAggregation(builder)
                .build();
        SearchHits<Goods> search = restTemplate.search(searchQuery, Goods.class);
        //获取到sum对象
        ParsedSum parsedSum = (ParsedSum) search.getAggregations().asMap().get("sum_salesprice");

        //获取值
        double value = parsedSum.getValue();
        System.out.println(value);
    }

    //最大值
    @Test
    public void max(){
        //类似于:select max(salesprice) as max_salesprice from xxx group by id
        MaxAggregationBuilder builder = AggregationBuilders.max("max_salesprice").field("salesprice");
        NativeSearchQuery searchQuery = new NativeSearchQueryBuilder()
                .addAggregation(builder)
                .build();
        SearchHits<Goods> search = restTemplate.search(searchQuery, Goods.class);
        //获取到max对象
        ParsedMax parsedMax = (ParsedMax) search.getAggregations().asMap().get("max_salesprice");

        //获取值
        double value = parsedMax.getValue();
        System.out.println(value);
    }

    //最小值
    @Test
    public void min(){
        //类似于:select min(salesprice) min_salesprice from xxx group by id
        MinAggregationBuilder builder = AggregationBuilders.min("min_salesprice").field("salesprice");
        NativeSearchQuery searchQuery = new NativeSearchQueryBuilder()
                .addAggregation(builder)
                .build();
        SearchHits<Goods> search = restTemplate.search(searchQuery, Goods.class);
        //获取到min对象
        ParsedMin parsedMin = (ParsedMin) search.getAggregations().asMap().get("min_salesprice");

        //获取值
        double value = parsedMin.getValue();
        System.out.println(value);
    }
}
```



### 正向索引（中 15）

在搜索引擎中每个文件都对应一个文件ID，文件内容被表示为一系列关键词的集合（实际上在搜索引擎索引库中，关键词也已经转换为关键词ID）。例如“文档1”经过分词，提取了20个关键词，每个关键词都会记录它在文档中的出现次数和出现位置。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726145255.png" alt="image-20210726145255749" style="zoom:50%;" />

一般是通过key，去找value

 

当用户在主页上搜索关键词“华为手机”时，假设只存在正向索引（forward index），那么就需要扫描索引库中的所有文档，找出所有包含关键词“华为手机”的文档，再根据打分模型进行打分，排出名次后呈现给用户。因为互联网上收录在搜索引擎中的文档的数目是个天文数字，这样的索引结构根本无法满足实时返回排名结果的要求。



所以，搜索引擎会将正向索引重新构建为倒排索引，即把文件ID对应到关键词的映射转换为关键词到文件ID的映射，每个关键词都对应着一系列的文件，这些文件中都出现这个关键词



### 倒排索引（中 30）

倒排索引（Inverted Index）也叫反向索引，有反向索引必有正向索引。通俗地来讲，正向索引是通过key找value，反向索引则是通过value找key。

 

搜索引擎会将正向索引重新构建为倒排索引，即把文件ID对应到关键词的映射转换为关键词到文件ID的映射，每个关键词都对应着一系列的文件，这些文件中都出现这个关键词。

 

得到倒排索引的结构如下：

“关键词1”：“文档1”的ID，“文档2”的ID，…………。

“关键词2”：带有此关键词的文档ID列表。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726145922.png" alt="image-20210726145921986" style="zoom:50%;" />

从词的关键字，去找文档



#### 单词—文档矩阵

单词-文档矩阵是表达两者之间所具有的一种包含关系的概念模型，下图展示了其含义。图中的每列代表一个文档，每行代表一个单词，打对勾的位置代表包含关系。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726145948.png" alt="image-20210726145948522" style="zoom:50%;" />

从纵向即文档这个维度来看，每列代表文档包含了哪些单词，比如文档1包含了词汇1和词汇4，而不包含其它单词。从横向即单词这个维度来看，每行代表了哪些文档包含了某个单词。比如对于词汇1来说，文档1和文档4中出现过单词1，而其它文档不包含词汇1。矩阵中其它的行列也可作此种解读。

 

搜索引擎的索引其实就是实现“单词-文档矩阵”的具体数据结构。可以有不同的方式来实现上述概念模型，比如“倒排索引”、“签名文件”、“后缀树”等方式。但是各项实验数据表明，“倒排索引”是实现单词到文档映射关系的最佳实现方式。



#### 倒排索引基本概念

- 文档(Document)：一般搜索引擎的处理对象是互联网网页，而文档这个概念要更宽泛些，代表以文本形式存在的存储对象，相比网页来说，涵盖更多种形式，比如Word，PDF，html，XML等不同格式的文件都可以称之为文档。再比如一封邮件，一条短信，一条微博也可以称之为文档。在本书后续内容，很多情况下会使用文档来表征文本信息。

- 文档集合(Document Collection)：由若干文档构成的集合称之为文档集合。比如海量的互联网网页或者说大量的电子邮件都是文档集合的具体例子。

- 文档编号(Document ID)：在搜索引擎内部，会将文档集合内每个文档赋予一个唯一的内部编号，以此编号来作为这个文档的唯一标识，这样方便内部处理，每个文档的内部编号即称之为“文档编号”，后文有时会用DocID来便捷地代表文档编号。

- 单词编号(Word ID)：与文档编号类似，搜索引擎内部以唯一的编号来表征某个单词，单词编号可以作为某个单词的唯一表征。

- 倒排索引(Inverted Index)：倒排索引是实现“单词-文档矩阵”的一种具体存储形式，通过倒排索引，可以根据单词快速获取包含这个单词的文档列表。倒排索引主要由两个部分组成：“单词词典”和“倒排文件”。

- 单词词典(Lexicon)：搜索引擎的通常索引单位是单词，单词词典是由文档集合中出现过的所有单词构成的字符串集合，单词词典内每条索引项记载单词本身的一些信息以及指向“倒排列表”的指针。

- 倒排列表(PostingList)：倒排列表记载了出现过某个单词的所有文档的文档列表及单词在该文档中出现的位置信息，每条记录称为一个倒排项(Posting)。根据倒排列表，即可获知哪些文档包含某个单词。

- 倒排文件(Inverted File)：所有单词的倒排列表往往顺序地存储在磁盘的某个文件里，这个文件即被称之为倒排文件，倒排文件是存储倒排索引的物理文件。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726150105.png" alt="image-20210726150104981" style="zoom:50%;" />



#### 倒排索引简单实例

倒排索引从逻辑结构和基本思路上来讲非常简单。下面我们通过具体实例来进行说明，使得读者能够对倒排索引有一个宏观而直接的感受。

 

假设文档集合包含五个文档，每个文档内容如图所示，在图中最左端一栏是每个文档对应的文档编号。我们的任务就是对这个文档集合建立倒排索引。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726150218.png" alt="image-20210726150218860" style="zoom:50%;" />

中文和英文等语言不同，单词之间没有明确分隔符号，所以首先要用分词系统将文档自动切分成单词序列。这样每个文档就转换为由单词序列构成的数据流，为了系统后续处理方便，需要对每个不同的单词赋予唯一的单词编号，同时记录下哪些文档包含这个单词，在如此处理结束后，我们可以得到最简单的倒排索引。

 

在下图中，“单词ID”一栏记录了每个单词的单词编号，第二栏是对应的单词，第三栏即每个单词对应的倒排列表。比如单词“谷姐”，其单词编号为1，倒排列表为{1,2,3,4,5}，说明文档集合中每个文档都包含了这个单词。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726150235.png" alt="image-20210726150235194" style="zoom:50%;" />

之所以说上图所示倒排索引是最简单的，是因为这个索引系统只记载了哪些文档包含某个单词，而事实上，索引系统还可以记录除此之外的更多信息。

 

下图是一个相对复杂些的倒排索引，与上图的基本索引系统比，在单词对应的倒排列表中不仅记录了文档编号，还记载了单词频率信息（TF），即这个单词在某个文档中的出现次数，之所以要记录这个信息，是因为词频信息在搜索结果排序时，计算查询和文档相似度是很重要的一个计算因子，所以将其记录在倒排列表中，以方便后续排序时进行分值计算。在下图的例子里，单词“创始人”的单词编号为7，对应的倒排列表内容为：（3:1），其中的3代表文档编号为3的文档包含这个单词，数字1代表词频信息，即这个单词在3号文档中只出现过1次，其它单词对应的倒排列表所代表含义与此相同。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726150249.png" alt="image-20210726150249106" style="zoom:50%;" />

使用的倒排索引还可以记载更多的信息，下图所示索引系统除了记录文档编号和单词频率信息外，额外记载了两类信息，即每个单词对应的“文档频率信息”（对应下图的第三栏）以及在倒排列表中记录单词在某个文档出现的位置信息。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726150301.png" alt="image-20210726150301489" style="zoom:50%;" />

文档频率信息”代表了在文档集合中有多少个文档包含某个单词，之所以要记录这个信息，其原因与单词频率信息一样，这个信息在搜索结果排序计算中是非常重要的一个因子。而单词在某个文档中出现的位置信息并非索引系统一定要记录的，在实际的索引系统里可以包含，也可以选择不包含这个信息，之所以如此，因为这个信息对于搜索系统来说并非必需的，位置信息只有在支持“短语查询”的时候才能够派上用场。

 

以单词“拉姆”为例，其单词编号为8，文档频率为2，代表整个文档集合中有两个文档包含这个单词，对应的倒排列表为：{(3;1;<4>)，(5;1;<4>)},其含义为在文档3和文档5出现过这个单词，单词频率都为1，单词“拉姆”在两个文档中的出现位置都是4，即文档中第四个单词是“拉姆”。

 

上图所示倒排索引已经是一个非常完备的索引系统，实际搜索系统的索引结构基本如此，区别无非是采取哪些具体的数据结构来实现上述逻辑结构。

 

有了这个索引系统，搜索引擎可以很方便地响应用户的查询，比如用户输入查询词“FaceLook”，搜索系统查找倒排索引，从中可以读出包含这个单词的文档，这些文档就是提供给用户的搜索结果，而利用单词频率信息、文档频率信息即可以对这些候选搜索结果进行排序，计算文档和查询的相似性，按照相似性得分由高到低排序输出，此即为搜索系统的部分内部流程。



#### 单词词典

单词词典是倒排索引中非常重要的组成部分，它用来维护文档集合中出现过的所有单词的相关信息，同时用来记载某个单词对应的倒排列表在倒排文件中的位置信息。在支持搜索时，根据用户的查询词，去单词词典里查询，就能够获得相应的倒排列表，并以此作为后续排序的基础。

 

对于一个规模很大的文档集合来说，可能包含几十万甚至上百万的不同单词，能否快速定位某个单词，这直接影响搜索时的响应速度，所以需要高效的数据结构来对单词词典进行构建和查找，常见的有哈希加链表结构和树形结构。



#### 哈希加链表

下图是这种词典结构的示意图。这种词典结构主要由两个部分构成：

主体部分是哈希表，每个哈希表项保存一个指针，指针指向冲突链表，在冲突链表里，相同哈希值的单词形成链表结构。之所以会有冲突链表，是因为两个不同单词获得相同的哈希值，如果是这样，在哈希方法里被称做是一次冲突，可以将相同哈希值的单词存储在链表里，以供后续查找。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726150415.png" alt="image-20210726150415045" style="zoom:50%;" />

在建立索引的过程中，词典结构也会相应地被构建出来。比如在解析一个新文档的时候，对于某个在文档中出现的单词T，首先利用哈希函数获得其哈希值，之后根据哈希值对应的哈希表项读取其中保存的指针，就找到了对应的冲突链表。如果冲突链表里已经存在这个单词，说明单词在之前解析的文档里已经出现过。如果在冲突链表里没有发现这个单词，说明该单词是首次碰到，则将其加入冲突链表里。通过这种方式，当文档集合内所有文档解析完毕时，相应的词典结构也就建立起来了。

 

在响应用户查询请求时，其过程与建立词典类似，不同点在于即使词典里没出现过某个单词，也不会添加到词典内。以上图为例，假设用户输入的查询请求为单词3，对这个单词进行哈希，定位到哈希表内的2号槽，从其保留的指针可以获得冲突链表，依次将单词3和冲突链表内的单词比较，发现单词3在冲突链表内，于是找到这个单词，之后可以读出这个单词对应的倒排列表来进行后续的工作，如果没有找到这个单词，说明文档集合内没有任何文档包含单词，则搜索结果为空。



### ElasticSearch与MySQL对比（中 15）

ElasticSearch索引比MySQL快的原因、MySQL索引实现原理

#### Mysql中的索引

在MySQL中，索引属于存储引擎级别的概念，不同存储引擎对索引的实现方式是不同的，本文主要讨论MyISAM和InnoDB两个存储引擎的索引实现方式。

 

1、MyISAM索引实现

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726150451.png" alt="image-20210726150451253" style="zoom:50%;" />

-  MyISAM表的索引和数据是分离的，索引保存在”表名.MYI”文件内，而数据保存在“表名.MYD”文件内。

-  MyISAM的索引方式也叫做“非聚集”的，之所以这么称呼是为了与InnoDB的聚集索引区分。

 2、InnoDB索引实现

虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726150519.png" alt="image-20210726150519731" style="zoom:67%;" />

上图是InnoDB主索引（同时也是数据文件）的示意图，可以看到叶节点包含了完整的数据记录。这种索引叫做聚集索引。因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726150531.png" alt="image-20210726150531761" style="zoom:67%;" />

这里以英文字符的ASCII码作为比较准则。聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726150545.png" alt="image-20210726150545521" style="zoom:67%;" />

了解不同存储引擎的索引实现方式对于正确使用和优化索引都非常有帮助，例如知道了InnoDB的索引实现后，就很容易明白为什么不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。再例如，用非单调的字段作为主键在InnoDB中不是个好主意，因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。

 

传统关系型数据库大部分采用B-Tree/B+Tree这样的数据结构。我们知道二叉树的查找效率是logN，同时写入更新新的节点不必移动全部节点，所以树型结构存储索引，能同时兼顾写入和查询性能。当我们不需要支持快速的更新的时候，则可以用预先排序等方式换取更小的存储空间，更快的检索速度等好处，其代价就是更新慢。



#### Elasticsearch

- Elasticsearch使用一种称为倒排索引的结构，它适用于快速的全文搜索。 

- 一个倒排索引由文档中所有不能重复词的列表构成，对于其中每个词，有一个包含它的文档列表。

- 倒排索引包含：文档的列表、文档的数量、词条在每个文档中出现的次数、出现的位置、每个文档的长度、所有文档的平均长度。

 

Elasticsearch 是通过 Lucene 的倒排索引技术实现比关系型数据库更快的过滤。特别是它对多条件的过滤支持非常好，比如年龄在 20 和 30 之间，性别为女性这样的组合查询。倒排索引很多地方都有介绍，但是其比关系型数据库的 b-tree 索引快在哪里？到底为什么快呢？

 

笼统的来说，b-tree 索引是为写入优化的索引结构。当我们不需要支持快速的更新的时候，可以用预先排序等方式换取更小的存储空间，更快的检索速度等好处，其代价就是更新慢。要进一步深入的化，还是要看一下 Lucene 的倒排索引是怎么构成的。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726150718.png" alt="image-20210726150718263" style="zoom:50%;" />

- Term（单词）：

​	一段文本经过分析器分析以后就会输出一串单词，这一个一个的就叫做Term

- Term Dictionary（单词字典）：

​	用于维护Term，可以理解为Term的集合

- Term Index（单词索引）：

​	为了更快的找到某个单词，为单词建立索引

- Posting List（倒排列表）：

​	倒排列表记录了出现过某个单词的所有文档的文档列表及单词在该文档中出现的位置信息，每条记录称为一个倒排项(Posting)。根据倒排列表，即可获知哪些文档包含某个单词。

假设有如下数据：

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726150800.png" alt="image-20210726150800673" style="zoom:67%;" />

ID是文档ID，那么建立的索引如下

Name

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726150812.png" alt="image-20210726150812384" style="zoom:67%;" />

Age

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726150827.png" alt="image-20210726150827591" style="zoom:67%;" />

Sex

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726150837.png" alt="image-20210726150837359" style="zoom:67%;" />

 可以看到，倒排索引是 per field 的，一个字段有一个自己的倒排索引。24,29 这些叫做 term，而 [1,3] 就是 posting list。Posting list 就是一个 int 的数组，存储了所有符合某个 term 的文档 id。那么什么是 term dictionary 和 term index？



**案例**

假设我们有很多个 term，比如：

 	**to,inn,tea,ada,ted,ten,adv,ada,ab**

 

如果按照这样的顺序排列，找出某个特定的 term 一定很慢，因为 term 没有排序，需要全部过滤一遍才能找出特定的 term。排序之后就变成了：

 	**ab,ada,add,adv,inn,tea,ted,ten**

 

这样我们可以用二分查找的方式，比全遍历更快地找出目标的 term。这个就是 term dictionary。有了 term dictionary 之后，可以用 logN 次磁盘查找得到目标。但是磁盘的随机读操作仍然是非常昂贵的（一次 random access 大概需要 10ms 的时间）。所以尽量少的读磁盘，有必要把一些数据缓存到内存里。但是整个 term dictionary 本身又太大了，无法完整地放到内存里。于是就有了 term index。term index 有点像一本字典的大的章节表。比如：



a 开头的 term ……………. Xxx 页

c 开头的 term ……………. Xxx 页

e 开头的 term ……………. Xxx 页

 

如果所有的 term 都是英文字符的话，可能这个 term index 就真的是 26 个英文字符表构成的了。但是实际的情况是，term 未必都是英文字符，term 可以是任意的 byte 数组。而且 26 个英文字符也未必是每一个字符都有均等的 term，比如 x 字符开头的 term 可能一个都没有，而 s 开头的 term 又特别多。实际的 term index 是一棵 trie 树（前缀树）：

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210815135510.png" alt="image-20210815135510532" style="zoom:33%;" />



例子是一个包含 "A", "to", "tea", "ted", "ten", "i", "in", 和 "inn" 的 trie 树。这棵树不会包含所有的 term，它包含的是 term 的一些前缀。通过 term index 可以快速地定位到 term dictionary 的某个 offset，然后从这个位置再往后顺序查找。再加上一些压缩技术（搜索 Lucene Finite State Transducers） term index 的尺寸可以只有所有 term 的尺寸的几十分之一，使得用内存缓存整个 term index 变成可能。整体上来说就是这样的效果。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726150949.png" alt="image-20210726150948980" style="zoom:67%;" />

Mysql 只有 term dictionary 这一层，是以 b-tree 排序的方式存储在磁盘上的。检索一个 term 需要若干次的 random access 的**磁盘**操作。而 Lucene 在 term dictionary 的基础上添加了 term index 来加速检索，term index 以树的形式缓存在**内存**中。从 term index 查到对应的 term dictionary 的 block 位置之后，再去磁盘上找 term，大大减少了磁盘的 random access 次数。



 #### 补充内容

##### logstash

Logstash是一个开源数据收集引擎，具有实时管道功能。

Logstash可以动态地将来自不同数据源的数据统一起来，并将数据标准化到你所选择的目的地进行存储。

Logstash的早期目标是搜集日志，现在它的功能已完全不只于此。任何事件类型都可以加入分析，通过输入、过滤器和输出插件进行转换。

Logstash还提供了很多原生编解码工具简化消息处理。

 

**Logstash运行原理**

1、Logstash使用管道方式进行日志的搜集处理和输出。Logstash管道有两个必需的元素，输入和输出，以及一个可选元素过滤器。输入插件从数据源那里消费数据，过滤器插件根据你的期望修改数据，输出插件将数据写入目的地。在logstash中，包括了三个阶段:输入input --> 处理filter（不是必须的） --> 输出output

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210816203601.png" alt="image-20210816203601489" style="zoom:50%;" />

2、Logstash 支持各种输入选择 ，可以在同一时间从众多常用来源捕捉事件。能够以连续的流式传输方式，轻松地从日志、指标、Web 应用、数据存储以及各种 AWS 服务采集数据

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210816203619.png" alt="image-20210816203618897" style="zoom: 50%;" />

目前，logstash主要支持的数据输入方式为：标准输入、文件输入、TCP输入、syslog输入、http_poller

抓取、kafka消息队列输入等。

 

3、过滤器：数据从源传输到存储库的过程中，Logstash 过滤器能够解析各个事件，识别已命名的字段以构建结构，并将它们转换成通用格式，以便更轻松、更快速地分析和实现商业价值。Logstash 能够动态地转换和解析数据，不受格式或复杂度的影响。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210816203634.png" alt="image-20210816203634605" style="zoom:50%;" />

目前，logstash过滤器支持的功能有：date时间处理、GROK正则捕获、dissect解析、GeoIP地址查询、Json编解码、metrics数据修改、splite拆分事件、交叉日志合并等

 

4、Logstash 提供众多输出选择，可以将数据发送到您要指定的地方，并且能够灵活地解锁众多下游用例。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210816203650.png" alt="image-20210816203650736" style="zoom:50%;" />

目前，logstash主要支持的输出方式：输出到Elasticsearch、发送email、调用系统命令执行、保存成文件、报警发送到Nagios、标准输出stdout、TCP发送数据、输出到HDFS。

 

Logstash安装

1、工作路径切换到/user/local/elasticsearch，下载logstash

wget https://artifacts.elastic.co/downloads/logstash/logstash-7.4.2.rpm

或者将logstash-7.4.2.rpm拷贝到该目录下

 

2、安装rpm包

rpm -ivh logstash-7.4.2.rpm

 

3、修改Logstash中的JVM配置文件（可选）

Logstash是一个基于Java开发的程序，需要运行在JVM中，可以通过配置jvm.options来针对JVM进行设定。比如内存的最大最小、垃圾清理机制等等。这里仅仅列举最常用的两个。

JVM的内存分配不能太大也不能太小，太大会拖慢操作系统。太小导致无法启动。

vi /etc/logstash/jvm.options

```
# logstash最大最小使用内存                          
-Xms512m                                                    
-Xmx1g

```

4、安装logstash-input-jdbc用于连接mysql数据库

/usr/share/logstash/bin/logstash-plugin install logstash-input-jdbc

如果报以下错误

![image-20210817145700261](https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210817145700.png)

添加参数再次安装

/usr/share/logstash/bin/logstash-plugin install --no-verify logstash-input-jdbc



5、将mysql-connector包上传到

注意：mysql-connector包的版本语言与数据库的版本一致，例如mysql是5那么mysql-connector包的版本也最好是5

/usr/share/logstash/logstash-core/lib/jars/



6、编辑vi /etc/logstash/conf.d/nlog.conf文件，添加以下内容

```json
input{
        stdin {
        }

        jdbc {
                jdbc_connection_string => "jdbc:mysql://192.168.101.110:3306/es1"
                jdbc_user => "root"
                jdbc_password => "root"
                #驱动类
                jdbc_driver_class => "com.mysql.jdbc.Driver"
                codec => plain { charset => "UTF-8"}

                #主键
                tracking_column => "id"
                #是否记录上次执行结果
                record_last_run => "true"
                #是否需要记录某个column 的值
                use_column_value => "true"
                #代表最后一次数据记录id的值存放的位置，必填不然启动报错
                last_run_metadata_path => "/usr/local/elasticsearch/last_id.txt"
                #是否清除 last_run_metadata_path 的记录
				#如果为真那么每次都相当于从头开始查询所有的数据库记录
                clean_run => "false"
                #是否分页
                jdbc_paging_enabled => "true"
                jdbc_page_size => "100000"
                #进行同步数据时，执行的SQL
                statement => "select * from book where id > :sql_last_value"
				#定时字段 各字段含义（由左至右）分、时、天、月、年，全部为*默认含义为每分钟都更新
                #"*/2 * * * * *"        表示每两秒同步一次
                schedule => "* * * * *"
         		#当前jdbc的类型，自定义，可以看做是当前jdbc的名字
         		type => "book"
        }
}
filter{
}
output{
        elasticsearch {
                hosts => "192.168.74.146:9200"
                #索引名字
                index => "es"
                #文档类型
                document_type => "book"
                #文档id，唯一，避免数据重复
                document_id => "%{id}"
        }
        stdout {
                #以json格式查看数据同步情况，生产环节关闭，提升效率
                codec => json_lines
        }
}


```

7、启动Logstash开始同步数据

/usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/nlog.conf

**<font color='red'>注意：</font>**

①如果出现数据库拒绝连接的错误，原因是数据库没有给root用户授权可以在非本机登录操作数据库，需要授权
执行以下两条SQL进行授权

```
UPDATE mysql.user SET HOST = '%' WHERE USER = 'root';
FLUSH PRIVILEGES;

```

②如果MySQL数据库是8，则URL上需要加上时区等连接参数

```
jdbc:mysql://192.168.101.110:3306/es1?useSSL=false&serverTimezone=UTC&characterEncoding=utf-8

```

③如果报com.mysql.jdbc.exceptions. jdbc4.MySQLNonTransientConnectionException: public Key Retrieval is not allowed 异常，可以在连接数据库的URL上加上allowPublicKeyRetrieval=true试试

```
jdbc:mysql://192.168.101.110:3306/es1?useSSL=false&serverTimezone=UTC&characterEncoding=utf-8&allowPublicKeyRetrieval=true

```

④如果还是报连接不上数据库，则先确定数据库ip、密码是否正确，如果没问题再确定Linux操作系统能否ping通MySQL所在的电脑（操作系统）



8、同步多张表

- 一张表对应一个jdbc，通过jdbc的type进行区分

- 在output中通过判断jdbc的type指定不同的index

```json
output{
	if [type] == "book" {
		elasticsearch {
		    hosts => "192.168.74.128:9200"
		    #索引名字
		    index => "es"
		    #文档类型
		    document_type => "book"
		    #文档id，唯一，避免数据重复
		    document_id => "%{id}"
	    }
	}
}

```



##### elasticsearch密码设置

1、ES主目录下的config/elasticsearch.yml文件末尾添加以下配置，开启身份认证

```
xpack.security.enabled: true
xpack.license.self_generated.type: basic
xpack.security.transport.ssl.enabled: true

```



2、启动elasticsearch



3、执行设置密码指令，开始设置密码

​	./bin/elasticsearch-setup-passwords interactive

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726095248.png" alt="image-20210726095248113" style="zoom: 40%;" />

 4、通过浏览器访问elasticsearch

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726095430.png" alt="image-20210726095430494" style="zoom: 33%;" />

 

```yaml
spring:
  elasticsearch:
    rest:
      uris: 192.168.74.146:9200
      username: elastic
      password: abc123456

```



 









# day12

### Docker简介（低 15）

Docker 是一个开源的**应用容器引擎**，基于 Go 语言 并遵从Apache2.0协议开源。

Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后**发布到任何流行的 Linux 机器上**，也可以实现虚拟化。

容器是完全使用**沙箱机制**，相互之间不会有任何接口（类似 iPhone 的 app）,更重要的是容器性能开销极低。

#### 沙箱是什么？

　　沙箱是一个虚拟系统程序，沙箱提供的环境相对于每一个运行的程序都是独立的，而且不会对现有的系统产生影响。

#### 沙箱的应用

　　（1）搭建测试环境。沙箱的应用只能访问自己的应用访问目录，而不能应用之间的资源进行共享，这样就形成了一个相对安全的机制，由于沙箱具有非常良好的独立性、隔离性，所以能够搭建一些具有高风险的软件进行测试。

　　（2）应用容器的利用，如Docker就是完全使用沙箱机制，这样使得应用组件经过Docker的封装，可以随意移植到服务上。

 

如今Docker的使用已经非常普遍，特别在一线互联网公司。使用Docker技术可以帮助企业**快速水平扩展服务**，从而到达弹性部署业务的能力。在云服务概念兴起之后，Docker的使用场景和范围进一步发展，如今在微服务架构越来越流行的情况下，微服务+Docker的完美组合，更加方便微服务架构运维部署落地。



#### 什么是Docker?

Docker 是世界领先的软件容器平台。开发人员利用 Docker 可以消除协作编码时“<font color='red'>在我的机器上可以正常工作</font>”的问题。运维人员利用 Docker 可以在隔离容器中并行运行和管理应用，获得更好的计算密度。企业利用 Docker 可以构建敏捷的软件交付管道，以更快的速度、更高的安全性和可靠的信誉为 Linux 和 Windows Server 应用发布新功能。

 

Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。它是目前最流行的 Linux 容器解决方案。Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。**有了 Docker，就不用担心环境问题。**

 

#### 为什么要使用Docker

容器除了运行其中应用外，基本不消耗额外的系统资源，使得应用的性能很高，同时系统的开销尽量小。传统虚拟机方式运行 10 个不同的应用就要起 10 个虚拟机，而Docker 只需要启动 10 个隔离的应用即可。

具体说来，Docker 在如下几个方面具有较大的优势。

 

1、更快速的交付和部署

对开发和运维人员来说，最希望的就是**一次创建或配置，可以在任意地方正常运行**。

开发者可以使用一个标准的镜像来构建一套开发容器，开发完成之后，运维人员可以直接使用这个容器来部署代码。 Docker 可以快速创建容器，快速迭代应用程序，并让整个过程全程可见，使团队中的其他成员更容易理解应用程序是如何创建和工作的。 **Docker 容器很轻很快！容器的启动时间是秒级的，大量地节约开发、测试、部署的时间**。

 

2、更高效的虚拟化

Docker 容器的运行不需要额外的 hypervisor（**虚拟机器监视器（英语：virtual machine monitor，缩写为 VMM），是用来建立与执行虚拟机器的软件、固件或硬件**）支持，它是内核级的虚拟化，因此可以实现更高的性能和效率。

 

3、更轻松的迁移和扩展

Docker 容器几乎可以在任意的平台上运行，包括物理机、虚拟机、公有云、私有云、个人电脑、服务器等。 这种兼容性可以让用户把一个应用程序从一个平台直接迁移到另外一个。

 

4、更简单的管理

使用 Docker，只需要小小的修改，就可以替代以往大量的更新工作。所有的修改都以增量的方式被分发和更新，从而**实现自动化并且高效的管理**。



#### Docker vs VM

从下图可以看出，VM是一个运行在宿主机之上的完整的操作系统，VM运行自身操作系统会占用较多的CPU、内存、硬盘资源。Docker不同于VM，只包含应用程序以及依赖库，基于libcontainer运行在宿主机上，并处于一个隔离的环境中，这使得Docker更加轻量高效，启动容器只需几秒钟之内完成。由于Docker轻量、资源占用少，使得Docker可以轻易的应用到构建标准化的应用中。但Docker目前还不够完善，比如隔离效果不如VM，共享宿主机操作系统的一些基础库等；网络配置功能相对简单，主要以桥接方式为主；查看日志也不够方便灵活。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726151658.png" alt="image-20210726151658501" style="zoom:67%;" />

Docker 在容器的基础上，进行了进一步的封装，从文件系统、网络互联到进程隔离等等，极大的简化了容器的创建和维护。使得 Docker 技术比虚拟机技术更为轻便、快捷。

作为一种新兴的虚拟化方式，Docker 跟传统的虚拟化方式相比具有众多的优势。Docker 容器的启动可以在秒级实现，这相比传统的虚拟机方式要快得多；Docker 对系统资源的利用率很高，一台主机上可以同时运行数千个 Docker 容器。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726151713.png" alt="image-20210726151713252" style="zoom:67%;" />

#### Docker的应用场景

在微服务的大背景下，一台物理机或者云主机可能要运行很多应用。应用必须依赖于开发环境。当我们遇到拓展物理机、云主机、应用迁移等场景，必然要重新搭建开发环境。这时，虚拟化技术就很好地保证环境一致、配置一致，并且让你更高效地迁移应用。

Docker正是应对这种场景的虚拟化技术。例如java，只要机器上安装了JVM，一份代码到处运行。应用好比java，只要机器上安装docker，我们事先保存的镜像可以到处运行。这些镜像可以是nginx、php、mysql、数据仓库等，无论你的主机从ubuntu迁移到centos，还是windows迁移linux，**只要主机安装了docker，就能迅速地部署好新环境，并且保持环境、配置一致**。

 

#### Docker 的优点

1、简化程序：

Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化。Docker改变了虚拟化的方式，使开发者可以直接将自己的成果放入Docker中进行管理。方便快捷已经是 Docker的最大优势，过去需要用数天乃至数周的任务，在Docker容器的处理下，只需要数秒就能完成。

2、避免选择恐惧症：

如果你有选择恐惧症，还是资深患者。Docker帮你打包你的纠结！比如 Docker 镜像；Docker 镜像中包含了运行环境和配置，所以 Docker 可以简化部署多种应用实例工作。比如 Web 应用、后台应用、数据库应用、大数据应用比如 Hadoop 集群、消息队列等等都可以打包成一个镜像部署。

3、节省开支：

一方面，云计算时代到来，使开发者不必为了追求效果而配置高额的硬件，Docker 改变了高性能必然高价格的思维定势。Docker 与云的结合，让云空间得到更充分的利用。不仅解决了硬件管理的问题，也改变了虚拟化的方式。

 

### Docker 安装（低 15）

1、Docker 要求 CentOS 系统的内核版本高于 3.10 ，查看本页面的前提条件来验证你的CentOS 版本是否支持 Docker

uname -r

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726151905.png" alt="image-20210726151905573" style="zoom: 67%;" />

2、卸载老版本的docker（**如果安装过**）

sudo yum remove docker  docker-common docker-selinux docker-engine

如果执行此命令时出现以下图片上的错误，请按照图片上的第二个框操作

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726151955.png" alt="image-20210726151955642" style="zoom:67%;" />

这里该命令是用于修改文件用户组合用户组

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726152014.png" alt="image-20210726152014332" style="zoom:67%;" />

3、使用以上命令可能卸载不干净，我们先查看一下当前安装了哪些与docker相关的包

​	yum list installed | grep docker

如果有则使用以下命令删除这些包

​	yum -y remove docker...



4、通过xshell将container-selinux-2.95-2.el7_6.noarch.rpm和docker-ce-18.06.3.ce-3.el7.x86_64.rpm上传到虚拟机上

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726152048.png" alt="image-20210726152048548" style="zoom:67%;" />

5、切换到root用户，安装container-selinux-2.95-2.el7_6.noarch.rpm

rpm -ih container-selinux-2.95-2.el7_6.noarch.rpm

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726152100.png" alt="image-20210726152100584" style="zoom:67%;" />

如果报

```
错误:依赖检测失败:
policycoreutils-python被container-selinux-2:2.95-2.el7_6.noarch需要
```

使用指令：    

```
yum install policycoreutils-python
```

 进行安装

6、安装docker-ce-18.06.3.ce-3.el7.x86_64.rpm

rpm -ih docker-ce-18.06.3.ce-3.el7.x86_64.rpm

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726152117.png" alt="image-20210726152117740" style="zoom:67%;" />

如果报

```
错误:依赖检测失败:
libltdl.so.7()(64bit）被docker-ce-18.06.3.ce-3.el7.x86_64需要
```

使用指令：

```
wget http://mirror.centos.org/centos/7/os/x86_64/Packages/libtool-ltdl-2.4.2-22.el7_3.x86_64.rpm
rpm -ivh libtool-ltdl-2.4.2-22.el7_3.x86_64.rpm   
```

进行安装

7、查看dock版本，出现以下信息表示docker安装成功

docker -v

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726152133.png" alt="image-20210726152133896" style="zoom:67%;" />

8、启动并加入开机启动

sudo systemctl start docker

sudo systemctl enable docker

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726152201.png" alt="image-20210726152201315" style="zoom:67%;" />



### Docker三大核心概念（中 15）

 #### Docker 包括三个基本概念

- 镜像（Image）				

  是特殊的文件系统，他包含程序、配置、资源等

- 容器（Container）			

  镜像的实例。就像是类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。

- 仓库（Repository）			

  用于保存镜像的服务。

理解了这三个概念，就理解了 Docker 的整个生命周期。



### Docker阿里云镜像加速器配置（低 15）

注册阿里云账号，并在产品列表中找到弹性计算->容器镜像服务ACR

<img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210726152858662.png" alt="image-20210726152858662" style="zoom:33%;" />

 选择“管理控制台”

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726153018.png" alt="image-20210726153017761" style="zoom: 33%;" />

找到“镜像工具"->"CentOS"，赋值下图红框中的内容

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726153507.png" alt="image-20210726153507685" style="zoom: 33%;" />



编辑配置文件

vi /etc/docker/daemon.json

添加以下内容

```json
{
  "registry-mirrors": ["https://zypktutb.mirror.aliyuncs.com"]
}
```



重启docker服务

sudo systemctl daemon-reload

sudo systemctl restart docker



### Docker拉取tomcat镜像并部署应用（低 30）

Docker拉取tomcat镜像并部署应用

#### 常见指令

- docker search 镜像名		搜索镜像

- docker pull 镜像名             通过名字拉取镜像
- docker load -i xxx.tar        通过压缩文件导入镜像
- docker save -o xxx.tar 镜像名:tag       将镜像导出为压缩文件
- docker images                   查看本地仓库中的镜像
- docker rmi -f  imageid      通过镜像id删除镜像



#### 项目部署（war）

1、创建并启动tomcat容器

​	docker run -d -p 8081:8080 --name tomcat1 tomcat

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726155159.png" alt="image-20210726155159432" style="zoom:50%;" />

​	docker ps   		查看运行中的容器

​	docker ps -a	   查看所有容器



2、利用xshell将需要部署的项目war上传到Linux中任意位置，然后切换到该目录下



3、输入以下命令将war包拷贝到tomcat容器的webapps目录下

​	docker cp xxx.war tomcat1:/usr/local/tomcat/webapps

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726155222.png" alt="image-20210726155222593" style="zoom:50%;" />

4、开启指定端口

​	firewall-cmd --zone=public --add-port=8081/tcp --permanent

​	systemctl restart firewalld.service



5、通过外部浏览器访问

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726155324.png" alt="image-20210726155324597" style="zoom:50%;" />





### Docker应用（高 20）

部署SpringBoot项目到Docker

1、将springboot项目打包成jar包，并上传到Linux任意文件夹



2、在该文件夹下创建Dockerfile文件，添加以下内容

```
FROM java:8
MAINTAINER "xiangwei"
VOLUME /tmp
ADD docker-1.0.jar app.jar
EXPOSE 8080
ENTRYPOINT ["java","-jar","/app.jar"]
```

参数解释：

1. 从docker仓库获取jdk作为我们项目的容器
2. MAINTAINER 作者/维护者
3. VOLUME指向了一个/tmp的目录，由于Spring Boot使用内置的Tomcat容器，Tomcat默认使用/tmp作为工作目录。效果就是在主机的/usr/local/apps目录下创建了一个临时文件，并连接到容器的/tmp。
4. 项目的docker-1.0.jar 作为 app.jar添加到容器。
5. ENTRYPOINT 执行项目 app.jar。



3、通过Dockefile生成镜像

docker build -t 镜像名:tag .

**<font color='red'>注意：指令最后有一个  .  表示Dockerfile在当前目录下</font>**

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726210834.png" alt="image-20210726210834659" style="zoom:50%;" />



4、执行完毕之后会执行docker images查看镜像

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726210606.png" alt="image-20210726210606119" style="zoom:50%;" />



5、执行以下指令启动镜像（项目）

​	docker run -d -p 8080:8080 --name project docker-test

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726210905.png" alt="image-20210726210905522" style="zoom:50%;" />



6、打开浏览器访问项目

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726210944.png" alt="image-20210726210944481" style="zoom:50%;" />

<font color='red'>如果看不到数据，可以使用 docker logs 容器名，查看日志信息</font>





### docker实现Tomcat集群

#### Tomcat集群能带来什么：

- 提高服务的性能，例如计算处理能力、并发能力等，以及实现服务的高可用性

- 提供项目架构的横向扩展能力，增加集群中的机器就能提高集群的性能

 

#### Nginx

- Nginx是一个高性能的Http和反向代理服务器，也是一个IMAP/POP3/SMTP服务器（电子邮件代理）。

- Nginx可作为负载均衡服务器，可作为Http代理服务器对外进行服务。

- 处理静态文件，索引文件以及自动索引;打开文件描述符缓冲。

- 模块化的结构。

- 在国内，很多著名的网站都用Nginx作为网页服务器，如百度、京东、新浪、网易、腾讯、淘宝等。

 

**反向代理**（Reverse Proxy）方式是指以代理服务器来接受Internet上的连接请求，然后将请求转发给内部网络上的服务器；并将从服务器上得到的结果返回给Internet上请求连接的客户端，此时代理服务器对外就表现为一个服务器

 

##### Nginx的功能

- 处理静态文件，索引文件以及自动索引；

- 反向代理加速(无缓存)，简单的负载均衡和容错；

- 基于IP 和名称的虚拟主机服务；

- 模块化的结构。同一个 proxy的多个子请求并发处理；

- IMAP/POP3/SMTP代理服务。

- 基于客户端 IP 地址和 HTTP 基本认证的访问控制；

- 支持 FLV （Flash 视频）；



 

####  集群的分类 

集群主要分成三大类：高可用集群(High Availability Cluster/HA)， 负载均衡集群(Load Balance Cluster)，高性能计算集群(High Performance Computing Cluster/HPC) 

（1） 高可用集群(High Availability Cluster/HA)：一般是指当集群中有某个节点失效的情况下，其上的任务会自动转移到其他正常的节点上。还指可以将集群中的某节点进行离线维护再上线，该过程并不影响整个集群的运行。常见的就是2个节点做 成的HA集群，有很多通俗的不科学的名称，比如"双机热备", "双机互备", "双机"，高可用集群解决的是保障用户的应用程序持续对外提供服务的能力。 

 

（2） 负载均衡集群(Load Balance Cluster)：负载均衡集群运行时一般通过一个或者多个前端负载均衡器将工作负载分发到后端的一组服务器上，从而达到将工作负载分发。这样的计算机集群有时也被称为服务器群（Server Farm）。一般web服务器集群、数据库集群 和应用服务器集群都属于这种类型。这种集群可以在接到请求时，检查接受请求较少，不繁忙的服务器，并把请求转到这些服务器 上。从检查其他服务器状态这一点上 看，负载均衡和容错集群很接近，不同之处是数量上更多。 

 

（3） 高性能计算集群(High Performance Computing Cluster/HPC)：高性能计算集群采用将计算任务分配到集群的不同计算节点而提高计算能力，因而主要应用在科学计算领域。这类集群致力于提供单个计算机所不能提供的强大的计算能力

 

#### 负载均衡

当一台服务器的处理能力、存储空间不足时，不要企图去换更强大的服务器，对大型网站而言，不管多么强大的服务器，都满足不了网站持续增长的业务需求。这种情况下，更恰当的做法是增加一台服务器分担原有服务器的访问及存储压力。扩展网络设备和服务器的带宽、增加吞吐量、加强网络数据处理能力、提高网络的灵活性和可用性。其意思就是分摊到多个操作单元上进行执行。

在这里我们只阐述对请求的的负载均衡。

通过负载均衡调度服务器，将来自浏览器的访问请求分发到应用服务器集群中的任何一台服务器上，如果有更多的用户，就在集群中加入更多的应用服务器，使应用服务器的负载压力不再成为整个网站的瓶颈。

理论上的JavaWeb项目结构应该是这样的

 <img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220531170927.png" alt="image-20220531170927496" style="zoom: 67%;" />

Nginx和Tomcat对请求负载均衡的方案

整体思想方向：前端部署nginx服务器，后端部署tomcat应用。用户访问nginx服务器，对于静态资源nginx服务器直接返回到浏览器展示给用户，对动态资源的请求被nginx服务器转发（分配）到tomcat应用服务器，tomcat应用服务器将处理后得到的数据结构返回给nginx服务器，然后返回到浏览器展示给用户。

注意：在这里Tomcat应用服务器就是Java应用，可以理解为后台

 <img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220531170946.png" alt="image-20220531170946580" style="zoom: 67%;" />

Nginx作为反向代理服务器，可以对后台的多台Tomcat服务器负载均衡，也可以让Nginx处理静态页面的请求、Tomcat处理JSP页面请求，以此达到动静分离的目的

 

#### Tomcat集群实现方式：

Tomcat集群的实现方式有多种，最简单的就是通过Nginx负载进行请求转发来实现



实现步骤

注：在执行下列的操作过程中可能会出现“IPv4 forwarding is disabled. Networking will not work”错误，解决方法为：

```
1、编辑 vi /etc/sysctl.conf
2、在文件末尾添加 net.ipv4.ip_forward=1
3、重启network服务 systemctl restart network
```

1.在宿主机上安装docker并启动 

 

2.拉取（导入）Nginx、Tomcat镜像

 

3.在当前用户主目录下创建nginx.conf配置文件，添加以下内容

```
#指定Nginx Worker进程运行用户以及用户组，默认由nobody账号运行
user  root;
#指定Nginx要开启的进程数。每个Nginx进程平均耗费10M~12M内存。建议指定和CPU的数量一致即可
worker_processes  1;
#error_log是个主模块指令，用来定义全局错误日志文件。日志输出级别有debug、info、notice、warn、error、crit可供选择，其中，debug输出日志最为最详细，而crit输出日志最少
error_log  /var/log/nginx/error.log warn;
#用来指定进程pid的存储文件位置
pid        /var/run/nginx.pid;
 
#events事件指令是设定Nginx的工作模式及连接数上限
events {
    #用于定义Nginx每个进程的最大连接数，默认是1024
    worker_connections  1024;
}
 
#HTTP服务器配置
http {
    #主机配置
    server {
                listen 80;   #监听80端口
                #URL匹配配置
                location  / {
                        proxy_pass http://blance;
                }
    }
    #upstream 通过server指令指定后端服务器的IP地址和端口，同时还可以设定每个后端服务器在负载均衡调度中的状态
    upstream blance{
            server 192.168.8.200:8081;
            server 192.168.8.200:8082;
            server 192.168.8.200:8083;
    }
    #实现对配置文件所包含的文件的设定，可以减少主配置文件的复杂度
include       /etc/nginx/mime.types;
#设定默认类型为二进制流，也就是当文件类型未定义时使用这种方式，例如在没有配置PHP环境时，Nginx是不予解析的，此时，用浏览器访问PHP文件就会出现下载窗口
    default_type  application/octet-stream;
    #用于指定Nginx日志的输出格式。main为此日志输出格式的名称
    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';
 
    access_log  /var/log/nginx/access.log  main;
    #用于开启高效文件传输模式
    sendfile        on;
    #tcp_nopush     on;
    #设置客户端连接保持活动的超时时间。在超过这个时间之后，服务器会关闭该连接
    keepalive_timeout  65;
 
    #gzip  on;
 
    include /etc/nginx/conf.d/*.conf;
}
```

4、创建、启动nginx容器，并指定将自定义的的配置文件挂载到nginx容器中，使配置生效

docker run -p 82:80 --name nginx1 -v /home/xiangwei/nginx.conf:/etc/nginx/nginx.conf -d nginx

 注：

- 停止容器运行

  docker stop 容器ID

- 使用docker restart命令来重启一个容器

  docker restart 容器ID

- 进入容器

  docker exec -it 容器ID bash

- 退出容器

  exit

- 删除容器

  docker rm 容器ID



5、输入以下命令创建、启动多个tomcat容器

 ```
docker run -d -p 8081:8080 --name tomcat1 tomcat
docker run -d -p 8082:8080 --name tomcat2 tomcat
docker run -d -p 8083:8080 --name tomcat3 tomcat

 ```

6、利用xshell将需要部署的项目war上传到Linux中任意位置，然后切换到该目录下

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220531171209.png" alt="image-20220531171209314" style="zoom:67%;" />

 输入以下命令分别将war包拷贝到tomcat容器的webapps目录下

```
docker cp HelloTomcat.war tomcat1:/usr/local/tomcat/webapps
docker cp HelloTomcat.war tomcat2:/usr/local/tomcat/webapps
docker cp HelloTomcat.war tomcat3:/usr/local/tomcat/webapps

```

7、打开Linux内置浏览器，在地址栏分别输入以下内容，检查项目是否部署完毕

```
http://localhost:8081/HelloTomcat/
http://localhost:8082/HelloTomcat/
http://localhost:8083/HelloTomcat/

```

出现项目首页表示部署完毕，如图：

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220531171248.png" alt="image-20220531171248424" style="zoom:67%;" />

 8、开启指定端口80、82、8081、8082、8083

```
firewall-cmd --zone=public --add-port=80/tcp --permanent
firewall-cmd --zone=public --add-port=82/tcp --permanent
firewall-cmd --zone=public --add-port=8081/tcp --permanent
firewall-cmd --zone=public --add-port=8082/tcp --permanent
firewall-cmd --zone=public --add-port=8083/tcp --permanent
#重启防火墙生效
systemctl restart firewalld.service

```

9、在Linux内置浏览器地址栏中输入以下内容检查nginx是否成功代理tomcat服务

```
http://192.168.8.200:82/HelloTomcat/

```

出现项目主页表示配置成功

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220531171322.png" alt="image-20220531171322241" style="zoom:50%;" />

 10、现在可以在宿主机浏览器的地址栏中输入同样的地址，看看是否能正常访问

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220531171334.png" alt="image-20220531171334079" style="zoom:50%;" />



### 反向代理服务器的工作原理

反向代理服务器通常有两种模型，它可以作为内容服务器的替身，也可以作为内容服务器集群的负载均衡器。

1、作内容服务器的替身           

如果内容服务器具有必须保持安全的敏感信息，如信用卡号数据库，可在防火墙外部设置一个代理服务器作为内容服务器的替身。当外部客户机尝试访问内容服务器时，会将其送到代理服务器。实际内容位于内容服务器上，在防火墙内部受到安全保护。代理服务器位于防火墙外部，在客户机看来就像是内容服务器。

 

​	当客户机向站点提出请求时，请求将转到代理服务器。然后，代理服务器通过防火墙中的特定通路，将客户机的请求发送到内容服务器。内容服务器再通过该通道将结果回传给代理服务器。代理服务器将检索到的信息发送给客户机，好像代理服务器就是实际的内容服务器。如果内容服务器返回错误消息，代理服务器会先行截取该消息并更改标头中列出的任何 URL，然后再将消息发送给客户机。如此可防止外部客户机获取内部内容服务器的重定向 URL。

 

​	这样，代理服务器就在安全数据库和可能的恶意攻击之间提供了又一道屏障。与有权访问整个数据库的情况相对比，就算是侥幸攻击成功，作恶者充其量也仅限于访问单个事务中所涉及的信息。未经授权的用户无法访问到真正的内容服务器，因为防火墙通路只允许代理服务器有权进行访问。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220531171352.png" alt="image-20220531171351954" style="zoom:67%;" />

可以配置防火墙路由器，使其只允许特定端口上的特定服务器有权通过防火墙进行访问，而不允许其他任何机器进出

 

2、作为内容服务器的负载均衡器

可以在一个组织内使用多个代理服务器来平衡各 Web 服务器间的网络负载。在此模型中，可以利用代理服务器的高速缓存特性，创建一个用于负载平衡的服务器池。此时，代理服务器可以位于防火墙的任意一侧。如果 Web 服务器每天都会接收大量的请求，则可以使用代理服务器分担 Web 服务器的负载并提高网络访问效率。

 

​	对于客户机发往真正服务器的请求，代理服务器起着中间调停者的作用。代理服务器会将所请求的文档存入高速缓存。如果有不止一个代理服务器，DNS 可以采用“循环复用法”选择其 IP 地址，随机地为请求选择路由。客户机每次都使用同一个 URL，但请求所采取的路由每次都可能经过不同的代理服务器。

 

​	可以使用多个代理服务器来处理对一个高用量内容服务器的请求，这样做的好处是内容服务器可以处理更高的负载，并且比其独自工作时更有效率。在初始启动期间，代理服务器首次从内容服务器检索文档，此后，对内容服务器的请求数会大大下降。

 

3、负载均衡策略

轮询					默认方式

weight				权重方式

ip_hash				依据ip分配方式

least_conn			最少连接方式

fair（第三方）		响应时间方式

url_hash（第三方）		依据URL分配方式

 

负载均衡用于从“upstream”模块定义的后端服务器列表中选取一台服务器接受用户的请求。一个最基本的upstream模块是这样的，模块内的server是服务器列表

```
upstream blance{
    server 192.168.8.200:8081;
    server 192.168.8.200:8082;
    server 192.168.8.200:8083;
}

```

3.1、轮询

　　最基本的配置方法，上面的例子就是轮询的方式，它是upstream模块默认的负载均衡默认策略。每个请求会按时间顺序逐一分配到不同的后端服务器。

注意：

- 在轮询中，如果服务器down掉了，会自动剔除该服务器。

- 缺省配置就是轮询策略。

- 此策略适合服务器配置相当，无状态且短平快的服务使用。

 

3.2、weight

　　权重方式，在轮询策略的基础上指定轮询的几率。例子如下：

```
upstream blance{
    server 192.168.8.200:8081  weight=2;
    server 192.168.8.200:8082  backup;
    server 192.168.8.200:8083  max_fails=3 fail_timeout=20s;
}

```



fail_timeout	与max_fails结合使用。

max_fails		设置在fail_timeout参数设置的时间内最大失败次数，如果在这个时间内，所有针对该服务器的请

求都失败了，那么认为该服务器会被认为是停机了，

fail_time		服务器会被认为停机的时间长度,默认为10s。

backup		标记该服务器为备用服务器。当主服务器停止时，请求会被发送到它这里。

down			标记服务器永久停机了。

在该例子中，weight参数用于指定轮询几率，weight的默认值为1,；weight的数值与访问比率成正比，比如8081端口服务器被访问的几率为其他服务器的两倍。

注意：

- 权重越高分配到需要处理的请求越多。

- 此策略可以与least_conn和ip_hash结合使用。

- 此策略比较适合服务器的硬件配置差别比较大的情况。

 

3.3、ip_hash

　　指定负载均衡器按照基于客户端IP的分配方式，这个方法确保了相同的客户端的请求一直发送到相同的服务器，以保证session会话。这样每个访客都固定访问一个后端服务器，可以解决session不能跨服务器的问题。

```
upstream blance{
    ip_hash;
    server 192.168.8.200:8081  weight=2;
    server 192.168.8.200:8082  backup;
    server 192.168.8.200:8083  max_fails=3 fail_timeout=20s;
}

```

注意：

- 在nginx版本1.3.1之前，不能在ip_hash中使用权重（weight）。

- ip_hash不能与backup同时使用。

- 此策略适合有状态服务，比如session。

- 当有服务器需要剔除，必须手动down掉。



3.4、least_conn

　　把请求转发给连接数较少的后端服务器。轮询算法是把请求平均的转发给各个后端，使它们的负载大致相同；但是，有些请求占用的时间很长，会导致其所在的后端负载较高。这种情况下，least_conn这种方式就可以达到更好的负载均衡效果。

```
upstream blance{
    least_conn;
    server 192.168.8.200:8081  weight=2;
    server 192.168.8.200:8082  backup;
    server 192.168.8.200:8083  max_fails=3 fail_timeout=20s;
}

```



注意：

·此负载均衡策略适合请求处理时间长短不一造成服务器过载的情况

 

以上便是4种负载均衡策略的实现方式，其中除了轮询和轮询权重外，都是Nginx根据不同的算法实现的。在实际运用中，需要根据不同的场景选择性运用，大都是多种策略结合使用以达到实际需求。

 

### 正向代理

正向代理，意思是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端才能使用正向代理。当你需要把你的服务器作为代理服务器的时候，可以用Nginx来实现正向代理，但是目前Nginx有一个问题，那么就是不支持HTTPS。

```
resolver 114.114.114.114 8.8.8.8;
server {
	resolver_ timeout 5s;
	listen 81;
	access_log e:\ wwwroot \proxy.access.log;
	error_log  e: \wwwroot \proxy . error. log;
	location / {
		proxy_pass http://$host$request_uri;
	}
}

```



resolver是配置正向代理的DNS服务器，listen 是正向代理的端口，配置好了就可以在ie上面或者其他代理插件上面使用服务器ip+端口号进行代理了。

 

正向代理和反向代理的区别：

1、正向代理：类似我们想要访问国外的Google服务器，但是由于访问限制，我们需要找一个代理去访问。换句话说，客户端明确知道要访问的服务器的地址，客户端把请求发送给代理，代理转发给服务器，服务器把响应传给代理，最后代理把响应传给客户端。我们可以看到客户端知道服务器是谁，但是服务器并不知道客户端是谁，这就是正向代理，隐藏了客户端的真实信息。

 

2、反向代理：类似我们访问淘宝，由于访问量巨大，淘宝会使用许多台服务器（就是分布式服务器）来支持，但是每个客户端的请求到底由哪一台服务器来响应，我们需要一个代理来决定。换句话说，客户端并不知道要把请求发送给哪一台服务器，但是知道发送给哪一个代理，然后代理依据规则（响应时间，负载均衡等）决定把请求转发给哪一台服务器。可以看到，客户端并不知道他访问的服务器是谁，这就是反向代理，隐藏了服务器的真实信息。



Nginx动静分离

重新认识Tomcat

·Tomcat属于轻量级的Web应用服务器，在中小型系统和并发访问用户不是很多的的场合下被普遍使用。

·Tomcat实际上是用来运行JSP页面和Servlet的，独立的Servlet容器是Tomcat的默认模式，可以理解为Tomcat只处理动态部分。

·实际上Tomcat是Apache服务器项目的一个扩展组件，不过它是独立运行的。

·当配置正确时，Apache 为HTML页面服务，而Tomcat 实际上运行JSP 页面和Servlet。

·Tomcat具有处理HTML页面的功能，但是它对HTML页面的处理能力远不如Apache。

 

　　以上列举了Tomcat这个Web应用服务器的不足之处以及它的侧重点，因为它是Apache服务器的一个独立扩展插件，所以要将Apache服务器和Tomcat应用服务器一起使用才能取之长处避之短处。

 

　　但是随着Nginx服务器的袭来，Apache服务器的主流功能都可被Nginx服务器代替，而且Nginx服务器的性能更好。Nginx对请求的处理是异步型的，非阻塞的；而Apache对请求的处理是阻塞型，非异步型的；在高并发情况下Nginx能保持地资源低消耗高性能高度模块化，而且Nginx的配置文件相对Apache更为简单。

 

### 动静分离

动态资源(jsp、ftl、thymeleaf)与静态资源(js、css、img)分开部署

 

网站通常会采用web服务器（如Nginx、apache）与应用服务器（如tomcat、jboss、jetty等）组合提供服务，这样做的优势是什么？

1.功能侧重点不同。

web服务器性能显著，如Nginx可以支撑5万并发连接；对js、css、图片等静态文件有较强的处理能力；可按照预定规则过滤url以及URL的重定向；可作为软负载提供负载均衡服务等等

应用服务器相对笨重，更多的是用于处理较复杂的业务逻辑，涉及的技术框架也较多，如struct、spring、ibatis、jdbc等

 

2.安全性角度。

为了网站的安全性，通常会关闭一些不必要端口只开放80端口，以减少攻击。web服务器通常是监听80端口，根据客户端请求的URL来判断是否需要重定向到应用服务器

 

#### 利用location实现动静分离

location语法规则

location [=|~|~*|^~] /uri/ {

​    ····· 

}

 

location 后接的匹配规则含义

=   	开头表示精确匹配

location = /hello/{

\#localhost:80/hello/xxx

}

^~   开头表示uri以某个常规字符串开头，理解为匹配 url路径即可。nginx不对url做编码，因此请求为/static/20%/aa，

可以被规则^~ /static/ /aa匹配到（注意是空格）

location ^~ /hello/{

\#localhost:80/hello/xxx

}

 

~   	开头表示区分大小写的正则匹配

location ~ /hello/{

\#localhost:80/hello/xxx

}

 

~*   开头表示不区分大小写的正则匹配

!~   区分大小写不匹配的正则

location !~ /hello/{

\#localhost:80/abc/xxx

}

 

!~*  	不区分大小写不匹配的正则

/   	通用匹配，任何请求都会匹配到

 

当我们有多个 location 配置的情况下，其匹配顺序为：

首先匹配 "="，其次匹配 "^~", 其次是按文件中顺序的正则匹配，最后是交给 "/" 通用匹配。

如果存在多个location，精确匹配应该放在前面

location = /hello/{

\#localhost:80/hello/xxx

}

。。。

location / {   #/表示所有的请求

​        proxy_pass http://abc;

​     }

 

当有匹配成功时候，停止匹配，按当前匹配规则处理请求。

 

比如现在同时存在如下所示匹配规则

location = / {

  \#规则A

}

location = /login {

  \#规则B

}

location ^~ /static/ {

  \#规则C

}

location ~ \.(gif|jpg|png|js|css)$ {

  \#规则D

}

location ~* \.png$ {

  \#规则E

}

location !~ \.xhtml$ {

  \#规则F

}

location !~* \.xhtml$ {

  \#规则G

}

location / {

  \#规则H

}

那么产生的效果如下

·访问根目录/  比如 http://localhost/  将匹配规则A

·访问 http://localhost/login  将匹配规则B，http://localhost/register 则匹配规则H

·访问 http://localhost/static/a.html  将匹配规则C

·访问 http://localhost/a.gif, http://localhost/b.jpg  将匹配规则D和规则E，但是规则D顺序优先，规则E不起作用，而 

http://localhost/static/c.png 则优先匹配到规则C

·访问 http://localhost/a.PNG  则匹配规则E，而不会匹配规则D，因为规则E不区分大小写

·访问 http://localhost/a.xhtml  不会匹配规则F和规则G，http://localhost/a.XHTML不会匹配规则G，因为不区分大小写。

规则F，规则G属于排除法，符合匹配规则但是不会匹配到，所以想想看实际应用中哪里会用到

·访问 http://localhost/category/id/1111  则最终匹配到规则H，因为以上规则都不匹配，这个时候应该是nginx转发请求给

后端应用服务器，比如FastCGI（php），tomcat（jsp），nginx作为方向代理服务器存在。

 

所以在实际应用中，至少需要有三个匹配规则定义，如下：

\# 直接匹配网站根，通过域名访问网站首页比较频繁，使用这个会加速处理，官网如是说。

\# 这里是直接转发给后端应用服务器了，也可以是一个静态首页

\# 第一个必选规则

location = / {

  proxy_pass http://localhost:8080/index

}

 

\# 第二个必选规则是处理静态文件请求，这是 nginx 作为 http 服务器的强项

\# 有两种配置模式，目录匹配或后缀匹配,任选其一或搭配使用

location ^~ /static/ {

  root /webroot/static/;

}

location ~* \.(gif|jpg|jpeg|png|css|js)$ {

  root /webroot/res/;

}

 

\# 第三个规则就是通用规则，用来转发动态请求到后端应用服务器

\# 非静态文件请求就默认是动态请求，自己根据实际把握

\# 毕竟目前的一些框架的流行，带 .php, .jsp 后缀的情况很少了

location / {

  proxy_pass http://localhost:8080/

}

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220531171656.png" alt="image-20220531171656203" style="zoom:67%;" />



#### 实现步骤

1、准备一个dynamic web项目，项目结构如下：

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220531171711.png" alt="image-20220531171711842" style="zoom:67%;" />

在webcontent下创建index.jsp文件，添加以下内容

```jsp
<body>
	<%=request.getServerName()%>:<%=request.getServerPort()%><br>
	<img alt="" src="images/1.jpg">
</body>

```

在webcontent下创建images文件夹，并放入一张图片

 

运行程序测试一下

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220531171738.png" alt="image-20220531171738434" style="zoom:50%;" />

2、将项目到处为war包，并利用xshell将上传到Linux上

 

将war包部署到三台Tomcat上，并进行单独测试

 

创建/home/xiangwei/static目录，将该目录作为静态资源的存放目录，并在static目录下创建images目录用于存放图片1.jpg，如果想要存放css、js、html等文件，同理可以在static下创建对应的目录，并在对应的目录下放对应的文件

 

3、修改nginx.conf文件，增加静态资源的配置

```
http {
    include /etc/nginx/mime.types; #非常重要，不然css、js等无法被浏览器解析
    server {
                listen 80;   #监听80端口
                location ~ .*\.(html|htm|gif|jpg|jpeg|bmp|png|js|css)$ {
                        root /home/xiangwei/static;
                }
                location  / {
                        proxy_pass http://blance;
                }
    }
    upstream blance{
            server 192.168.74.132:8081;
            server 192.168.74.132:8082;
            server 192.168.74.132:8083;
    }
}

```

保存退出，执行以下命令开启nginx容器（为一条指令）

docker run -p 80:80 --name nginx1 -v /home/xiangwei/nginx.conf:/etc/nginx/nginx.conf -d nginx

 

此时打开浏览器通过80端口访问index.jsp文件，可以看到图片并未加载出来

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220531171805.png" alt="image-20220531171805171" style="zoom:50%;" />



在终端上输入：docker logs nginx1可以查看到nginx的日志信息，日志信息显示/home/xiangwei/HelloTomcat/images/1.jpg不存在

![image-20220531171817223](https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220531171817.png)

同时可以看到图片的路径由root+项目名/页面图片路径组成，而此路径在Linux下并不存在，图片的实际路径应该是/home/xiangwei/static/1.jpg，解决办法就是在创建nginx容器时将/home/xiangwei/static/HelloTomcat（不用包含images目录）路径挂载到/home/xiangwei/static下

 

停止、删除nginx1容器，并重新创建

 

输入以下指令，指定挂载目录

docker run -p 80:80 --name nginx1 

-v /home/xiangwei/nginx.conf:/etc/nginx/nginx.conf 

-v /home/xiangwei/static/:/home/xiangwei/static/HelloTomcat/ -d nginx

刷新浏览器此时就可以看到图片了（不用管图片中的82端口，截图的问题）

![image-20220531171829361](https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220531171829.png)



在static下创建html文件，并放入一个html文件

![image-20220531171840785](https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220531171840.png)

利用浏览器访问该文件

 

如果war包中没有指定index.htm、index.jsp等首页，我们也可以在nginx.conf中配置首页

 

将项目中的index.jsp文件删除，并重新打包

 

利用xshell重新上传到Linux，并拷贝到三个Tomcat中

```
docker cp HelloTomcat.war tomcat1:/usr/local/tomcat/webapps
docker cp HelloTomcat.war tomcat2:/usr/local/tomcat/webapps
docker cp HelloTomcat.war tomcat3:/usr/local/tomcat/webapps

```

浏览器访问8081、8082、8083期中的任何一台，可以看到404页面，表示没有主页



利用index设置首页

创建/home/xiangwei/static/index.html文件 

编辑nginx.conf添加以下配置

```
server {
    listen 80;   #监听80端口
    location = /HelloTomcat/ {
         root /home/xiangwei/static;
         index index.html;
    }
    location ~ .*\.(html|htm|gif|jpg|jpeg|bmp|png|js|css)$ {
         root /home/xiangwei/static;
    }
    location  / {
         proxy_pass http://blance;
    }
}

```

重启nginx

 

打开浏览器输入：http://localhost/HelloTomcat/ 测试

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220531171934.png" alt="image-20220531171934227" style="zoom:50%;" />



### nacos

#### Nacos基本介绍（低 15）

用在前面的微服务学习过程中注册中心和配置中心是两个非常重要的组成部分，但是注册中心、配置中心的管理却非常困难，特别是配置中心在更新完配置之后需要用到Bus进行配置推送，整个操作过程及其麻烦，正是因为这些原因阿里推出了一款叫做nacos的应用，该应用在能够实现注册中心的同时也实现了配置中心，而且操作十分简单，能够将程序员从繁琐的注册中心、配置中心的操作中解救出来。



英文全称Dynamic Naming and Configuration Service，Na为naming/nameServer即注册中心,co为configuration即注册中心，service是指该注册/配置中心都是以服务为核心。



Nacos注册中心分为server与client，server采用Java编写，为client提供注册发现服务与配置服务。而client可以用多语言实现，client与微服务嵌套在一起，nacos提供sdk和openApi，如果没有sdk也可以根据openApi手动写服务注册与发现和配置拉取的逻辑

#### Nacos 地图

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726220240.png" alt="image-20210726220240152" style="zoom: 50%;" />

#### Nacos 生态图

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726214737.png" alt="image-20210726214737542" style="zoom: 33%;" />



### Nacos安装（低 15）

1、下载安装

官网地址为：https://nacos.io/zh-cn/docs/quick-start.html

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727093518.png" alt="image-20210727093518590" style="zoom:50%;" />

2、 在新窗口中找到nacos指定版本的gz文件，点击下载。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727093440.png" alt="image-20210727093440654" style="zoom: 33%;" />

3、下载完成之后通过xshell将压缩包上传到Linux下，并解压

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727093715.png" alt="image-20210727093715892" style="zoom: 50%;" />



4、 将工作路径切换到解压出来的文件夹下的bin目录，并执行startup.sh文件启动nacos，执行命令

./startup.sh -m standalone

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727102447.png" alt="image-20210727102447914" style="zoom: 50%;" />



5、开启8848端口

firewall-cmd --zone=public --add-port=8848/tcp --permanent
sudo service firewalld restart



6、打开Windows中的浏览器，并在地址栏输入http://虚拟机ip:8848/nacos/访问nacos，出现以下界面表示成功

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727102531.png" alt="image-20210727102531226" style="zoom: 33%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727102546.png" alt="image-20210727102546652" style="zoom:33%;" />

8、输入账号密码进行登录，账号密码默认都是“nacos”，看到以下界面表示登录成功

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727102531.png" alt="image-20210727102531226" style="zoom: 33%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727102546.png" alt="image-20210727102546652" style="zoom:33%;" />



### nacos作为注册中心（高 30）

#### 创建provider微服务

1、创建provider项目，导入依赖

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727104120.png" alt="image-20210727104120363" style="zoom:33%;" />

2、在项目下会自动生成nacos的配置类，将本模块注册到nacos中

```java
@EnableDiscoveryClient
@Configuration
public class NacosDiscoveryConfiguration {
}

```



3、在该微服务的application.yml中进行以下配置

```yaml
server:
  port: 8081
spring:
  application:
    name: nacos-provider
  cloud:
    nacos:
      discovery:
        server-addr: 192.168.74.146:8848
management:
  endpoints:
    web:
      exposure:
        include: '*'

```



4、创建controller类，添加以下代码

```java
package com.woniuxy.alibabaprovider.controller;

import org.springframework.beans.factory.annotation.Value;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

@RestController
@RequestMapping("/provider")
public class ProviderController {
    @Value("${server.port}")
    private String port;

    @RequestMapping("/test")
    public String test() {
        return port;
    }
}

```



5、启动微服务，启动成功之后刷新nacos管理页面，查看注册情况，出现以下页面表示成功

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727104847.png" alt="image-20210727104846985" style="zoom:33%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727104932.png" alt="image-20210727104932386" style="zoom:33%;" />

在另外一个窗口中请求controller，看到以下页面表示成功

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727104932.png" alt="image-20210727104932386" style="zoom:33%;" />

再开启一个provider服务，端口号8082

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727105127.png" alt="image-20210727105127356" style="zoom:33%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727105158.png" alt="image-20210727105158036" style="zoom:33%;" />



# day13

### nacos

#### Nacos基本介绍（低 15）

用在前面的微服务学习过程中注册中心和配置中心是两个非常重要的组成部分，但是注册中心、配置中心的管理却非常困难，特别是配置中心在更新完配置之后需要用到Bus进行配置推送，整个操作过程及其麻烦，正是因为这些原因阿里推出了一款叫做nacos的应用，该应用在能够实现注册中心的同时也实现了配置中心，而且操作十分简单，能够将程序员从繁琐的注册中心、配置中心的操作中解救出来。



英文全称Dynamic Naming and Configuration Service，Na为naming/nameServer即注册中心,co为configuration即注册中心，service是指该注册/配置中心都是以服务为核心。



Nacos注册中心分为server与client，server采用Java编写，为client提供注册发现服务与配置服务。而client可以用多语言实现，client与微服务嵌套在一起，nacos提供sdk和openApi，如果没有sdk也可以根据openApi手动写服务注册与发现和配置拉取的逻辑

#### Nacos 地图

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726220240.png" alt="image-20210726220240152" style="zoom: 50%;" />

#### Nacos 生态图

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210726214737.png" alt="image-20210726214737542" style="zoom: 33%;" />



### Nacos安装（低 15）

1、下载安装

官网地址为：https://nacos.io/zh-cn/docs/quick-start.html

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727093518.png" alt="image-20210727093518590" style="zoom:50%;" />

2、 在新窗口中找到nacos指定版本的gz文件，点击下载。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727093440.png" alt="image-20210727093440654" style="zoom: 33%;" />

3、下载完成之后通过xshell将压缩包上传到Linux下，并解压

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727093715.png" alt="image-20210727093715892" style="zoom: 50%;" />



4、 将工作路径切换到解压出来的文件夹下的bin目录，并执行startup.sh文件启动nacos，执行命令

./startup.sh -m standalone

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727102447.png" alt="image-20210727102447914" style="zoom: 50%;" />



5、开启8848端口

firewall-cmd --zone=public --add-port=8848/tcp --permanent
sudo service firewalld restart



6、打开Windows中的浏览器，并在地址栏输入http://虚拟机ip:8848/nacos/访问nacos，出现以下界面表示成功

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727102531.png" alt="image-20210727102531226" style="zoom: 33%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727102546.png" alt="image-20210727102546652" style="zoom:33%;" />

8、输入账号密码进行登录，账号密码默认都是“nacos”，看到以下界面表示登录成功

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727102531.png" alt="image-20210727102531226" style="zoom: 33%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727102546.png" alt="image-20210727102546652" style="zoom:33%;" />



### nacos作为注册中心（高 30）

#### 创建provider微服务

1、创建provider项目，导入依赖

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727104120.png" alt="image-20210727104120363" style="zoom:33%;" />

2、在项目下会自动生成nacos的配置类，将本模块注册到nacos中

```java
@EnableDiscoveryClient
@Configuration
public class NacosDiscoveryConfiguration {
}
```



3、在该微服务的application.yml中进行以下配置

```yaml
server:
  port: 8081
spring:
  application:
    name: nacos-provider
  cloud:
    nacos:
      discovery:
        server-addr: 192.168.74.146:8848
management:
  endpoints:
    web:
      exposure:
        include: '*'
```



4、创建controller类，添加以下代码

```java
package com.woniuxy.alibabaprovider.controller;

import org.springframework.beans.factory.annotation.Value;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

@RestController
@RequestMapping("/provider")
public class ProviderController {
    @Value("${server.port}")
    private String port;

    @RequestMapping("/test")
    public String test() {
        return port;
    }
}
```



5、启动微服务，启动成功之后刷新nacos管理页面，查看注册情况，出现以下页面表示成功

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727104847.png" alt="image-20210727104846985" style="zoom:33%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727104932.png" alt="image-20210727104932386" style="zoom:33%;" />

在另外一个窗口中请求controller，看到以下页面表示成功

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727104932.png" alt="image-20210727104932386" style="zoom:33%;" />

再开启一个provider服务，端口号8082

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727105127.png" alt="image-20210727105127356" style="zoom:33%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727105158.png" alt="image-20210727105158036" style="zoom:33%;" />





#### 创建consumer微服务

1、创建消费者微服务，端口号为8001，并在其pom.xml文件中引入nacos的依赖

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727104120.png" alt="image-20210727104120363" style="zoom:33%;" />

2、在项目下会自动生成nacos的配置类，将本模块注册到nacos中

```java
@EnableDiscoveryClient
@Configuration
public class NacosDiscoveryConfiguration {
}
```



3、创建application.yml添加以下内容

```yaml
server:
  port: 8001
spring:
  application:
    name: nacos-consumer
  cloud:
    nacos:
      discovery:
        server-addr: 192.168.74.146:8848
management:
  endpoints:
    web:
      exposure:
        include: '*'
```



4、创建RestTemplate的配置文件并编写以下代码

```java
package com.woniuxy.alibabaconsumer.configuration;

import org.springframework.cloud.client.loadbalancer.LoadBalanced;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.web.client.RestTemplate;

@Configuration
public class RestTemplateConfiguration {
    @Bean
    @LoadBalanced
    public RestTemplate restTemplate() {
        return new RestTemplate();
    }
}
```



5、编写Controller并编写以下代码

```java
package com.woniuxy.alibabaconsumer.controller;

import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;
import org.springframework.web.client.RestTemplate;

import javax.annotation.Resource;

@RestController
@RequestMapping("/consumer")
public class ConsumerController {
    private String provider_url = "http://nacos-provider/provider/test";

    @Resource
    private RestTemplate restTemplate;

    @RequestMapping("/test")
    public String test() {
        return restTemplate.getForObject(provider_url, String.class);
    }
}
```



6、启动消费者微服务并刷新nacos管理页面，出现以下信息表示消费者注册成功

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727110808.png" alt="image-20210727110808644" style="zoom:33%;" />

在另一个浏览器窗口中请求消费者的URL，然后不断刷新查看页面上的数据，如果发现数字在8081和8082之间来回切换，说明通过消费者可以访问到生产者并且已经自动采用了轮询的方式访问生产者

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727110930.png" alt="image-20210727110930091" style="zoom:33%;" />



### nacos作为配置中心（高 45）

配置文件介绍、基本命名方式、微服务获取配置、分类配置（dataid、groupid、namespace）

1、新建一个微服务，名字叫做nacos-config-client，并在其pom中引入以下依赖

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727111508.png" alt="image-20210727111508122" style="zoom:33%;" />

2、 在resource下创建bootstrap.yml文件添加以下内容

官方中文文档网址：https://nacos.io/zh-cn/docs/quick-start-spring-cloud.html

```yaml
server:
  port: 8002
spring:
  application:
    name: nacos-config-client
  cloud:
    nacos:
      discovery:
        server-addr: 192.168.74.146:8848 #注册中心ip:端口
      config:
        server-addr: 192.168.74.146:8848 #配置中心ip:端口
        file-extension: yaml #配置文件格式
```



3、在application.yml中添加以下配置

```yaml
spring:
  profiles:
    active: dev #开发环境

```



4、创建Controller并添加以下代码

```java
package com.woniuxy.nacosconfigclient.controller;

import org.springframework.beans.factory.annotation.Value;
import org.springframework.cloud.context.config.annotation.RefreshScope;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

@RestController
@RequestMapping("/config")
@RefreshScope    //支持nacos的动态刷新功能:修改配置文件之后立即刷新获取最新的配置
public class ConfigController {
    @Value("${config.info}")
    private String info;

    @RequestMapping("/test")
    public String test() {
        return info;
    }
}

```



5、在nacos控制台上创建一个配置文件

配置文件名需要按照官方要求取名，官方取名要求格式为：

​	${spring.application.name}-${spring.profiles.active}.${file-extension}

说明：

​	${spring.application.name} 	bootstrap.yml文件中指定的微服务名字

​	${spring.profiles.active}  		 application.yml文件中active的值

​	${file-extension}						后缀名格式，nacos只支持properties和yaml两种格式

例如此案例中对应的配置文件名为：nacos-config-client-dev.yaml



找到配置列表，点击右侧添加按钮

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727112407.png" alt="image-20210727112406879" style="zoom:33%;" />

输入配置文件名字、选择配置文件格式、填写配置信息

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727113221.png" alt="image-20210727113221703" style="zoom:33%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727113240.png" alt="image-20210727113240627" style="zoom:33%;" />

点击发布

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727112705.png" alt="image-20210727112705161" style="zoom:33%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727113221.png" alt="image-20210727113221703" style="zoom:33%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727113240.png" alt="image-20210727113240627" style="zoom:33%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727113259.png" alt="image-20210727113259218" style="zoom:33%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727113259.png" alt="image-20210727113259218" style="zoom:33%;" />

6、 运行nacos-config-client微服务，启动成功之后先到注册中心中看是否注册上

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727113355.png" alt="image-20210727113355210" style="zoom:33%;" />

7、在新的浏览器窗口地址栏中输入nacos-config-client微服务的URL进行访问，看到以下信息表明微服务能够从配置中心中获取配置信息了

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727113508.png" alt="image-20210727113508062" style="zoom:33%;" />

8、修改配置中心的配置文件，演示更新配置之后微服务能够及时获取新的配置信息

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727113608.png" alt="image-20210727113608450" style="zoom:33%;" />

修改配置，并发布

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727113657.png" alt="image-20210727113657518" style="zoom:33%;" />

刷新访问nacos-config-client微服务的页面，看到以下信息表明微服务拿到了新的配置信息

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727113819.png" alt="image-20210727113819469" style="zoom:33%;" />

#### 分类配置

多项目多开发环境需要不同的配置，利用分类配置可以区分不同环境下的配置，实现方式主要有三种：DataId、GroupId和Namespace方式



1、dataid实现分组

创建一个test配置文件

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727115348.png" alt="image-20210727115348719" style="zoom:33%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727115412.png" alt="image-20210727115412195" style="zoom:33%;" />

修改application.yml中的配置信息

```yaml
spring:
  profiles:
    active: test #测试环境

```



启动项目测试

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727115806.png" alt="image-20210727115806536" style="zoom:33%;" />



2、Group实现配置不同环境

新建两个配置文件，指定分组名称

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727120027.png" alt="image-20210727120027505" style="zoom:33%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727120151.png" alt="image-20210727120150921" style="zoom:33%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727120236.png" alt="image-20210727120236001" style="zoom:33%;" />

在bootstrap.yml中配置group信息

```yaml
server:
  port: 8002
spring:
  application:
    name: nacos-config-client
  cloud:
    nacos:
      discovery:
        server-addr: 192.168.74.146:8848 #注册中心ip:端口
      config:
        server-addr: 192.168.74.146:8848 #配置中心ip:端口
        file-extension: yaml #配置文件格式
        group: FIRST_GROUP  #配置分组

```

application.yml

```yaml
spring:
  profiles:
    active: dev #测试环境

```

启动项目测试

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727120652.png" alt="image-20210727120651988" style="zoom:33%;" />

3、Namespace实现不同环境配置

创建两个Namespace

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727120742.png" alt="image-20210727120742409" style="zoom:33%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727120855.png" alt="image-20210727120855130" style="zoom:33%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727120943.png" alt="image-20210727120943061" style="zoom:33%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727120959.png" alt="image-20210727120959101" style="zoom:33%;" />

回到配置列表可以看到管理页面上方已经多出两个刚才创建的命名空间

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727121043.png" alt="image-20210727121043647" style="zoom:33%;" />

在新Namespace中添加两个配置文件，分别分在不同的组中

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727121120.png" alt="image-20210727121120357" style="zoom:33%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727121352.png" alt="image-20210727121352551" style="zoom:33%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727121120.png" alt="image-20210727121120357" style="zoom:33%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727121352.png" alt="image-20210727121352551" style="zoom:33%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727121251.png" alt="image-20210727121250831" style="zoom:33%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727121439.png" alt="image-20210727121438722" style="zoom:33%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727121515.png" alt="image-20210727121515422" style="zoom:33%;" />

在bootstrap.yml中添加namespace的id

```yaml
server:
  port: 8002
spring:
  application:
    name: nacos-config-client
  cloud:
    nacos:
      discovery:
        server-addr: 192.168.74.146:8848 #注册中心ip:端口
      config:
        server-addr: 192.168.74.146:8848 #配置中心ip:端口
        file-extension: yaml #配置文件格式
        group: FIRST_GROUP  #配置分组
        namespace: dea45281-b010-4acf-b1ea-9fe045f635c4 #命名空间id

```

命名空间id可以在nacos管理页面看到

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727122046.png" alt="image-20210727122045816" style="zoom:33%;" />

运行测试

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727121946.png" alt="image-20210727121946151" style="zoom:33%;" />





### Sentinel介绍（低 20）

Sentinel 控制台是流量控制、熔断降级规则统一配置和管理的入口，它为用户提供了机器自发现、簇点链路自发现、监控、规则配置等功能。在 Sentinel 控制台上，我们可以配置规则并实时查看流量控制效果。



随着微服务的普及，服务调用的稳定性变得越来越重要。Sentinel以“流量”为切入点，在流量控制、断路、负载保护等多个领域开展工作，保障服务可靠性。

哨兵具有以下特点：

- 场景丰富： Sentinel 支持阿里巴巴双十一的关键场景10多年，如秒杀（即控制突发流量，使其在系统容量可接受范围内），消息负载转移，不可靠下游应用的断路。

- 全面的实时监控： Sentinel 提供实时监控能力。您可以秒级精确查看服务器的监控数据，甚至可以看到少于500个节点的集群的整体运行状态。

- 广泛的开源生态系统： Sentinel 提供了开箱即用的模块，可以轻松地与其他开源框架/库集成，例如 Spring Cloud、Dubbo 和 gRPC。使用Sentinel只需要引入相关的依赖，做一些简单的配置即可。

- Sound SPI Extensions： Sentinel 提供了简单易用且完善的 SPI 扩展接口。您可以使用 SPI 扩展快速自定义逻辑，例如，您可以定义自己的规则管理，或适应特定的数据源。

 官方文档：https://github.com/alibaba/Sentinel/wiki/%E4%BB%8B%E7%BB%8D



### Sentinel安装与配置（低 15）

1、下载地址：https://github.com/alibaba/Sentinel/releases

 <img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727142810.png" alt="image-20210727142809953" style="zoom: 50%;" />



2、将jar包放到Windows任意目录下，并启动（Linux操作方式相同）

Sentinel 仪表板是标准的 SpringBoot 应用程序，可以在 Spring Boot 模式下运行 JAR 文件

​	java -Dserver.port=8858 -Dcsp.sentinel.dashboard.server=localhost:8080 -Dproject.name=sentinel-dashboard -jar sentinel-dashboard-1.8.2.jar



上述命令中我们指定几个 JVM 参数，其中 `-Dserver.port=8858` 是 Spring Boot 的参数， 用于指定 Spring Boot 服务端启动端口为 `8080`。其余几个是 Sentinel 客户端的参数。

为便于演示，我们对控制台本身加入了流量控制功能，具体做法是引入 Sentinel 提供的 `CommonFilter` 这个 Servlet Filter。 上述 JVM 参数的含义是：

| 参数                                           | 作用                                                         |
| ---------------------------------------------- | ------------------------------------------------------------ |
| -Dcsp.sentinel.dashboard.server=localhost:8080 | 向 Sentinel 接入端指定控制台的地址                           |
| -Dproject.name=sentinel-dashboard              | 向 Sentinel 指定应用名称，比如上面对应的应用名称就为 sentinel-dashboard |



3、开启8858端口（<font color="red">仅限Linux</font>）

firewall-cmd --zone=public --add-port=8858/tcp --permanent

systemctl restart firewalld.service



4、在Windows浏览器上访问sentinel，账号密码都是sentinel

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727202456.png" alt="image-20210727202456723" style="zoom:33%;" />



### Sentinel应用（高 45）

#### 1、创建sentinel-provider子模块

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727144033.png" alt="image-20210727144033821" style="zoom:33%;" />

 在application.yml文件中添加以下配置

```yaml
spring:
  application:
    name: sentinel-provider
  cloud:
    nacos:
      discovery:
        server-addr: 192.168.74.146:8848
    sentinel:
      transport:
        dashboard: localhost:8858 #Sentinel 控制台地址
      eager: true # 取消Sentinel控制台懒加载,默认情况下 Sentinel 会在客户端首次调用的时候进行初始化，开始向控制台发送心跳包
server:
  port: 8080
management:
  endpoints:
    web:
      exposure:
        include: '*'

```



创建controller

```java
package com.woniuxy.sentinelprovider.controller;

import com.alibaba.csp.sentinel.annotation.SentinelResource;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

@RestController
@RequestMapping("/test")
public class TestController {

    @GetMapping("/hello")
    @SentinelResource("hello")
    public String test(){
        return "Hello Sentinel";
    }
}

```

@SentinelResource 注解用于识别资源是速率受限还是降级。在上面的示例中，注解的 'hello' 属性指的是资源名称。



启动sentinel-provider并请求controller中的接口，观察sentinel控制台信息

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727203446.png" alt="image-20210727203446499" style="zoom:33%;" />

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210727203502.png" alt="image-20210727203502290" style="zoom:33%;" />

#### 2、常见概念

响应时间	服务器从接到请求到完成处理请求的时间

吞吐量		单位时间内接收处理请求的数量

QPS			每秒查询率，每秒响应请求的数量

并发数		同时能够承载正常使用当前系统的用户数量



如果不想看到context、error等信息，可以在application.yml中关闭

```yaml
spring:
  cloud:
    sentinel:
      transport:
        dashboard: localhost:8858
      eager: true
      filter:
        enabled: false  #关闭sentinel filter实例化   不监控context、error

```



#### 3、服务降级

利用@SentinelResource中的fallback属性实现服务降级

fallback / fallbackClass：fallback 函数名称，可选项，用于在抛出异常的时候提供 fallback 处理逻辑。fallback 函数可以针对所有类型的异常（除了 exceptionsToIgnore 里面排除掉的异常类型）进行处理。fallback 函数签名和位置要求：

- 返回值类型必须与原函数返回值类型一致；

- 方法参数列表需要和原函数一致，或者可以额外多一个 Throwable 类型的参数用于接收对应的异常。

- fallback 函数默认需要和原方法在同一个类中。若希望使用其他类的函数，则可以指定 fallbackClass 为对应的类的 Class 对象，注意对应的函数必需为 static 函数，否则无法解析。

```java
package com.woniuxy.sentinelprovider.controller;

import com.alibaba.csp.sentinel.annotation.SentinelResource;s
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

import java.util.Random;

@RestController
@RequestMapping("/test")
public class TestController {

    @GetMapping("/hello")
    @SentinelResource(value = "hello",fallback = "helloFallback")
    public String test(){
        int n = new Random().nextInt(3);
        if (n == 0){
            //模拟运行时异常
            throw new RuntimeException("运行时异常");
        }
        return "Hello Sentinel";
    }
    //fallback函数,还可以加个Throwable类型的参数，得到异常信息
    public String helloFallback() {
        return String.format("fallback");
    }
}

```

运行项目测试，在多次请求中得到fallback结果，证明服务降级有效。



#### 4、服务限流

通过blokHandler实现服务限流

- blockHandler / blockHandlerClass: blockHandler 对应处理 BlockException 的函数名称，可选项。

- blockHandler 函数访问范围需要是 public，返回类型需要与原方法相匹配，参数类型需要和原方法相匹配并且最后加一个额外的参数，类型为 BlockException。

- blockHandler 函数默认需要和原方法在同一个类中。若希望使用其他类的函数，则可以指定 blockHandlerClass 为对应的类的 Class 对象，注意对应的函数必需为 static 函数，否则无法解析。

在handler中添加以下代码

```java
package com.woniuxy.sentinelprovider.controller;

import com.alibaba.csp.sentinel.annotation.SentinelResource;
import com.alibaba.csp.sentinel.slots.block.BlockException;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

import java.util.Random;

@RestController
@RequestMapping("/test")
public class TestController {

    @GetMapping("/hello")
    @SentinelResource(value = "hello",fallback = "helloFallback",blockHandler = "exceptionHandler")
    public String test(){
        int n = new Random().nextInt(3);
        if (n == 0){
            //模拟运行时异常
            throw new RuntimeException("运行时异常");
        }
        return "Hello Sentinel";
    }
    
    // fallback函数,还可以加个Throwable类型的参数，得到异常信息
    public String helloFallback() {
         return String.format("fallback");
    }

    // 限流异常处理  Block 异常处理函数，参数最后多一个 BlockException，其余与原函数一致.
    public String exceptionHandler(BlockException e) {
        return "Oops, error occurred at " + e.getMessage();
    }
}


```

在sentinel控制台中添加浏览控制指定QPS

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210728142033.png" alt="image-20210728142033405" style="zoom:33%;" />

指定QPS为1

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210728142120.png" alt="image-20210728142120372" style="zoom:33%;" />

启动项目，快速访问几次hello接口，发现只要在1秒钟之内请求次数超过1次，就会得到exceptionHandler中返回的结果，证明限流成功。



#### 5、fallback与lockHandler的区别

- fallback：失败调用，若本接口出现未知异常，则调用fallback指定的接口。

- blockHandler：sentinel定义的失败调用或限制调用，若本次访问被限流或服务降级，则调用blockHandler指定的接口。



### 流控模式（补充）

sentinel共有三种

- 直接（默认）：接口达到限流条件时，开启限流
- 关联：当关联的资源达到限流条件时，开启限流，适合做应用让步。例如为一个查询的接口添加关联流控，关联资源为一个更新的接口，当更新的接口达到阈值时，开启查询接口的限流，为更新接口让步服务器资源。
- 链路：当从某个接口过来的资源达到限流条件时，开启限流

####  直接流控

**基于QPS流量控制**

当QPS超过某个阈值的时候，则采用措施进行流量控制（基于并发线程数的没有这个控制）。流量控制的手段包括以下几种：直接拒绝，Warm Up，均速排队

- 直接拒绝:(RuleConstant.CONTROL_BEHAVIOR_DEFAULT)方式是默认的流量控制方式，当QPS超过任何规则的阈值后，新的请求就会立即拒绝，拒绝方式为抛出- FlowException 。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210728142120.png" alt="image-20210728142120372" style="zoom:33%;" />



- Warm Up:(RuleConstant.CONTROL_BEHAVIOR_WARM_UP)方式，即预热/冷启动方式。当系统长期处理低水平的情况下，当流量突然增加时，直接把系统拉升到高水位可能瞬间把系统压垮。通过"冷启动"，让通过的流量缓慢增加，在一定时间内逐渐增加到阈值的上限，给系统一个预热的时间，避免冷系统被压垮。

  例如设置QPS阈值为10，预热时间为5秒，含义是：系统的QPS最大是10，但是要达到10需要预热5秒，在5秒之内QPS的阈值会慢慢增加，那么在5秒之内可能会出现限流的情况

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210728144132.png" alt="image-20210728144132490" style="zoom:33%;" />

设置好流控之后，不断请求hello，然后查看sentinel的实时监控

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210728144709.png" alt="image-20210728144708846" style="zoom:33%;" />

可以看到前期被拒绝的请求很多，但是随着预热时间到，被拒绝的逐渐减少



- 均速排队:(RuleConstant.CONTROL_BEHAVIOR_RATE_LIMITER)方式后严格控制请求通过的时间间隔，也即是让请求以均匀的速度通过，对应的是漏桶算法。

这种方式主要用于处理间隔性突发的流量，例如消息队列。适用于：在某一秒有大量的请求到来，而接下来的几秒则处于空闲状态，我们希望系统能够在接下来的空闲期间逐渐处理这些请求，而不是在第一秒直接拒绝多余的请求。

例如：设置QPS为5，超时时间为1000毫秒，含义为QPS最大为5，如果超过该阈值的就等待，1000毫秒内如果没有处理则拒绝

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210728145310.png" alt="image-20210728145310175" style="zoom:33%;" />



<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210728145225.png" alt="image-20210728145225018" style="zoom:33%;" />



**基于并发线程数控制**

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20210728150011.png" alt="image-20210728150011351" style="zoom:33%;" />

并发数控制用于保护业务线程池不被慢调用耗尽

Sentinel 并发控制不负责创建和管理线程池，而是简单统计当前请求上下文的线程数目（正在执行的调用数目）；

如果超出阈值，新的请求会被立即拒绝，效果类似于信号量隔离；



### mycat

#### 数据切分

关系型数据库本身比较容易成为系统瓶颈，单机存储容量、连接数、处理能力都有限。当单表的数据量达到1000W或100G以后，由于查询维度较多，即使添加从库、优化索引，做很多操作时性能仍下降严重。此时就要考虑对其进行切分了，切分的目的就在于减少数据库的负担，缩短查询时间。

 

数据库分布式核心内容无非就是数据切分（Sharding），以及切分后对数据的定位、整合。数据切分就是将数据分散存储到多个数据库中，使得单一数据库中的数据量变小，通过扩充主机的数量缓解单一数据库的性能问题，从而达到提升数据库操作性能的目的。

 

数据切分根据其切分类型，可以分为两种方式：垂直（纵向）切分和水平（横向）切分

##### 垂直（纵向）切分

垂直切分常见有**垂直分库**和**垂直分表**两种。

 

**垂直分库**就是根据业务耦合性，将关联度低的不同表存储在不同的数据库。做法与大系统拆分为多个小系统类似，按业务分类进行独立划分。如图：

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220601171514.png" alt="image-20220601171514859" style="zoom:67%;" />

**垂直分表**是基于数据库中的"列"进行，某个表字段较多，可以新建一张扩展表，将不经常用或字段长度较大的字段拆分出去到扩展表中。在字段很多的情况下（例如一个大表有100多个字段），通过"大表拆小表"，更便于开发与维护，也能避免跨页问题（MySQL底层是通过数据页存储的，一条记录占用空间过大会导致跨页，造成额外的性能开销）。另外数据库以行为单位将数据加载到内存中，这样表中字段长度较短且访问频率较高，内存能加载更多的数据，命中率更高，减少了磁盘IO，从而提升了数据库性能。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220601171531.png" alt="image-20220601171531239" style="zoom:67%;" />

优点：

- 解决业务系统层面的耦合，业务清晰

- 与微服务的治理类似，也能对不同业务的数据进行分级管理、维护、监控、扩展等

- 高并发场景下，垂直切分一定程度的提升IO、数据库连接数、单机硬件资源的瓶颈

缺点：

- 部分表无法join，只能通过接口聚合方式解决，提升了开发的复杂度

- 分布式事务处理复杂

- 依然存在单表数据量过大的问题（需要水平切分）

 

##### 水平（横向）切分

当一个应用难以再细粒度的垂直切分，或切分后数据量行数巨大，存在单库读写、存储性能瓶颈，这时候就需要进行水平切分了。

 

水平切分分为**库内分表**和**分库分表**，是根据表内数据内在的逻辑关系，将同一个表按不同的条件分散到多个数据库或多个表中，每个表中只包含一部分数据，从而使得单个表的数据量变小，达到分布式的效果。如图所示：

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220601171644.png" alt="image-20220601171644870" style="zoom:67%;" />

库内分表只解决了单一表数据量过大的问题，但没有将表分布到不同机器的库上，因此对于减轻MySQL数据库的压力来说，帮助不是很大，大家还是竞争同一个物理机的CPU、内存、网络IO，最好通过分库分表来解决。

 

水平切分的优点：

- 不存在单库数据量过大、高并发的性能瓶颈，提升系统稳定性和负载能力

- 应用端改造较小，不需要拆分业务模块

缺点：

- 跨分片的事务一致性难以保证

- 跨库的join关联查询性能较差

- 数据多次扩展难度和维护量极大

 

#### Mycat简介

MyCat是一个开源的分布式数据库系统，是一个实现了MySQL协议的服务器，前端用户可以把它看作是一个数据库代理，用MySQL客户端工具和命令行访问，而其后端可以用MySQL原生协议与多个MySQL服务器通信，也可以用JDBC协议与大多数主流数据库服务器通信，其核心功能是分表分库，即将一个大表水平分割为N个小表，存储在后端MySQL服务器里或者其他数据库里。

 

MyCat发展到目前的版本，已经不是一个单纯的MySQL代理了，它的后端可以支持MySQL、SQL Server、Oracle、DB2、PostgreSQL等主流数据库，也支持MongoDB这种新型NoSQL方式的存储，未来还会支持更多类型的存储。而在最终用户看来，无论是那种存储方式，在MyCat里，都是一个传统的数据库表，支持标准的SQL语句进行数据的操作，这样一来，对前端业务系统来说，可以大幅降低开发难度，提升开发速度。

<img src="https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220601171720.png" alt="image-20220601171720083" style="zoom:67%;" />

我们的应用只需要一台数据库服务器的时候我们并不需要Mycat，而如果你需要分库甚至分表，这时候应用要面对很多个数据库的时候，这个时候就需要对数据库层做一个抽象，来管理这些数据库，而最上面的应用只需要面对一个数据库层的抽象或者说数据库中间件就好了，这就是Mycat的核心作用。

 

Mycat是一个广受好评的数据库中间件，为了减轻单数据库的压力，可以实现主从、热备、分表分库，从而实现数据库的分布式架构。



#### Mycat环境搭建

准备工作

- 准备两台Linux

- 都安装上JDK和MySQL数据库

- 保证两台MySQL可以通过MySQL界面工具远程访问

- 下载Mycat，Mycat下载地址：

  https://github.com/MyCATApache/Mycat-Server

1、将下载好的Mycat压缩包上传到其中一个Linux的/root目录下

![image-20220601171801742](https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220601171801.png)

2、解压压缩包，得到mycat目录

![image-20220601171810655](https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220601171810.png)

3、进入mycat目录

![image-20220601171819788](https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220601171819.png)

4、进入bin目录查看Mycat系统命令

![image-20220601171832894](https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220601171832.png)

5、启动Mycat,并查看运行情况

./mycat start

ps -ef|grep mycat

![image-20220601171844541](https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220601171844.png)

Mycat常见命令

- mycat start			启动mycat

- mycat stop 			关闭服务

- mycat console 		启动时在前台打印信息

- mycat status		查看mycat状态



6、利用MySQL界面工具分别连接两个MySQL数据库，确保能连接成功

如果出现Host xxx is not allowed to connect to this MySQL server这样的错误可能是由以下情况造成的

- 没有开放3306端口

  firewall-cmd --zone=public --add-port=3306/tcp --permanent

  systemctl restart firewalld.service

- MySQL不允许远程登录

  ①在装有MySQL的机器上登录MySQL mysql -u root -p密码

  ②执行use mysql;

  ③GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'root' WITH GRANT OPTION;

  这一句执行完可能会报错，不用管它。

  ④执行FLUSH PRIVILEGES;	刷新MySQL的权限



7、开启Mycat的8066端口

firewall-cmd --zone=public --add-port=8066/tcp --permanent

systemctl restart firewalld.service

 

8、通过MySQL可视化工具连接到Mycat，账号密码都为test

![image-20220601171950181](https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220601171950.png)

9、分别在两个MySQL上创建三个数据库，然后分别在三个数据库中创建相同的一张表

9.1、在MySQL1上创建DB1、DB2创建数据库

```sql
CREATE DATABASE db1 DEFAULT CHARACTER SET utf8;
CREATE DATABASE db2 DEFAULT CHARACTER SET utf8;

```

9.2、分别在DB1、DB2上创建product表

```sql
CREATE TABLE product(
	id INT PRIMARY KEY,
	pname CHAR(20)
);

```

9.3、在MySQL2上创建DB3，并创建product表

```sql
CREATE DATABASE db3 DEFAULT CHARACTER SET utf8;
CREATE TABLE product(
	id INT PRIMARY KEY,
	pname CHAR(20)
);

```

10、配置mycat

10.1、打开mycat/conf/server.xml配置登录账号、密码及虚拟表

![image-20220601172054573](https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220601172054.png)

修改完毕之后保存退出

10.2、打开schema.xml文件配置节点

配置虚拟表

![image-20220601172144662](https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220601172144.png)

配置节点

![image-20220601172158503](https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220601172158.png)

配置每个节点的mysql

![image-20220601172214863](https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220601172214.png)

完整配置

```xml
<?xml version="1.0"?>
<!DOCTYPE mycat:schema SYSTEM "schema.dtd">
<mycat:schema xmlns:mycat="http://org.opencloudb/">

	<schema name="TESTDB" checkSQLschema="false" sqlMaxLimit="100">
		<!-- auto sharding by id (long) -->
		<table name="product" dataNode="dn1,dn2,dn3" rule="auto-sharding-long" />
	</schema>

	<dataNode name="dn1" dataHost="localhost1" database="db1" />
	<dataNode name="dn2" dataHost="localhost1" database="db2" />
	<dataNode name="dn3" dataHost="localhost2" database="db3" />
	<dataHost name="localhost1" maxCon="1000" minCon="10" balance="0"
		writeType="0" dbType="mysql" dbDriver="native">
		<heartbeat>select user()</heartbeat>
		<!-- can have multi write hosts -->
		<writeHost host="hostM1" url="192.168.74.153:3306" user="root"
			password="root">
			<!-- can have multi read hosts -->
			<!-- <readHost host="hostS1" url="localhost:3306" user="root" password="123456" 
				/> -->
		</writeHost>
		<!-- <writeHost host="hostM2" url="localhost:3316" user="root" password="123456"/> -->
	</dataHost>
	<dataHost name="localhost2" maxCon="1000" minCon="10" balance="0"
		writeType="0" dbType="mysql" dbDriver="native">
		<heartbeat>select user()</heartbeat>
		<!-- can have multi write hosts -->
		<writeHost host="hostM1" url="192.168.74.154:3306" user="root"
			password="root">
			<!-- can have multi read hosts -->
			<!-- <readHost host="hostS1" url="localhost:3306" user="root" password="123456" 
				/> -->
		</writeHost>
		<!-- <writeHost host="hostM2" url="localhost:3316" user="root" password="123456"/> -->
	</dataHost>
</mycat:schema>

```

11、配置好后重启mycat

 

12、连接mycat

![image-20220601172234979](https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220601172235.png)

也可以用Linux控制台连接mycat

mysql -utest -ptest -P8066 -h127.0.0.1

![image-20220601172244258](https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220601172244.png)

13、向虚拟表product中添加几条数据

```sql
INSERT into product(id,pname) VALUES(1,'手机');
INSERT into product(id,pname) VALUES(2,'电脑');
INSERT into product(id,pname) VALUES(5000000,'手表');
INSERT into product(id,pname) VALUES(5000001,'电脑');
INSERT into product(id,pname) VALUES(10000001,'电筒');

```

14、分别打开db1、db2、db3的product可以看到db1中保存的是前5000000行数据，db2保存的是5000001-1000W行数据，而db3保存的是100000001到1500W行数据

 

15、打开rule.xml文件，其中指定了分片规则（水平拆分），及规则文件

![image-20220601172311655](https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220601172311.png)

16、打开conf/autopartition-long.txt文件修改规则

![image-20220601172328668](https://woniumd.oss-cn-hangzhou.aliyuncs.com/java/xiangwei/20220601172328.png)

修改完规则重启mycat，删除原有的数据，然后再插入数据试试

```sql
INSERT into product(id,pname) VALUES(1,'手机');
INSERT into product(id,pname) VALUES(2,'电脑');
INSERT into product(id,pname) VALUES(500001,'手表');
INSERT into product(id,pname) VALUES(1000001,'电脑');

```

可以在mycat中像查询单表一样将三个库中的数据都查询出来





















































































